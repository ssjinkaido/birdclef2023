Date :04/10/2023, 03:28:14
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 0
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
13552
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 03:29:12
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 0
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
13552
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 04:35:03
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 04:36:48
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 04:39:43
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 04:51:55
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 10.2513, val loss: 9.3489
Model improve: 0.0000 -> 0.5159
Epoch: 2/100
Date :04/10/2023, 13:33:41
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 09:35:24
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 09:53:17
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 09:55:55
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 10:53:43
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 256
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 10.2591, val loss: 9.0692
Model improve: 0.0000 -> 0.5260
Epoch: 2/100
Date :04/10/2023, 11:23:36
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 11:24:35
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 11:25:00
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 11:25:23
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 11:25:51
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/10/2023, 11:26:56
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 10.4396, val loss: 8.8715
Model improve: 0.0000 -> 0.5263
Epoch: 2/100
Date :04/11/2023, 00:19:18
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 16
nmels: 128
fmax: 16386
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/13/2023, 01:52:36
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 50
nmels: 128
fmax: 14000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 9.3526, val loss: 5.4947
0.6632210946672733
Model improve: 0.0000 -> 0.6632
Epoch: 2/100
Train loss: 6.8848, val loss: 4.0402
0.7575198610564583
Model improve: 0.6632 -> 0.7575
Epoch: 3/100
Train loss: 5.9954, val loss: 3.5464
0.7893189483001798
Model improve: 0.7575 -> 0.7893
Epoch: 4/100
Train loss: 5.2765, val loss: 3.1446
0.8095934784385606
Model improve: 0.7893 -> 0.8096
Epoch: 5/100
Train loss: 5.0761, val loss: 2.9360
0.8245479300138489
Model improve: 0.8096 -> 0.8245
Epoch: 6/100
Train loss: 4.7465, val loss: 2.8365
0.832657013470036
Model improve: 0.8245 -> 0.8327
Epoch: 7/100
Train loss: 4.3958, val loss: 2.8595
0.8447703223227531
Model improve: 0.8327 -> 0.8448
Epoch: 8/100
Train loss: 4.3473, val loss: 2.6534
0.8496942003696264
Model improve: 0.8448 -> 0.8497
Epoch: 9/100
Train loss: 4.1625, val loss: 2.4417
0.8562646255072226
Model improve: 0.8497 -> 0.8563
Epoch: 10/100
Date :04/14/2023, 00:45:19
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
19479
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 9.4146, val loss: 5.9020
0.6497029489293402
Model improve: 0.0000 -> 0.6497
Epoch: 2/100
Train loss: 6.9898, val loss: 4.4077
0.741680136577835
Model improve: 0.0000 -> 0.7417
Epoch: 3/100
Train loss: 6.0483, val loss: 3.6904
0.7817667420528217
Model improve: 0.0000 -> 0.7818
Epoch: 4/100
Train loss: 5.3772, val loss: 3.3303
0.8053604498960166
Model improve: 0.0000 -> 0.8054
Epoch: 5/100
Train loss: 5.1127, val loss: 3.2917
0.8162518227394542
Model improve: 0.0000 -> 0.8163
Epoch: 6/100
Train loss: 4.7317, val loss: 3.0284
0.8230986305161774
Model improve: 0.0000 -> 0.8231
Epoch: 7/100
Date :04/14/2023, 01:09:53
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
19479
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 9.4207, val loss: 5.8636
0.6458022923855747
Model improve: 0.0000 -> 0.6458
Epoch: 2/100
Date :04/14/2023, 01:17:12
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Epoch: 2/100
Date :04/14/2023, 01:17:41
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:17:56
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:18:08
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:18:53
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:19:10
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:19:19
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
50
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:28:01
Duration: 5
Sample rate: 32000
nfft: 2048
nmels: 128
fmin: 20
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.5
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
19479
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Date :04/14/2023, 01:28:43
Duration: 5
Sample rate: 32000
nfft: 2048
nmels: 128
fmin: 20
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.5
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
19479
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 9.6118, val loss: 6.0235
0.6434632411378763
Model improve: 0.0000 -> 0.6435
Date :04/14/2023, 01:39:26
Duration: 5
Sample rate: 32000
nfft: 2048
nmels: 128
fmin: 20
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.0004
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.5
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
19479
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.0004
    lr: 0.0004
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 9.6121, val loss: 5.9225
0.6399945356123397
Model improve: 0.0000 -> 0.6400
Epoch: 2/100
Train loss: 7.3658, val loss: 4.4339
0.7384370195387417
Model improve: 0.6400 -> 0.7384
Epoch: 3/100
Train loss: 6.4503, val loss: 3.8235
0.7795226683670775
Model improve: 0.7384 -> 0.7795
Epoch: 4/100
Date :04/14/2023, 08:24:12
Duration: 5
Sample rate: 32000
nfft: 2048
nmels: 128
fmin: 20
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 100
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_s
mix_up: 0.5
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 2
19479
AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    initial_lr: 0.001
    lr: 0.001
    maximize: False
    weight_decay: 0.01
)
Epoch: 1/100
Train loss: 9.6226, val loss: 6.3898
0.6341025020826937
Model improve: 0.0000 -> 0.6341
Epoch: 2/100
Train loss: 7.7435, val loss: 5.0407
0.7157214257717975
Model improve: 0.6341 -> 0.7157
Epoch: 3/100

conv_stem
bn1
act1
blocks
blocks.0
blocks.0.0
blocks.0.0.conv_dw
blocks.0.0.bn1
blocks.0.0.act1
blocks.0.0.se
blocks.0.0.se.conv_reduce
blocks.0.0.se.act1
blocks.0.0.se.conv_expand
blocks.0.0.se.gate
blocks.0.0.conv_pw
blocks.0.0.bn2
blocks.0.0.act2
blocks.1
blocks.1.0
blocks.1.0.conv_pw
blocks.1.0.bn1
blocks.1.0.act1
blocks.1.0.conv_dw
blocks.1.0.bn2
blocks.1.0.act2
blocks.1.0.se
blocks.1.0.se.conv_reduce
blocks.1.0.se.act1
blocks.1.0.se.conv_expand
blocks.1.0.se.gate
blocks.1.0.conv_pwl
blocks.1.0.bn3
blocks.1.1
blocks.1.1.conv_pw
blocks.1.1.bn1
blocks.1.1.act1
blocks.1.1.conv_dw
blocks.1.1.bn2
blocks.1.1.act2
blocks.1.1.se
blocks.1.1.se.conv_reduce
blocks.1.1.se.act1
blocks.1.1.se.conv_expand
blocks.1.1.se.gate
blocks.1.1.conv_pwl
blocks.1.1.bn3
blocks.2
blocks.2.0
blocks.2.0.conv_pw
blocks.2.0.bn1
blocks.2.0.act1
blocks.2.0.conv_dw
blocks.2.0.bn2
blocks.2.0.act2
blocks.2.0.se
blocks.2.0.se.conv_reduce
blocks.2.0.se.act1
blocks.2.0.se.conv_expand
blocks.2.0.se.gate
blocks.2.0.conv_pwl
blocks.2.0.bn3
blocks.2.1
blocks.2.1.conv_pw
blocks.2.1.bn1
blocks.2.1.act1
blocks.2.1.conv_dw
blocks.2.1.bn2
blocks.2.1.act2
blocks.2.1.se
blocks.2.1.se.conv_reduce
blocks.2.1.se.act1
blocks.2.1.se.conv_expand
blocks.2.1.se.gate
blocks.2.1.conv_pwl
blocks.2.1.bn3
blocks.3
blocks.3.0
blocks.3.0.conv_pw
blocks.3.0.bn1
blocks.3.0.act1
blocks.3.0.conv_dw
blocks.3.0.bn2
blocks.3.0.act2
blocks.3.0.se
blocks.3.0.se.conv_reduce
blocks.3.0.se.act1
blocks.3.0.se.conv_expand
blocks.3.0.se.gate
blocks.3.0.conv_pwl
blocks.3.0.bn3
blocks.3.1
blocks.3.1.conv_pw
blocks.3.1.bn1
blocks.3.1.act1
blocks.3.1.conv_dw
blocks.3.1.bn2
blocks.3.1.act2
blocks.3.1.se
blocks.3.1.se.conv_reduce
blocks.3.1.se.act1
blocks.3.1.se.conv_expand
blocks.3.1.se.gate
blocks.3.1.conv_pwl
blocks.3.1.bn3
blocks.3.2
blocks.3.2.conv_pw
blocks.3.2.bn1
blocks.3.2.act1
blocks.3.2.conv_dw
blocks.3.2.bn2
blocks.3.2.act2
blocks.3.2.se
blocks.3.2.se.conv_reduce
blocks.3.2.se.act1
blocks.3.2.se.conv_expand
blocks.3.2.se.gate
blocks.3.2.conv_pwl
blocks.3.2.bn3
blocks.4
blocks.4.0
blocks.4.0.conv_pw
blocks.4.0.bn1
blocks.4.0.act1
blocks.4.0.conv_dw
blocks.4.0.bn2
blocks.4.0.act2
blocks.4.0.se
blocks.4.0.se.conv_reduce
blocks.4.0.se.act1
blocks.4.0.se.conv_expand
blocks.4.0.se.gate
blocks.4.0.conv_pwl
blocks.4.0.bn3
blocks.4.1
blocks.4.1.conv_pw
blocks.4.1.bn1
blocks.4.1.act1
blocks.4.1.conv_dw
blocks.4.1.bn2
blocks.4.1.act2
blocks.4.1.se
blocks.4.1.se.conv_reduce
blocks.4.1.se.act1
blocks.4.1.se.conv_expand
blocks.4.1.se.gate
blocks.4.1.conv_pwl
blocks.4.1.bn3
blocks.4.2
blocks.4.2.conv_pw
blocks.4.2.bn1
blocks.4.2.act1
blocks.4.2.conv_dw
blocks.4.2.bn2
blocks.4.2.act2
blocks.4.2.se
blocks.4.2.se.conv_reduce
blocks.4.2.se.act1
blocks.4.2.se.conv_expand
blocks.4.2.se.gate
blocks.4.2.conv_pwl
blocks.4.2.bn3
blocks.5
blocks.5.0
blocks.5.0.conv_pw
blocks.5.0.bn1
blocks.5.0.act1
blocks.5.0.conv_dw
blocks.5.0.bn2
blocks.5.0.act2
blocks.5.0.se
blocks.5.0.se.conv_reduce
blocks.5.0.se.act1
blocks.5.0.se.conv_expand
blocks.5.0.se.gate
blocks.5.0.conv_pwl
blocks.5.0.bn3
blocks.5.1
blocks.5.1.conv_pw
blocks.5.1.bn1
blocks.5.1.act1
blocks.5.1.conv_dw
blocks.5.1.bn2
blocks.5.1.act2
blocks.5.1.se
blocks.5.1.se.conv_reduce
blocks.5.1.se.act1
blocks.5.1.se.conv_expand
blocks.5.1.se.gate
blocks.5.1.conv_pwl
blocks.5.1.bn3
blocks.5.2
blocks.5.2.conv_pw
blocks.5.2.bn1
blocks.5.2.act1
blocks.5.2.conv_dw
blocks.5.2.bn2
blocks.5.2.act2
blocks.5.2.se
blocks.5.2.se.conv_reduce
blocks.5.2.se.act1
blocks.5.2.se.conv_expand
blocks.5.2.se.gate
blocks.5.2.conv_pwl
blocks.5.2.bn3
blocks.5.3
blocks.5.3.conv_pw
blocks.5.3.bn1
blocks.5.3.act1
blocks.5.3.conv_dw
blocks.5.3.bn2
blocks.5.3.act2
blocks.5.3.se
blocks.5.3.se.conv_reduce
blocks.5.3.se.act1
blocks.5.3.se.conv_expand
blocks.5.3.se.gate
blocks.5.3.conv_pwl
blocks.5.3.bn3
blocks.6
blocks.6.0
blocks.6.0.conv_pw
blocks.6.0.bn1
blocks.6.0.act1
blocks.6.0.conv_dw
blocks.6.0.bn2
blocks.6.0.act2
blocks.6.0.se
blocks.6.0.se.conv_reduce
blocks.6.0.se.act1
blocks.6.0.se.conv_expand
blocks.6.0.se.gate
blocks.6.0.conv_pwl
blocks.6.0.bn3
conv_head
bn2
act2
global_pool
global_pool.flatten
global_pool.pool
classifier
Date :04/20/2023, 14:09:36
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 60
learningrate: 0.001
weightdecay: 0.0
thrupsample: 50
model_name: tf_efficientnet_b0_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
19577
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Val loss: 1.3997
Best metric at: 0.9036
a1: 0.0011131166943540928
a2: 0.30232160930999574
a3: 0.6965652739956502
Val loss: 1.3837
Best metric at: 0.9046
a1: 0.1461415760181248
a2: 0.079568643671926
a3: 0.7742897803099492
Val loss: 1.3862
Best metric at: 0.9046
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.5329862577210289
Val loss: 1.3878
Best metric at: 0.9043
a1: 0.39340303201413257
a2: 0.32672084535187756
a3: 0.2798761226339898
Val loss: 1.3971
Best metric at: 0.9037
a1: 0.41558337474485857
a2: 0.40005175093013445
a3: 0.18436487432500703
Val loss: 1.3995
Best metric at: 0.9037
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.09788405064933436
Val loss: 1.3948
Best metric at: 0.9035
a1: 0.028086329672748975
a2: 0.6512626503833255
a3: 0.32065101994392553
Val loss: 1.3879
Best metric at: 0.9039
a1: 0.41371444954108855
a2: 0.3273902629320654
a3: 0.2588952875268461
Val loss: 1.3982
Best metric at: 0.9036
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.6892352650691428
Val loss: 1.3861
Best metric at: 0.9045
a1: 0.818825727204042
a2: 0.022656254747031326
a3: 0.15851801804892668
Val loss: 1.4235
Best metric at: 0.9029
a1: 0.009776086248847793
a2: 0.9770242230220217
a3: 0.013199690729130409
Val loss: 1.3949
Best metric at: 0.9031
a1: 0.005815216265836556
a2: 0.07928556065878622
a3: 0.9148992230753772
Val loss: 1.3839
Best metric at: 0.9046
a1: 0.024878223773343255
a2: 0.16443276040118682
a3: 0.8106890158254699
Val loss: 1.3839
Best metric at: 0.9047
a1: 0.6158783787068355
a2: 0.14575350922107183
a3: 0.23836811207209269
Val loss: 1.4086
Best metric at: 0.9032
a1: 0.21227229164308403
a2: 0.20014236730041798
a3: 0.587585341056498
Val loss: 1.3882
Best metric at: 0.9044
a1: 0.30882797842110765
a2: 0.20595013659163075
a3: 0.4852218849872616
Val loss: 1.3918
Best metric at: 0.9041
a1: 0.603813055278065
a2: 0.008621594784895215
a3: 0.38756534993703984
Val loss: 1.4064
Best metric at: 0.9036
a1: 0.08931590956749638
a2: 0.2458492164481382
a3: 0.6648348739843655
Val loss: 1.3851
Best metric at: 0.9045
a1: 0.07834238098948165
a2: 0.5119315988589438
a3: 0.40972602015157455
Val loss: 1.3871
Best metric at: 0.9042
a1: 0.28648156387757595
a2: 0.25034749233886633
a3: 0.4631709437835577
Val loss: 1.3912
Best metric at: 0.9040
a1: 0.0053223594274635355
a2: 0.12182516874343977
a3: 0.8728524718290968
Val loss: 1.3837
Best metric at: 0.9047
a1: 0.08923254748730641
a2: 0.13976449024050847
a3: 0.7710029622721852
Val loss: 1.3849
Best metric at: 0.9046
a1: 0.0030791912768876593
a2: 0.10351705278032015
a3: 0.8934037559427922
Val loss: 1.3837
Best metric at: 0.9047
a1: 0.13132822931131585
a2: 0.0942919969265213
a3: 0.7743797737621629
Val loss: 1.3858
Best metric at: 0.9046
a1: 0.2319983188313238
a2: 0.1120724530823474
a3: 0.6559292280863288
Date :04/28/2023, 01:48:41
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Date :04/28/2023, 01:49:08
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
13830
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Date :04/28/2023, 01:50:02
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
13830
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Best metric at: 0.9981
a1: 0.0011131166943540928
a2: 0.30232160930999574
a3: 0.6965652739956502
Date :04/28/2023, 01:53:38
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
13839
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Best metric at: 0.8082
a1: 0.0011131166943540928
a2: 0.30232160930999574
a3: 0.6965652739956502
Best metric at: 0.8080
a1: 0.1461415760181248
a2: 0.079568643671926
a3: 0.7742897803099492
Best metric at: 0.8077
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.5329862577210289
Best metric at: 0.8082
a1: 0.39340303201413257
a2: 0.32672084535187756
a3: 0.2798761226339898
Best metric at: 0.8083
a1: 0.41558337474485857
a2: 0.40005175093013445
a3: 0.18436487432500703
Best metric at: 0.8083
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.09788405064933436
Date :04/28/2023, 02:11:23
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
Date :04/28/2023, 02:13:39
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Best metric at: 0.8081268
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
Best metric at: 0.8073981
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
Best metric at: 0.8075904
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
Best metric at: 0.8081816
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.0010230441271738824
a4: 0.09686100652216048
Best metric at: 0.8076516
a1: 0.6640923675664397
a2: 0.14028298904179887
a3: 0.018145055328930255
a4: 0.17747958806283112
Best metric at: 0.8080408
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.18330951110581858
a4: 0.5059257539633242
Best metric at: 0.8076898
a1: 0.9586106983864842
a2: 0.013276901904298664
a3: 0.009509026216147827
a4: 0.01860337349306935
Date :04/28/2023, 02:34:01
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Val cmap: 0.8081608
Date :04/28/2023, 02:40:22
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Date :04/28/2023, 02:40:55
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
Val cmap: 0.8081608
a1: 0.0011131166943540928
a2: 0.30232160930999574
a3: 0.6965652739956502
Val cmap: 0.8077651
a1: 0.1461415760181248
a2: 0.079568643671926
a3: 0.7742897803099492
Val cmap: 0.8077515
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.5329862577210289
Val cmap: 0.8082292
a1: 0.39340303201413257
a2: 0.32672084535187756
a3: 0.2798761226339898
Val cmap: 0.8084176
a1: 0.41558337474485857
a2: 0.40005175093013445
a3: 0.18436487432500703
Val cmap: 0.8082371
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.09788405064933436
Val cmap: 0.8079384
a1: 0.028086329672748975
a2: 0.6512626503833255
a3: 0.32065101994392553
Val cmap: 0.8078833
a1: 0.41371444954108855
a2: 0.3273902629320654
a3: 0.2588952875268461
Val cmap: 0.8083923
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.6892352650691428
Val cmap: 0.8081028
a1: 0.818825727204042
a2: 0.022656254747031326
a3: 0.15851801804892668
Val cmap: 0.8075438
a1: 0.6064027814315271
a2: 0.24610446455278778
a3: 0.14749275401568507
Val cmap: 0.8081018
a1: 0.573435998924321
a2: 0.18477854159651486
a3: 0.2417854594791642
Val cmap: 0.8080777
a1: 0.3760787961778391
a2: 0.3937050102785273
a3: 0.2302161935436336
Val cmap: 0.8083472
a1: 0.7321559319881465
a2: 0.008736101096801424
a3: 0.259107966915052
Val cmap: 0.8077304
a1: 0.9865107677786839
a2: 0.6171210684649691
a3: -0.6036318362436529
Val cmap: 0.8051993
a1: 0.30882797842110765
a2: 0.5048094336139191
a3: 0.1863625879649733
Val cmap: 0.8082223
a1: 0.5024266320562268
a2: 0.3162824469752265
a3: 0.18129092096854665
Val cmap: 0.8083196
a1: 0.29990159686554707
a2: 0.5080645107215854
a3: 0.1920338924128675
Val cmap: 0.8082172
a1: 0.5113598948009357
a2: 0.21386313156159856
a3: 0.2747769736374658
Val cmap: 0.8081879
a1: 0.3030724463345107
a2: 0.3304741637986349
a3: 0.3664533898668544
Val cmap: 0.8082684
a1: 0.43473465568346525
a2: 0.3583717941477761
a3: 0.20689355016875866
Val cmap: 0.8083097
a1: 0.36424521834772094
a2: 0.38018908473006324
a3: 0.2555656969222158
Val cmap: 0.8083624
a1: 0.3237414994387427
a2: 0.272097003025349
a3: 0.40416149753590835
Val cmap: 0.8083145
a1: 0.4879647674609903
a2: 0.33262421747977666
a3: 0.17941101505923296
Val cmap: 0.8082860
a1: 0.2616734297241315
a2: 0.44163655571303795
a3: 0.2966900145628306
Val cmap: 0.8082992
a1: 0.4017420121042397
a2: 0.3618753366518758
a3: 0.23638265124388452
Val cmap: 0.8083285
a1: 0.3728675175939209
a2: 0.24644903699461912
a3: 0.38068344541146
Val cmap: 0.8083596
a1: 0.2284921928107781
a2: 0.4707794204919336
a3: 0.30072838669728824
Val cmap: 0.8082437
a1: 0.35612950674822524
a2: 0.40735084205030525
a3: 0.23651965120146945
Val cmap: 0.8083316
a1: 0.463105003728117
a2: 0.3023558726185125
a3: 0.23453912365337048
Val cmap: 0.8082622
a1: 0.382049555133493
a2: 0.23584702084493717
a3: 0.3821034240215698
Val cmap: 0.8083267
a1: 0.3655416459939759
a2: 0.36342802598854923
a3: 0.2710303280174748
Val cmap: 0.8084032
a1: 0.4246284319681163
a2: 0.3640241959421033
a3: 0.21134737208978044
Val cmap: 0.8082884
a1: 0.2689251074735626
a2: 0.42343507072705655
a3: 0.3076398217993809
Val cmap: 0.8083611
a1: 0.36065913491544677
a2: 0.28475304735514434
a3: 0.3545878177294089
Val cmap: 0.8083038
a1: 0.47663920126386194
a2: 0.3040821231926055
a3: 0.21927867554353253
Val cmap: 0.8083258
a1: 0.23452551877234498
a2: 0.373564506687382
a3: 0.39190997454027304
Val cmap: 0.8083372
a1: 0.16700507170343842
a2: 0.17342747832036334
a3: 0.6595674499761983
Val cmap: 0.8081117
a1: 0.4346829671175167
a2: 0.34837321680924555
a3: 0.2169438160732377
Val cmap: 0.8082641
a1: 0.5501234409008035
a2: 0.3309818199910483
a3: 0.11889473910814824
Val cmap: 0.8082567
a1: 0.25077746183399324
a2: 0.4181409433452865
a3: 0.3310815948207202
Val cmap: 0.8083405
a1: 0.33447948708536973
a2: 0.3885946142224004
a3: 0.27692589869222983
Val cmap: 0.8083877
a1: 0.3482400348971018
a2: 0.390627160572651
a3: 0.26113280453024723
Val cmap: 0.8083908
a1: 0.3353131613910149
a2: 0.29361136872309346
a3: 0.3710754698858916
Val cmap: 0.8083157
a1: 0.41701323011523556
a2: 0.3225343850287775
a3: 0.2604523848559869
Val cmap: 0.8083832
a1: 0.13975583938557162
a2: 0.45975323267986656
a3: 0.40049092793456187
Val cmap: 0.8082227
a1: 0.313160390981983
a2: 0.384489255263813
a3: 0.302350353754204
Val cmap: 0.8083342
a1: 0.20076269793518903
a2: 0.4863836209637311
a3: 0.3128536811010798
Val cmap: 0.8082512
a1: 0.4458400950303443
a2: 0.3898224804872727
a3: 0.16433742448238303
Val cmap: 0.8081821
a1: 0.40596643881457134
a2: 0.34201935221767404
a3: 0.25201420896775456
Val cmap: 0.8083769
a1: 0.4003982191107982
a2: 0.3181920592566707
a3: 0.2814097216325311
Val cmap: 0.8083097
a1: 0.5254741710401216
a2: 0.34982234823004305
a3: 0.12470348072983534
Val cmap: 0.8082346
a1: 0.4617650472473718
a2: 0.3255207850362067
a3: 0.21271416771642154
Val cmap: 0.8082877
a1: 0.27972487451442185
a2: 0.27170521460444474
a3: 0.4485699108811334
Val cmap: 0.8083836
a1: 0.28310528938305457
a2: 0.28004423621565466
a3: 0.43685047440129077
Val cmap: 0.8083191
a1: 0.3315372774140851
a2: 0.26512795604744965
a3: 0.40333476653846523
Val cmap: 0.8083224
a1: 0.3532734921438654
a2: 0.39917378867474673
a3: 0.24755271918138788
Val cmap: 0.8083452
a1: 0.3013416321488255
a2: 0.21202298367031447
a3: 0.48663538418086005
Val cmap: 0.8083362
a1: 0.282896098877499
a2: 0.4356661427528663
a3: 0.2814377583696347
Val cmap: 0.8083011
a1: 0.3867531805235319
a2: 0.36378996562687066
a3: 0.24945685384959743
Val cmap: 0.8083363
a1: 0.4169309652210315
a2: 0.30719292771613516
a3: 0.2758761070628333
Val cmap: 0.8083429
a1: 0.3577647917236461
a2: 0.3415789872587435
a3: 0.3006562210176103
Val cmap: 0.8084213
a1: 0.327377387350801
a2: 0.3829303159442674
a3: 0.2896922967049316
Val cmap: 0.8083576
a1: 0.35586754816217464
a2: 0.34627354622988293
a3: 0.29785890560794237
Val cmap: 0.8084218
a1: 0.35644827237682575
a2: 0.34627236464965333
a3: 0.2972793629735209
Val cmap: 0.8084285
a1: 0.4548751475691005
a2: 0.34507651433015185
a3: 0.20004833810074762
Val cmap: 0.8082922
a1: 0.3950105588607504
a2: 0.35043212722495654
a3: 0.25455731391429304
Val cmap: 0.8083588
a1: 0.36714563740351736
a2: 0.40395486354463817
a3: 0.22889949905184448
Val cmap: 0.8083230
a1: 0.48613692808299147
a2: 0.36657422411008606
a3: 0.14728884780692247
Val cmap: 0.8082561
a1: 0.4465532505392071
a2: 0.33493594249725495
a3: 0.21851080696353792
Val cmap: 0.8083279
a1: 0.3391543528618671
a2: 0.3765190266430943
a3: 0.2843266204950386
Val cmap: 0.8084141
a1: 0.35258973996458015
a2: 0.3086234973920578
a3: 0.3387867626433621
Val cmap: 0.8083140
a1: 0.3843526518534506
a2: 0.3593190445432949
a3: 0.25632830360325454
Val cmap: 0.8084036
a1: 0.39904716975840293
a2: 0.36383956687814967
a3: 0.2371132633634474
Val cmap: 0.8083315
a1: 0.3809541734056953
a2: 0.3151618482263054
a3: 0.30388397836799924
Val cmap: 0.8083387
a1: 0.3123493314756662
a2: 0.2923018767040473
a3: 0.3953487918202865
Val cmap: 0.8083379
a1: 0.428037295526496
a2: 0.3352517926662776
a3: 0.23671091180722648
Val cmap: 0.8083593
a1: 0.3810659370455272
a2: 0.37177522761746534
a3: 0.2471588353370075
Val cmap: 0.8083512
a1: 0.481010139801167
a2: 0.35553726708684613
a3: 0.16345259311198684
Date :04/28/2023, 06:19:09
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Val cmap: 0.8081268
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
Val cmap: 0.8073981
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
Val cmap: 0.8075904
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
Val cmap: 0.8081816
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.0010230441271738824
a4: 0.09686100652216048
Val cmap: 0.8076516
a1: 0.6640923675664397
a2: 0.14028298904179887
a3: 0.018145055328930255
a4: 0.17747958806283112
Val cmap: 0.8080408
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.18330951110581858
a4: 0.5059257539633242
Val cmap: 0.8076898
a1: 0.9586106983864842
a2: 0.013276901904298664
a3: 0.009509026216147827
a4: 0.01860337349306935
Val cmap: 0.8071933
a1: 0.8677488716207818
a2: 0.117512988043294
a3: 0.0011347706749306656
a4: 0.013603369660993481
Val cmap: 0.8074560
a1: 0.039625180617320656
a2: 0.16367818071783483
a3: 0.348091804863963
a4: 0.4486048338008815
Date :04/28/2023, 06:44:43
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.5865652373491543
Val cmap: 0.8080032
a1: 0.7134009240142943
a2: 0.28659907598570566
Val cmap: 0.8077441
a1: 0.0011131166943540928
a2: 0.9988868833056459
Val cmap: 0.8067726
a1: 0.3000069143328895
a2: 0.6999930856671105
Val cmap: 0.8078669
a1: 0.1461415760181248
a2: 0.8538584239818752
Val cmap: 0.8074756
a1: 0.09232287022634102
a2: 0.907677129773659
Val cmap: 0.8072471
a1: 0.18521134905251652
a2: 0.8147886509474835
Date :05/15/2023, 22:23:12
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
Date :05/15/2023, 22:23:27
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
Date :05/15/2023, 22:24:06
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Date :05/15/2023, 22:24:27
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Date :05/15/2023, 22:25:00
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Date :05/15/2023, 22:26:10
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Val cmap: 0.8098948
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
Date :05/15/2023, 22:33:48
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
Date :05/15/2023, 22:34:02
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
Date :05/15/2023, 22:34:25
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.5991671594562349
a2: 0.21699623949333136
a3: 0.13671576610598835
a4: 0.04712083494444541
time: 0.0000
Date :05/15/2023, 22:35:10
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.18164341303499953
a2: 0.07782665868049075
a3: 0.0010786067499180291
a4: 0.7394513215345917
Date :05/15/2023, 22:35:39
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.1469804442813717
a2: 0.07519747650083451
a3: 0.0021838939391287805
a4: 0.775638185278665
time: 355.1438
Val cmap: 0.8098350
a1: 0.47722510759494774
a2: 0.5187452375506482
a3: 0.002076859891568781
a4: 0.0019527949628353157
time: 406.7059
Val cmap: 0.8100861
a1: 0.1161460401828281
a2: 0.0017367152510394045
a3: 0.038017675212723624
a4: 0.8440995693534089
time: 415.0082
Val cmap: 0.8097148
a1: 0.834594214116995
a2: 0.02272367474941524
a3: 0.0019121921460696534
a4: 0.14076991898752012
time: 406.8442
Val cmap: 0.8101850
a1: 0.3109750031176998
a2: 0.21817678534493185
a3: 0.01537975751952042
a4: 0.45546845401784786
time: 415.3320
Val cmap: 0.8101348
a1: 0.013406612219347486
a2: 0.7444342524176044
a3: 0.0010878939700066715
a4: 0.24107124139304145
time: 408.1732
Val cmap: 0.8099257
a1: 0.2594401270603586
a2: 0.3610568085776919
a3: 0.0013547773696926996
a4: 0.37814828699225683
time: 404.2616
Val cmap: 0.8100461
a1: 0.9566112069369568
a2: 0.03574128201874301
a3: 0.0009061970771437856
a4: 0.00674131396715642
time: 411.6642
Val cmap: 0.8100634
a1: 0.193766149991476
a2: 0.6971277139641268
a3: 0.0024906942204091166
a4: 0.1066154418239881
time: 420.1133
Val cmap: 0.8100627
a1: 0.8596022214203706
a2: 0.039734446043295436
a3: 0.005866311600712886
a4: 0.09479702093562112
time: 404.4708
Val cmap: 0.8101395
a1: 0.7382017609880211
a2: 0.001828313515558344
a3: 0.10225832271026519
a4: 0.1577116027861553
time: 413.1416
Val cmap: 0.8101096
a1: 0.8393891491609993
a2: 0.02532553106748415
a3: 0.0054568347736032455
a4: 0.12982848499791333
time: 413.2671
Val cmap: 0.8102195
a1: 0.6992611950594377
a2: 0.08235800089380987
a3: 0.005378257763060938
a4: 0.21300254628369145
time: 416.8773
Val cmap: 0.8101102
a1: 0.9861912869720209
a2: 0.0039359753847084365
a3: 0.001417127759309904
a4: 0.008455609883960807
time: 413.1820
Val cmap: 0.8100350
a1: 0.7188802499650041
a2: 0.06927797185815972
a3: 0.005343119963808759
a4: 0.20649865821302743
time: 414.2981
Val cmap: 0.8100802
a1: 0.5814660604203046
a2: 0.13607901451163085
a3: 0.009438450567218943
a4: 0.27301647450084565
time: 410.1744
Val cmap: 0.8101645
a1: 0.836491730146787
a2: 0.023249188153229988
a3: 0.002603822205557693
a4: 0.1376552594944253
time: 415.3607
Val cmap: 0.8101682
a1: 0.5585455313408849
a2: 0.12003180212252108
a3: 0.01974603703738661
a4: 0.3016766294992074
time: 411.8703
Val cmap: 0.8101781
a1: 0.8565191915957986
a2: 0.01597387759428992
a3: 0.003759897831855804
a4: 0.12374703297805568
time: 416.2672
Val cmap: 0.8101691
a1: 0.9225877935070828
a2: 0.014765309967960523
a3: 0.0036544556425018877
a4: 0.05899244088245484
time: 418.9213
Val cmap: 0.8101121
a1: 0.7880414329056887
a2: 0.0376685066060924
a3: 0.00714872778020977
a4: 0.1671413327080091
time: 417.9386
Val cmap: 0.8101420
a1: 0.6099696005469601
a2: 0.10995147864829187
a3: 0.013014363375798659
a4: 0.26706455742894936
time: 413.8327
Val cmap: 0.8101560
a1: 0.4412479925211691
a2: 0.15209460511936684
a3: 0.035158240726940605
a4: 0.37149916163252344
time: 405.7703
Val cmap: 0.8101464
a1: 0.6352861988737767
a2: 0.059875762515202886
a3: 0.021262575525904142
a4: 0.2835754630851163
time: 417.6042
Val cmap: 0.8101648
a1: 0.7861273479477883
a2: 0.05211970840315987
a3: 0.009040567461737911
a4: 0.15271237618731393
time: 416.8036
Val cmap: 0.8101568
a1: 0.5589153450550765
a2: 0.10342875371374582
a3: 0.0037979902056413132
a4: 0.3338579110255364
time: 403.7243
Val cmap: 0.8101906
a1: 0.6854148645373909
a2: 0.09381503581285348
a3: 0.004044247290091131
a4: 0.21672585235966452
time: 407.5523
Val cmap: 0.8101306
a1: 0.8997599146218975
a2: 0.027971383635344297
a3: 0.0016580402817193548
a4: 0.07061066146103882
time: 304.4416
Val cmap: 0.8101452
a1: 0.7824321183353298
a2: 0.050771690331360336
a3: 0.0031721825080371973
a4: 0.1636240088252727
time: 286.7604
Val cmap: 0.8101341
a1: 0.9104187734022617
a2: 0.012000998160536036
a3: 0.0018834188458781013
a4: 0.07569680959132412
time: 287.8430
Val cmap: 0.8101327
a1: 0.5442322219329412
a2: 0.08240065240363106
a3: 0.003069088930454823
a4: 0.37029803673297296
time: 288.7790
Val cmap: 0.8101813
a1: 0.5222043453345164
a2: 0.08250157967752869
a3: 0.002600405163062138
a4: 0.39269366982489273
time: 292.1378
Val cmap: 0.8102335
a1: 0.4742405227437743
a2: 0.15008337614279588
a3: 0.0018671177243214146
a4: 0.37380898338910845
time: 297.0545
Val cmap: 0.8101190
a1: 0.41426766905233625
a2: 0.17212969498509262
a3: 0.0025022930916325163
a4: 0.4111003428709386
time: 367.9066
Val cmap: 0.8101460
a1: 0.6367790946797303
a2: 0.06897760030530613
a3: 0.004026042900140582
a4: 0.290217262114823
time: 444.5101
Val cmap: 0.8101782
a1: 0.5140250273325813
a2: 0.10366760250343565
a3: 0.0012780907309458262
a4: 0.38102927943303727
time: 439.8720
Val cmap: 0.8102276
a1: 0.5099021122708303
a2: 0.10500843531897394
a3: 0.001185424694618862
a4: 0.3839040277155769
time: 405.2408
Val cmap: 0.8101973
a1: 0.38306277177635345
a2: 0.2464387943062234
a3: 0.001159407248658103
a4: 0.369339026668765
time: 401.9116
Val cmap: 0.8101419
a1: 0.3542827308000247
a2: 0.20978069879612327
a3: 0.0009291740393106901
a4: 0.43500739636454133
time: 385.4639
Val cmap: 0.8101810
a1: 0.4911087219777661
a2: 0.11721752886298606
a3: 0.0015240058542802886
a4: 0.3901497433049675
time: 358.5145
Val cmap: 0.8101480
a1: 0.5233698896727323
a2: 0.08810169518804871
a3: 0.0013015201422458182
a4: 0.3872268949969731
time: 412.6697
Val cmap: 0.8102381
a1: 0.47822440418355966
a2: 0.09126354161923869
a3: 0.0014508226084414381
a4: 0.4290612315887602
time: 409.4929
Val cmap: 0.8101172
a1: 0.5293516439175895
a2: 0.0774044226552982
a3: 0.0011762180111373544
a4: 0.3920677154159749
time: 407.6551
Val cmap: 0.8102582
a1: 0.5279050940267221
a2: 0.06490644888701372
a3: 0.002158637989170194
a4: 0.40502981909709396
time: 410.3771
Val cmap: 0.8102209
a1: 0.5198116008581546
a2: 0.06582359735933879
a3: 0.0009000146870446117
a4: 0.413464787095462
time: 410.8473
Val cmap: 0.8101742
a1: 0.4481907511786171
a2: 0.17221701102424664
a3: 0.0021029094891758214
a4: 0.3774893283079604
time: 408.7402
Val cmap: 0.8101315
a1: 0.5191408613464233
a2: 0.07519790534555122
a3: 0.0012037659824080803
a4: 0.4044574673256174
time: 406.8348
Val cmap: 0.8101673
a1: 0.5788687351508649
a2: 0.04344528716687687
a3: 0.0023283646196151676
a4: 0.37535761306264304
time: 414.5297
Val cmap: 0.8101061
a1: 0.4068690314727981
a2: 0.13222450595734384
a3: 0.0019115869175748324
a4: 0.4589948756522833
time: 415.2069
Val cmap: 0.8101649
a1: 0.35623311338496777
a2: 0.18632398803489397
a3: 0.0013735024504022114
a4: 0.45606939612973607
time: 415.3377
Val cmap: 0.8101618
a1: 0.6012757615156704
a2: 0.0803813783854675
a3: 0.0010602230660530028
a4: 0.31728263703280907
time: 399.1935
Val cmap: 0.8101472
a1: 0.6727483656627533
a2: 0.06167454252505412
a3: 0.0015656724015051732
a4: 0.2640114194106874
time: 407.5570
Val cmap: 0.8101356
a1: 0.5433421520125166
a2: 0.045090430241767496
a3: 0.0021710629955953333
a4: 0.4093963547501206
time: 416.8282
Val cmap: 0.8102351
a1: 0.5347911997906185
a2: 0.039138951385187165
a3: 0.0026010597201490218
a4: 0.4234687891040453
time: 406.5352
Val cmap: 0.8101579
a1: 0.4643660741878648
a2: 0.12441772523301595
a3: 0.0018796483777066483
a4: 0.4093365522014126
time: 405.1048
Val cmap: 0.8101211
a1: 0.5023904800838999
a2: 0.09470304989682944
a3: 0.001189929805513446
a4: 0.40171654021375724
time: 405.8945
Val cmap: 0.8101373
a1: 0.5439678643165694
a2: 0.05296688513052047
a3: 0.0021769886042652493
a4: 0.4008882619486449
time: 410.1489
Val cmap: 0.8102189
a1: 0.5877997480713479
a2: 0.08309250558383012
a3: 0.0016121746575533955
a4: 0.3274955716872685
time: 411.2314
Val cmap: 0.8101519
a1: 0.6328858589759448
a2: 0.06709642240284788
a3: 0.0029382208967870718
a4: 0.2970794977244202
time: 405.1807
Val cmap: 0.8101717
a1: 0.44006748982437416
a2: 0.00681034245656751
a3: 0.0009445390537414936
a4: 0.5521776286653168
time: 403.9113
Val cmap: 0.8101222
a1: 0.5692772794462886
a2: 0.03083115889259374
a3: 0.001321608407355972
a4: 0.3985699532537617
time: 409.1658
Val cmap: 0.8102226
a1: 0.5622731620946073
a2: 0.029707875286514855
a3: 0.00130930200199451
a4: 0.4067096606168833
time: 405.5353
Val cmap: 0.8102160
a1: 0.49686895128941155
a2: 0.1051916186738401
a3: 0.0016743606366978693
a4: 0.3962650694000505
time: 384.3475
Val cmap: 0.8101322
a1: 0.6116787462619706
a2: 0.04705687119393012
a3: 0.0021729659592056327
a4: 0.33909141658489367
time: 325.6224
Val cmap: 0.8101174
a1: 0.5682169130760327
a2: 0.024746013617077012
a3: 0.0010642797805993575
a4: 0.4059727935262909
time: 421.2936
Val cmap: 0.8102210
a1: 0.5794078724803989
a2: 0.022233152440153336
a3: 0.001036532826817102
a4: 0.39732244225263064
time: 409.0745
Val cmap: 0.8102209
a1: 0.557104893896749
a2: 0.033570048843632974
a3: 0.001305248119706406
a4: 0.40801980913991165
Date :05/16/2023, 06:13:20
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Date :05/16/2023, 06:14:12
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.8064980382195703
a2: 0.08706545884239182
a3: 0.02067178518636001
a4: 0.08576471775167784
time: 264.1821
Val cmap: 0.8149543
a1: 0.2129544008216183
a2: 0.45412852660253955
a3: 0.05398341743540929
a4: 0.27893365514043283
Date :05/16/2023, 06:22:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.38142513353205
a2: 0.4461381308182054
a3: 0.0067694727454003095
a4: 0.1656672629043443
time: 269.8210
Val cmap: 0.8150600
a1: 0.8684249041247577
a2: 0.008360213099619365
a3: 0.001902704476545267
a4: 0.12131217829907767
time: 266.1394
Val cmap: 0.8150980
a1: 0.9579318001917813
a2: 0.0038638850336644767
a3: 0.009561729614214835
a4: 0.028642585160339427
time: 264.8193
Val cmap: 0.8149710
a1: 0.16419119805068844
a2: 0.16199125408037468
a3: 0.054200426356918616
a4: 0.6196171215120182
time: 272.9717
Val cmap: 0.8147836
a1: 0.5937246356680904
a2: 0.1378659988232148
a3: 0.15712204035106303
a4: 0.11128732515763173
time: 262.7523
Val cmap: 0.8150115
a1: 0.47808843068588436
a2: 0.1578578211240553
a3: 0.047891316036473335
a4: 0.31616243215358697
time: 260.8143
Val cmap: 0.8149402
a1: 0.9001886500694407
a2: 0.06186676076844555
a3: 0.018725054903235734
a4: 0.019219534258878006
time: 274.5136
Val cmap: 0.8150110
a1: 0.39212074442283124
a2: 0.27037676584823184
a3: 0.3250991862896087
a4: 0.012403303439328273
time: 260.1545
Val cmap: 0.8149496
a1: 0.8803627934872306
a2: 0.018432679264694152
a3: 0.035752663436761825
a4: 0.06545186381131346
time: 259.9277
Val cmap: 0.8150317
a1: 0.5269483686244755
a2: 0.1561632504809505
a3: 0.01892526454669891
a4: 0.29796311634787515
time: 257.9801
Val cmap: 0.8150422
a1: 0.734028227667008
a2: 0.060285846150421
a3: 0.001335766726102909
a4: 0.20435015945646806
time: 256.7591
Val cmap: 0.8149688
a1: 0.26465225085130945
a2: 0.49484184432732825
a3: 0.0034547425500665767
a4: 0.23705116227129577
time: 260.6986
Val cmap: 0.8149587
a1: 0.00994236730059811
a2: 0.898226034516596
a3: 0.0029405105180210387
a4: 0.08889108766478492
time: 263.3352
Val cmap: 0.8145970
a1: 0.6951711408826355
a2: 0.0039012786559413093
a3: 0.0010398811465819212
a4: 0.2998876993148412
time: 254.9661
Val cmap: 0.8149600
a1: 0.37756757836787563
a2: 0.3796314233482439
a3: 0.00566231185552234
a4: 0.23713868642835817
time: 259.0150
Val cmap: 0.8149246
a1: 0.7776069321620602
a2: 0.06412064082647104
a3: 0.0020232066963861476
a4: 0.1562492203150826
time: 262.4266
Val cmap: 0.8150641
a1: 0.7627188320464596
a2: 0.03625170874543263
a3: 0.0017440312686004948
a4: 0.19928542793950726
time: 257.7520
Val cmap: 0.8149922
a1: 0.824979195522998
a2: 0.026477336036364985
a3: 0.0021553749512172823
a4: 0.1463880934894197
time: 258.5784
Val cmap: 0.8151030
a1: 0.944269807596552
a2: 0.00115585548931171
a3: 0.0010422393283283351
a4: 0.05353209758580796
time: 262.8534
Val cmap: 0.8149662
a1: 0.8361501142910162
a2: 0.02659293489062413
a3: 0.0031251457858935392
a4: 0.13413180503246616
time: 257.2814
Val cmap: 0.8150870
a1: 0.9789125662384888
a2: 0.00690955326071185
a3: 0.0020402794559683394
a4: 0.012137601044831043
time: 255.2434
Val cmap: 0.8149490
a1: 0.8337458437288754
a2: 0.024638180235334893
a3: 0.003590020716379059
a4: 0.13802595531941064
Date :05/16/2023, 08:31:36
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.3352170925163992
a2: 0.16232200329789936
a3: 0.5024609041857014
time: 265.8556
Val cmap: 0.8146123
a1: 0.5053735926907296
a2: 0.12164658069705088
a3: 0.37297982661221957
time: 271.8975
Val cmap: 0.8150273
a1: 0.1332692971445244
a2: 0.581294520944652
a3: 0.28543618191082365
time: 267.5143
Val cmap: 0.8149382
a1: 0.42301093442383103
a2: 0.33522327670565605
a3: 0.24176578887051287
time: 261.8565
Val cmap: 0.8152356
a1: 0.6866493462921237
a2: 0.16930046782336267
a3: 0.14405018588451363
time: 262.0813
Val cmap: 0.8151764
a1: 0.9328823240860998
a2: 0.031186025227533755
a3: 0.03593165068636641
time: 264.0008
Val cmap: 0.8150448
a1: 0.51743727205514
a2: 0.09505895577757248
a3: 0.3875037721672875
time: 275.5582
Val cmap: 0.8149858
a1: 0.09351647625823285
a2: 0.39829661515183234
a3: 0.5081869085899348
time: 257.4677
Val cmap: 0.8145613
a1: 0.631410499869833
a2: 0.14751911969153833
a3: 0.22107038043862867
time: 262.5048
Val cmap: 0.8151112
a1: 0.7932773774231918
a2: 0.11775360098272108
a3: 0.0889690215940871
time: 261.1355
Val cmap: 0.8150338
a1: 0.3341902136985
a2: 0.28565762520730587
a3: 0.38015216109419414
time: 258.8717
Val cmap: 0.8149906
a1: 0.7055908632533898
a2: 0.019759675466936383
a3: 0.2746494612796738
time: 263.0993
Val cmap: 0.8151049
a1: 0.9549516986324471
a2: 0.006205050300124474
a3: 0.03884325106742842
time: 261.5946
Val cmap: 0.8150483
a1: 0.6517447442300854
a2: 0.21077585165906892
a3: 0.13747940411084564
time: 270.4683
Val cmap: 0.8152163
a1: 0.37879276905823567
a2: 0.29693674932505193
a3: 0.3242704816167124
time: 262.0684
Val cmap: 0.8151915
a1: 0.537270555752322
a2: 0.24826575200677414
a3: 0.2144636922409039
time: 268.0363
Val cmap: 0.8151310
a1: 0.4115668975137846
a2: 0.37000040399542045
a3: 0.21843269849079494
time: 261.8622
Val cmap: 0.8151909
a1: 0.18012159466064986
a2: 0.5610818559508712
a3: 0.25879654938847896
time: 260.7773
Val cmap: 0.8149998
a1: 0.0029819574018332684
a2: 0.6876994512229795
a3: 0.30931859137518725
time: 263.3438
Val cmap: 0.8147864
a1: 0.6096809419051304
a2: 0.2002715395323959
a3: 0.19004751856247365
time: 271.1401
Val cmap: 0.8151170
a1: 0.2325690394429129
a2: 0.3657881873055933
a3: 0.4016427732514937
time: 264.6176
Val cmap: 0.8147428
a1: 0.41011368171737045
a2: 0.249852866094944
a3: 0.3400334521876855
time: 267.0346
Val cmap: 0.8151316
a1: 0.4431456914210973
a2: 0.32055935517080447
a3: 0.23629495340809825
time: 267.4199
Val cmap: 0.8152217
a1: 0.45874873353682083
a2: 0.3218186103350814
a3: 0.2194326561280978
time: 265.8257
Val cmap: 0.8152447
a1: 0.4554202314534655
a2: 0.3161335055514213
a3: 0.22844626299511328
time: 271.7694
Val cmap: 0.8152230
a1: 0.2960338670174919
a2: 0.4064641275558204
a3: 0.2975020054266877
time: 277.3573
Val cmap: 0.8150925
a1: 0.47706181477449466
a2: 0.3257859154984452
a3: 0.19715226972706007
time: 262.3029
Val cmap: 0.8151641
a1: 0.2753267535125633
a2: 0.47793755522678216
a3: 0.24673569126065453
time: 264.6197
Val cmap: 0.8150756
a1: 0.5784199952055346
a2: 0.2570159658005262
a3: 0.16456403899393923
time: 271.4560
Val cmap: 0.8151443
a1: 0.4609429267771212
a2: 0.3219618346011115
a3: 0.21709523862176727
time: 259.7638
Val cmap: 0.8152396
a1: 0.34602343397710156
a2: 0.352672828302912
a3: 0.3013037377199864
Date :05/19/2023, 08:38:54
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a1: 0.8389315783467116
a2: 0.03425939040945279
a3: 0.12680903124383558
time: 271.2013
Val cmap: 0.8186780
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a1: 0.8198211929182605
a2: 0.09646788065142907
a3: 0.08371092643031043
time: 263.2553
Val cmap: 0.8184568
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a1: 0.5472118244452256
a2: 0.35075722935652126
a3: 0.10203094619825309
time: 266.4342
Val cmap: 0.8184483
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a1: 0.5011194296504629
a2: 0.48435038032372174
a3: 0.014530190025815404
time: 269.9951
Val cmap: 0.8183550
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a1: 0.33468392459621454
a2: 0.35430552291476547
a3: 0.31101055248902
Date :05/19/2023, 08:59:18
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.9040041216211572
a2: 0.05283647194580379
a3: 0.023232857734290017
a4: 0.007923787226325748
a4: 0.004804162278017393
a4: 0.007198599194405875
time: 264.5817
Val cmap: 0.8186198
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.7483564672128773
a2: 0.00860492287979633
a3: 0.132902085099826
a4: 0.107282283494239
a4: 0.0001811092044565822
a4: 0.0026731321088047724
time: 271.6667
Val cmap: 0.2191463
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.2893425085340508
a2: 0.5769103063153395
a3: 0.09949184506107184
a4: 0.003818803460920623
a4: 0.007626730945763394
a4: 0.022809805682853828
Date :05/19/2023, 09:11:36
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.7789783178583912
a2: 0.019335669653118115
a3: 0.17848394371103415
a4: 0.004003244105554634
a4: 0.0008235824002027392
a4: 0.018375242271699135
time: 265.4052
Val cmap: 0.8127174
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.8112733819655307
a2: 0.13699939386084464
a3: 0.03055787795204665
a4: 0.010007254185315114
a4: 0.0001597090707930066
a4: 0.011002382965469916
time: 265.1965
Val cmap: 0.8171296
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.2622677874401985
a2: 0.5512864548772092
a3: 0.04163220753516595
a4: 0.003205204335658184
a4: 0.013789467560035228
a4: 0.12781887825173294
Date :05/19/2023, 09:21:46
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a1: 0.8471745103161712
a2: 0.026014007608561172
a3: 0.01428345517564199
a4: 0.07586074052651706
a5: 0.00037906454417119755
a6: 0.03628822182893738
Date :05/19/2023, 09:22:55
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7602327248729647
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.09512959788965854
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.03156169188410945
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.014100397139168061
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.013439722241833684
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.08553586597226562
time: 263.9517
Val cmap: 0.8184777
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8253297094184994
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05143994904406601
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0024424422580221787
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.11721423696530378
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.002047704833011049
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.001525957481097609
time: 266.4332
Val cmap: 0.8182062
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7474739084813344
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.17117985330154728
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.004846671120882876
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0461595577336176
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0003744248196141531
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.029965584543003652
time: 263.2766
Val cmap: 0.8182328
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.337078030768525
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.26101621441010875
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.05232808374619526
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.346355918489455
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0006354825175052543
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.002586270068210666
time: 261.4903
Val cmap: 0.8180474
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8903531167970451
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.033709862183272314
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.05296454543416046
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.010795560609001853
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.008730347503885358
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.003446567472634911
time: 263.5251
Val cmap: 0.8183711
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.07934804607278463
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.7846371303410486
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.020182165386793044
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.07579404474271476
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0020301341435406952
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03800847931311818
time: 269.4357
Val cmap: 0.8181166
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2811689224145834
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.39558710303096867
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.19064593214624648
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.11624167758315197
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.014848004650262744
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.001508360174786711
time: 264.9671
Val cmap: 0.8182600
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8533999082623539
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.07439888776406214
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.011902616494535917
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.033552592561168354
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.02464146814751416
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.002104526770365522
time: 269.9177
Val cmap: 0.8182907
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3949550010972508
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.38962604058516637
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.08145054729485912
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0508954770173044
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.00032392947682175974
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.08274900452859756
time: 259.8532
Val cmap: 0.8183335
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6768754955182781
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.015895634133477016
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.08672837330858102
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.023515388491663364
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004279717769041287
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.19270539077895926
time: 263.3866
Val cmap: 0.8186627
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5982299619527626
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.017714176741928656
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.011164121900288704
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.24569483475252835
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.11651720820201686
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.010679696450474858
time: 258.3967
Val cmap: 0.8181319
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6341730832795176
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01445158552248487
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.054826097998458376
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.007927062722731668
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.00646116737153764
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.2821610031052698
time: 263.6051
Val cmap: 0.8184123
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.9790476806141495
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.002967058188496125
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.014817614673768973
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0017622701162763946
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 9.678232675698052e-05
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.001308594080552043
time: 262.2546
Val cmap: 0.8182932
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7020389663860603
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08171806147041824
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.019239979316003252
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.07545854620269778
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.003956779426831221
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.11758766719798916
time: 257.4327
Val cmap: 0.8184289
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5414415235171044
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.13132739217046566
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.012524397774810635
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.15655666029933046
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0023204842144554276
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.15582954202383345
time: 270.4671
Val cmap: 0.8183244
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7138543315305396
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04795211422639474
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1250562304860432
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.031339752872481856
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.03557437734382723
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04622319354071341
time: 260.5592
Val cmap: 0.8186184
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4790104729285063
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.14500533578886854
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.10730566932374037
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.1876406445237889
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.040028374969647715
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04100950246544819
time: 260.5443
Val cmap: 0.8183124
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6509680978205351
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.005150745651416754
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.02823389653106354
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.07204323673684279
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004383391263501564
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.2392206319966402
time: 259.6471
Val cmap: 0.8184538
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5271094132537393
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06495483659257179
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15489543909326497
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.11517867065485399
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.07845429193894174
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.059407348466628235
time: 259.9536
Val cmap: 0.8184065
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6681403017706478
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04401310104727217
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.18443005925470407
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.033611802906611754
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.04918299191885027
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.020621743101913965
time: 261.4934
Val cmap: 0.8186431
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5959169016979871
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.10420281128164816
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0822834903652819
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.060272276245525024
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.1367182899349427
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.02060623047461517
time: 260.6224
Val cmap: 0.8181858
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7158586391593876
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04469418809714053
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14514691957179407
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.031592078835641565
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0463219133209728
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.016386261015063387
time: 262.1229
Val cmap: 0.8186773
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7754819034497643
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02873805638065227
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.10316548867952273
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.030773539653878954
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.05073622156275144
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.01110479027343031
time: 259.4007
Val cmap: 0.8185088
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6843423562871758
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03808393417585405
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.012453217593567684
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.05159058581069575
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.19496464884729167
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.01856525728541509
time: 259.7014
Val cmap: 0.8180173
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8150295556166696
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.019438523989785888
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.11491247363201283
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.021291831931698837
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.02159521382996159
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.007732400999871297
time: 257.7156
Val cmap: 0.8186331
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.9285778279833993
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.007668368208658223
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.02472672115246928
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.021234309408476634
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.012938015076115627
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.00485475817088096
time: 257.6500
Val cmap: 0.8183224
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6847517581100473
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.049604067588279926
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.00818132653165382
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0013466081247172842
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.23140698628183004
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.024709253363471635
time: 257.3289
Val cmap: 0.8179390
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8144027644687534
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02946996471703669
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.052464672807967454
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.031868536711875076
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.05344417065544318
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.01834989063892423
time: 257.8742
Val cmap: 0.8183983
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.612956771757396
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06936017598884406
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.13622008669178548
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.09009014782140623
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.07805537804122568
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.013317439699342529
time: 275.7285
Val cmap: 0.8185439
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.76380895709997
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.021451482693128892
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.10008054891193782
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.02032801147126125
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.02511738062454663
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.06921361919915543
time: 264.0222
Val cmap: 0.8185317
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7507271229295344
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.039528624410929296
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12491674048174975
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04120502608295622
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.01361377817695394
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03000870791787642
time: 269.4606
Val cmap: 0.8187034
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7565137994939385
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03965239261120981
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12440655694314055
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.03773446786219412
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.011018626411420275
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.030674156678096743
time: 271.5490
Val cmap: 0.8187100
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7463321244057668
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05475144266374417
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.09934709380220832
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04176414288503856
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.008597169588145234
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04920802665509695
time: 265.2729
Val cmap: 0.8186052
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.864579735160313
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.028782629469427234
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.03570328774292921
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.025537713604671133
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.014204443973573191
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03119219004908628
time: 259.7660
Val cmap: 0.8184437
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7928792359927509
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0012320938995807398
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15346236250017561
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.014283349076188997
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006846558851980139
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03129639967932364
time: 257.6856
Val cmap: 0.8187702
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7860959532024047
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.005335510728627479
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15979193309130987
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.009024663153376408
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.01023416229904567
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.029517777525235912
time: 259.0123
Val cmap: 0.8187646
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8957781078999184
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0016480912088273824
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.05046931549004086
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.012049065213935173
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.009870519003464862
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03018490118381332
time: 256.9906
Val cmap: 0.8184179
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8009099915329086
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0015650038440283608
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14421056887368863
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.012855364246752432
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006774435656008395
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03368463584661355
time: 260.4639
Val cmap: 0.8187777
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8169360956515926
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0010766497198764493
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12843176904289735
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.009901127720781265
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006074812723522804
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.037579545141329475
time: 264.5131
Val cmap: 0.8187448
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.9339625328921554
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.001024580580451116
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.013722634772889144
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.007503446863467362
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006535032312955937
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03725177257808108
time: 265.0347
Val cmap: 0.8183991
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8120966548839195
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.010721793892812088
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.10975272153687785
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.013120318043115503
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0027248099543251024
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.051583701688950004
time: 264.5785
Val cmap: 0.8187045
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8607097919985841
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.009749181263463061
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0864710336576543
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.013076498622985426
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.005580065756566589
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.024413428700746528
time: 259.3826
Val cmap: 0.8185532
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7975235502708589
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02540868728515524
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.10056794165638358
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.002392923547303409
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.009360992676375928
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.06474590456392297
time: 260.3679
Val cmap: 0.8186493
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8470105387941576
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.010861554038224166
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.08648049752634188
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.016477020197292132
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.003155377109828099
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03601501233415617
time: 263.8915
Val cmap: 0.8185977
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8973474261787038
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0061804434620459725
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.05721882405715696
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.007908704491309381
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006826254017408427
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.024518347793375476
time: 263.8111
Val cmap: 0.8184464
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7953641189327423
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.019097788519121594
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1237497697840366
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.015900784504716402
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004849778368572582
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.041037759890810536
time: 270.6470
Val cmap: 0.8187262
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.837076126962499
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01611846211164026
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.08400913217105378
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.016573537546266184
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.005029332978113521
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04119340823042728
time: 262.8856
Val cmap: 0.8186043
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.9870418916938811
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0023083476530037566
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0029148013439015317
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.003280173298016178
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0035349840021358116
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.000919802009061597
time: 261.8518
Val cmap: 0.8183015
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7981857971023669
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.020189733314167974
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0662589717349991
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.025957480253060616
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.007718400078289039
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.08168961751711634
time: 257.9678
Val cmap: 0.8186173
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7306392964371197
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03119069033094903
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12768750872849796
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.051441476371816994
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.002020215445551154
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.057020812686065216
time: 260.7996
Val cmap: 0.8186948
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.9456838067270807
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.004108220941288095
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.00799641972927128
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.010274340089848623
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.005481024206740868
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.026456188305770387
time: 262.9728
Val cmap: 0.8183336
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7745189286887091
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.019714838936346207
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14256651577822177
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.01805428115130806
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.010762597663579341
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03438283778183555
time: 259.6760
Val cmap: 0.8187864
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7855554301224754
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.021600040526614423
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12136899097014897
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.018495967127615306
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0078022898643141355
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.045177281388831744
time: 264.6376
Val cmap: 0.8187399
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8955367048846558
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.013499350628026919
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0298763426214247
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.005828401162422114
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.008435196827531345
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04682400387593917
time: 259.9842
Val cmap: 0.8184427
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7178787848158378
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02951219028895488
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.08703806938460483
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04013323751969873
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.018576084439952442
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.10686163355095132
time: 263.5762
Val cmap: 0.8185959
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8656553346538925
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01005847419011573
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.06997982326830482
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.009078061833253995
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.010924302032688677
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.034304004021744224
time: 267.6359
Val cmap: 0.8185525
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6443049577203508
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.056633445851332884
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15226288384289544
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.05551436382672091
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.01723780988817353
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.07404653887052641
time: 262.7495
Val cmap: 0.8186226
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.768116186022184
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02359167670471922
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1177377417372299
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.025466793270563275
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006924259203755104
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.05816334306154848
time: 263.2255
Val cmap: 0.8187193
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8358838444613876
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.015202737570940431
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.07608036690594676
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.02012964379952874
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.011350810120455732
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.0413525971417407
time: 266.1955
Val cmap: 0.8185821
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7020839548239701
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03785960978708864
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1605713522956555
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04531810499584471
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0037361237512346973
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.050430854346206345
time: 261.1661
Val cmap: 0.8187797
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7075763115332585
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.037303579768205995
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1534496329638162
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04266078587792299
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.003968341827110103
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.05504134802968623
time: 279.7491
Val cmap: 0.8187598
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7121174000608477
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.034326756900677775
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15011839525339682
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04549454569881638
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004123897667140272
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.05381900441912109
time: 257.3457
Val cmap: 0.8187666
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6844858672828273
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.037762526108514605
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1290463460007887
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0480597931163986
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.003999632811512131
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.0966458346799586
time: 259.4288
Val cmap: 0.8187048
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7357578860577904
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0349450274154526
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12493980984139733
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04542139263550855
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.002330782479341456
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.056605101570509686
time: 259.7850
Val cmap: 0.8187068
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7085868529107129
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06075689857163413
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1196248919855156
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.037507657654705644
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0018060400027527961
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.07171765887467894
time: 266.9321
Val cmap: 0.8186652
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6332827915192686
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08092318412944613
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.13430066765982382
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.06306705635639258
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0031749272730515047
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.08525137306201741
time: 259.9427
Val cmap: 0.8185342
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6872266298832912
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04595445077355419
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14830931803846764
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.06235061992805353
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004279338919879862
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.051879642456753576
time: 261.5936
Val cmap: 0.8186994
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6680284960528986
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05427074944276309
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.22382098319382687
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0301994474859258
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0015246380460648902
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.022155685778520742
time: 259.5900
Val cmap: 0.8185950
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7716475072952482
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03409074276747075
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.09795463988712999
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.027408028510866846
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004884306403937362
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.06401477513534681
time: 261.6209
Val cmap: 0.8185772
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7215232359737163
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04739567161814267
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15960378465502426
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.03440290636422848
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0039390250503119305
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.033135376338576376
time: 260.1399
Val cmap: 0.8187732
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7367682820173586
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04663472854582758
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14094683390777668
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.034221702733814904
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.012545569477990905
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.02888288331723137
time: 259.1125
Val cmap: 0.8187403
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7119992201252191
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.061875085225748326
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14187720761775668
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04535897192335556
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0037804623200109076
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.0351090527879094
time: 264.3994
Val cmap: 0.8187250
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5783953549864586
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.07750615336628093
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.24756142185337
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.06936807324722064
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006345735841583212
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.020823260705086652
time: 266.3571
Val cmap: 0.8185243
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7743552674441181
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02647217644694941
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.11610451429562105
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.02441271533299922
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.009633835694823754
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.049021490785488474
time: 270.0054
Val cmap: 0.8187136
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7477040604516347
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04242404959778888
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.13611330919174106
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.038042983284566456
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0025473977999927386
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03316819967427611
time: 265.6302
Val cmap: 0.8187554
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6592223964513464
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0671437661527767
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1896035891761899
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.052316874868913094
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.00318970419424545
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.028523669156528438
time: 264.9010
Val cmap: 0.8187171
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7002166573116488
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05069008205931501
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15555341812941553
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04354371473113877
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004512598146858291
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04548352962162355
time: 262.5486
Val cmap: 0.8187798
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8245588390185858
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.007317797456404033
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.097092593517977
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.023122033674911384
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.005596261754620526
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04231247457750121
time: 257.8368
Val cmap: 0.8186685
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6262445658146529
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0724069976850526
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.17925666822655087
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.08860449693604985
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.00799537157469781
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.025491899762995925
time: 258.5616
Val cmap: 0.8186427
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.764654657350222
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01456041893853946
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.15667525083105652
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.03146065890431829
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.01600630213106263
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.016642711844801126
time: 258.8360
Val cmap: 0.8187546
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6900499939778497
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05095766801093406
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.23180485798271117
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.0023768426692711356
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.002807394084541532
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.022003243274692406
time: 258.1352
Val cmap: 0.8186269
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7131824371771904
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.037868825632157495
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.16337508895337338
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04401264455449501
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004285283701734777
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.037275719981048915
time: 261.2403
Val cmap: 0.8187812
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6598724713900496
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08644032951640775
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.17406335184142713
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.03793635838947819
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004882690381050651
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03680479848158674
time: 257.7904
Val cmap: 0.8187538
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7279853645932022
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02451551048678912
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1503937059056438
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.05762413111378488
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0067278404473642235
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03275344745321578
time: 257.8382
Val cmap: 0.8187671
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7485330360573987
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02871611730636739
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.12425841645883197
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.048042710625952646
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006075883690746727
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.044373835860702544
time: 262.5793
Val cmap: 0.8187078
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7269179524017884
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.044716472819103154
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.13522184784332766
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.055495525351250165
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.004220590410363741
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03342761117416693
time: 261.4245
Val cmap: 0.8187510
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6716295066587543
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05523539551939213
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.16947991680540528
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.057043771950815024
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.007265485175238703
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.03934592389039453
time: 260.8187
Val cmap: 0.8187596
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.80331785104731
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.032625298650193875
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.0767803801922409
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.03481772196086877
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.00469880597821159
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.04775994217117486
time: 261.4889
Val cmap: 0.8185902
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6970549744588181
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.022872749382738904
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14624965587154284
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.06839058288093047
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.00353533817145515
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.06189669923451448
time: 257.7033
Val cmap: 0.8186925
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6026295949246034
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.09379663975411856
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.18692689731469828
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.07560974226517508
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.008282595672859062
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.0327545300685456
time: 261.2219
Val cmap: 0.8186076
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7340386583172966
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04047979486940859
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1494106237515509
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.043450715304617665
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.0051796071271126695
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.02744060063001354
time: 262.1883
Val cmap: 0.8187498
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7835470841824763
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01788676381988602
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.1413889984625543
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.017630716874102847
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.010071399455639061
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.029475037205341472
time: 261.7400
Val cmap: 0.8188050
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7928989176839394
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01839354039656831
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.11546897983591131
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.028680849820593574
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.006394753720197936
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.038162958542789484
time: 268.3035
Val cmap: 0.8187251
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7537014996122939
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02553808573664391
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14683048953436645
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.015664150595074096
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.009542570599496137
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.048723203922125466
time: 265.8075
Val cmap: 0.8187471
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8331934138336771
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.012302993901425337
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.06888993753939036
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.04875913228789455
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.005716459943773659
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.031138062493839016
time: 265.4508
Val cmap: 0.8185462
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.776349992110657
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.019664309701159448
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.14428206495636864
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.02138864544910893
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.011787316715415039
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.026527671067290908
time: 280.7920
Val cmap: 0.8187827
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8728995896142199
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01714194808786532
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.058937711818507765
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.012332095571787247
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.012325699330928298
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.026362955576691507
time: 271.6776
Val cmap: 0.8184033
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8233122457018489
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008239508244618658
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.11619707673658045
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.021240692475764517
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.007296103374062804
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.023714373467124655
time: 260.2490
Val cmap: 0.8186914
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7865896433362631
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.022250351601848184
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.11898136139386824
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.020273642009391184
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.009103213542182147
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.042801788116447116
time: 259.7903
Val cmap: 0.8187341
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7720631039433643
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.013580371556384776
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_111_0.815124.pth
a6: 0.13702179596592762
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_160_0.817094.pth
a3: 0.029275648799395423
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_150_0.815493.pth
a5: 0.013428206302050674
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_126_0.816729.pth
a4: 0.034630873432877206
time: 259.5084
Val cmap: 0.8187646
{'a1': 0.7835470841824763, 'a2': 0.01788676381988602, 'a3': 0.017630716874102847, 'a4': 0.029475037205341472, 'a5': 0.010071399455639061}
Date :05/19/2023, 17:27:27
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8281571303961917
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.12095839273100097
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.008121712856439674
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04276276401636771
Date :05/19/2023, 17:28:05
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.507742233630335
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.386576858488337
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.07137282732581902
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03430808055550898
time: 274.2011
Val cmap: 0.8184503
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.45318753017557817
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.14298343784766937
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.1123706369854244
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.2914583949913281
time: 271.9665
Val cmap: 0.8184484
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.44696237018630125
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.1522022489137574
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.31628304087272735
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08455234002721401
time: 269.6167
Val cmap: 0.8182161
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.2561786132382891
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.11734554789772488
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.18657632712822605
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.43989951173576003
time: 271.9226
Val cmap: 0.8184351
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.42426267766169884
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.01568703623103216
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.32415079490567317
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.23589949120159576
time: 274.4685
Val cmap: 0.8183307
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.36757698170030956
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.37111785361374433
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.10019332993708267
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.16111183474886337
time: 276.8379
Val cmap: 0.8184291
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3905462658045263
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.23742173647817572
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.20675304729712402
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.16527895042017404
time: 281.1864
Val cmap: 0.8183682
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7181954524221327
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04406496833517499
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.1663213346909271
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07141824455176524
time: 271.3043
Val cmap: 0.8185314
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7214358790391837
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.14616400369837237
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.07068422420270716
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06171589305973675
time: 274.1964
Val cmap: 0.8186423
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5576498616973364
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.3497671590958168
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.03090829139161776
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.061674687815229015
time: 271.4620
Val cmap: 0.8185256
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.917718226572039
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.012954665863849815
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.007329669081489021
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06199743848262211
time: 274.7283
Val cmap: 0.8187538
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9795261658434962
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0014409608811455261
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.003476156666993806
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.015556716608364503
time: 304.7996
Val cmap: 0.8188826
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9681255351431614
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0011232854607060826
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0012380058337440282
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.029513173562388535
time: 289.3608
Val cmap: 0.8188261
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9682919130326944
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0010494446693960595
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.001035641169816511
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.029623001128093077
time: 271.8829
Val cmap: 0.8188291
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.010083130893432324
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.5783143082177642
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0029726614332404658
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.40862989945556294
time: 274.7277
Val cmap: 0.8182190
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9813587282427078
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0015061825709585357
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0010288714863863537
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.016106217699947356
time: 282.0559
Val cmap: 0.8188793
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8451889758240276
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.026603747405756724
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.020239020126421096
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.10796825664379456
time: 280.4634
Val cmap: 0.8187300
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8818874410444656
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005241120020856709
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.017066750378910006
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0958046885557677
time: 275.3755
Val cmap: 0.8187259
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7988326720983978
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.033717296094877475
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.03474856663756522
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.13270146516915948
time: 270.6415
Val cmap: 0.8187297
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9876138748328365
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0021365645485247895
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0019131678227029142
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008336392795935827
time: 269.3840
Val cmap: 0.8188726
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7825899639065119
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.05033950904000581
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0381215684272532
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.12894895862622907
time: 269.1082
Val cmap: 0.8187285
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9779246917526621
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0029561749311031293
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0024962261896639953
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.016622907126570816
time: 267.2742
Val cmap: 0.8188881
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8907332161249195
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.011007703384087785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.011138268405608687
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08712081208538401
time: 268.1545
Val cmap: 0.8187363
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8679164857003682
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.020798000638404424
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.01773150572831729
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.09355400793291012
time: 271.6788
Val cmap: 0.8187053
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9832862632324482
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002952645766914579
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0025356617650924363
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.011225429235544818
time: 275.2695
Val cmap: 0.8188993
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6886846040287643
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.053325820755110796
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.051404581174217485
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.20658499404190744
time: 284.9658
Val cmap: 0.8186461
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8059759103662427
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02941095678320932
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.023051759303619093
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.14156137354692888
time: 275.5237
Val cmap: 0.8187464
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9223369654266417
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010553098784834649
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.008560565969230913
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05854936981929276
time: 277.8203
Val cmap: 0.8187431
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9028658208256265
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.008904250861956488
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.010568235925676829
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0776616923867402
time: 278.6194
Val cmap: 0.8187467
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6330293238898185
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.068794971966889
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.053290780613532505
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.24488492352976002
time: 274.3603
Val cmap: 0.8186883
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.828615318310831
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.020221187258346332
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.025524163114798423
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.12563933131602423
time: 270.1285
Val cmap: 0.8187422
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9875026971101164
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002113905190818408
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0022861721101773897
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008097225588887801
time: 264.9242
Val cmap: 0.8188717
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9095240689164095
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006374494940241261
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.007650356483361464
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07645107965998782
time: 270.0287
Val cmap: 0.8187403
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9438392818558526
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00525614950872336
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005236668274822396
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04566790036060161
time: 279.1794
Val cmap: 0.8187418
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8445630217811398
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.018887857414406406
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.01467079001237852
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.12187833079207523
time: 272.2900
Val cmap: 0.8187343
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.986718371600715
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0024175246972365167
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0028614298949322927
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.00800267380711623
time: 283.5289
Val cmap: 0.8188559
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7762070668860148
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.033298733019291385
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.029536310789979463
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.16095788930471436
time: 275.2044
Val cmap: 0.8186914
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9317033236087267
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.007126996197798163
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.004800669225136272
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05636901096833891
time: 268.1795
Val cmap: 0.8187565
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8586622863379705
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.016234879611372786
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.014108047750530607
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.11099478630012612
time: 271.4166
Val cmap: 0.8186966
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9149243127772319
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.009643511693288165
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.010006062229687602
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06542611329979238
time: 270.4913
Val cmap: 0.8187404
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7361419487845833
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.06297357904184854
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.04009237126735088
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.16079210090621732
time: 273.6607
Val cmap: 0.8186843
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9791143964279387
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0028958030550921905
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0020280205093992456
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.015961780007569825
time: 275.0240
Val cmap: 0.8188825
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9410948356822126
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004133684839122936
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.006233558091562081
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04853792138710235
time: 270.9782
Val cmap: 0.8187571
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9892464255951045
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0015300525957944616
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0016552795650100064
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.007568242244091082
time: 272.2113
Val cmap: 0.8188732
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8852709310817531
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.016224275607926903
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.012449920042877984
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08605487326744198
time: 274.6375
Val cmap: 0.8187195
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9463757830322809
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003852040412767607
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005827925024938025
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.043944251530013495
time: 271.9924
Val cmap: 0.8187731
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8477921784731763
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02490285590914454
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.018932873664868365
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.10837209195281075
time: 274.0567
Val cmap: 0.8187313
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9331456135876309
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0072440362318569465
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.004844686212756578
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05476566396775555
time: 290.1931
Val cmap: 0.8187560
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8218612260327779
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.021777888653940466
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.02365530715545408
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.13270557815782755
time: 281.8079
Val cmap: 0.8187469
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8785753123435701
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.013547872779045088
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.013673712141768785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.09420310273561601
time: 277.5305
Val cmap: 0.8187335
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9601182652931721
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003439415880881709
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0039001879886720065
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03254213083727416
time: 274.7306
Val cmap: 0.8188089
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9875287872314791
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0014925442740610854
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0015616601271641038
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.009417008367295735
time: 272.5407
Val cmap: 0.8188878
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9585395378753696
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0032391042062006755
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.003691137604956457
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03453022031347326
time: 272.2915
Val cmap: 0.8187976
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.90170449647455
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0119750624589307
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.009204919336879362
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07711552172963995
time: 277.4716
Val cmap: 0.8187375
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9878991023024967
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0014364075961855866
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0012214125948500167
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.00944307750646773
time: 270.8334
Val cmap: 0.8188838
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9414210680881715
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005745667260899971
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0072422945521046
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04559097009882393
time: 274.1304
Val cmap: 0.8187733
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8713377506895936
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.014216737104312677
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.01322681251755128
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.10121869968854241
time: 266.1223
Val cmap: 0.8187138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.962206447476258
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0013127663263937995
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0011027629932993182
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03537802320404883
time: 267.0293
Val cmap: 0.8188099
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9061449287297456
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00903875345763099
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.00923154691519234
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07558477089743106
time: 267.8039
Val cmap: 0.8187446
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9852734734279289
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0010860897132133843
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0014681201451953395
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.01217231671366235
time: 268.6831
Val cmap: 0.8188970
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8197628453957204
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.030782165444980858
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.01998823306461839
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.12946675609468034
time: 265.6151
Val cmap: 0.8187683
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9865574352576654
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009768025289894466
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0014258647247448785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.011039897488600302
time: 274.5739
Val cmap: 0.8188965
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9238513137651809
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006172595295902162
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.007173253662299324
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06280283727661759
time: 273.6067
Val cmap: 0.8187562
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9857665135527973
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0010709319399388774
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0015719906340063516
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.011590563873257452
time: 275.4584
Val cmap: 0.8188946
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9582606912566318
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.001073900694742904
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0032318168059563314
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03743359124266894
time: 274.2539
Val cmap: 0.8188049
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8783944927871575
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010762091399057476
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.01554767778937994
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.09529573802440505
time: 273.5894
Val cmap: 0.8187321
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8974838959989275
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.008232894151146874
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.010856821372074905
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0834263884778507
time: 266.8672
Val cmap: 0.8187342
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9881961553306985
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009487360462846862
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0014564430158680863
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.009398665607148738
time: 267.9049
Val cmap: 0.8188857
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9333291008526752
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0044643766648497256
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0057614041088621774
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05644511837361292
time: 270.2598
Val cmap: 0.8187608
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9557095195395833
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004499026763396882
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0027315967290574977
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.037059856967962344
time: 272.7964
Val cmap: 0.8187753
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8386283355066102
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.018602146602426258
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.017369208536345104
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.12540030935461843
time: 271.0153
Val cmap: 0.8187506
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9874268812103825
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009368305413107391
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0014478844164714498
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.010188403831835344
time: 276.2027
Val cmap: 0.8188794
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.916841967392469
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.007808878866355497
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.008232579370877699
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06711657437029778
time: 265.2172
Val cmap: 0.8187477
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9883897554999754
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0017243419005441474
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0009027861684026675
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008983116431077754
time: 273.4385
Val cmap: 0.8188817
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9628946207695871
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0026137724013750984
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0021991592367801406
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03229244759225766
time: 278.7757
Val cmap: 0.8188154
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9253996081935544
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005547343523409479
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005971282691155644
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0630817655918805
time: 429.0228
Val cmap: 0.8187541
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8933627184365894
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.012652612043946337
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.011778734095387646
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08220593542407659
time: 499.8709
Val cmap: 0.8187241
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8599733659402398
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.015375236676595582
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.015252045813977353
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.1093993515691873
time: 356.8872
Val cmap: 0.8187060
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9522697745918469
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002982973783276972
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.004715338173232272
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.040031913451643836
time: 335.8244
Val cmap: 0.8187784
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9670566434922717
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0022225707840253964
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002784529481097118
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.02793625624260577
time: 363.8020
Val cmap: 0.8188315
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9151534380406198
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00825436427168116
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.00716528917717256
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0694269085105265
time: 356.1591
Val cmap: 0.8187557
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9882884406349273
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0017856848284435267
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0014317619428915
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008494112593737706
time: 371.6993
Val cmap: 0.8188746
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9419858168214468
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004601474657182551
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0034001975438844117
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05001251097748626
time: 369.4343
Val cmap: 0.8187445
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9635346172419356
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003265617797880651
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002105957127561518
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.031093807832622267
time: 315.1724
Val cmap: 0.8188277
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9884898985919327
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0013607368084625373
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0017180362369032488
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.00843132836270151
time: 471.6108
Val cmap: 0.8188750
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8874581501284176
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010291888210530455
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.009318990618455937
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.09293097104259605
time: 395.4363
Val cmap: 0.8187356
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9292804892242819
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00645105129822854
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.004676971203360105
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.059591488274129495
time: 376.8683
Val cmap: 0.8187653
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8610402535764818
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.012762235884338327
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.009733507796230296
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.11646400274294953
time: 374.4707
Val cmap: 0.8187100
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9643476413557517
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002419764774818625
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0038911711243165385
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.029341422745113154
time: 352.7040
Val cmap: 0.8188344
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9020319749905059
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.009681223460503128
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0063722992872930675
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0819145022616979
time: 368.7031
Val cmap: 0.8187436
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.968731743831439
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0019092137917882971
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0009003902866495287
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.028458652090123167
time: 391.3215
Val cmap: 0.8188237
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9419608577469688
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003951257872691978
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0040452644212555545
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.050042619959083656
time: 357.9252
Val cmap: 0.8187441
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9679693001150106
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009128489000047223
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.00220413137382785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.02891371961115684
time: 373.3596
Val cmap: 0.8188272
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9891174532558565
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0011829663592571745
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0012901716878930517
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008409408696993236
time: 382.0925
Val cmap: 0.8188715
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9236387931993363
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006050842316990837
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0049091094160733754
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0654012550675995
time: 359.8432
Val cmap: 0.8187609
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9431567403477975
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005031633574912912
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0031256384898307914
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04868598758745879
time: 381.1242
Val cmap: 0.8187487
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9096393345110432
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.007357289923650059
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.00801477387305024
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07498860169225652
time: 362.3989
Val cmap: 0.8187481
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9696201908170152
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0027949657104447277
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002633707173226322
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.024951136299313725
time: 382.8283
Val cmap: 0.8188592
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8738754027238098
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010958345374193669
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.011789261237736192
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.10337699066426033
time: 370.8164
Val cmap: 0.8187118
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.938442715508227
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0035045401897986017
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005250472413219576
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.052802271888754825
time: 321.7089
Val cmap: 0.8187366
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9898297542178053
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0015496377403046821
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0017694574807692273
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.006851150561120812
time: 392.3916
Val cmap: 0.8188686
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9717752921803638
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0020882053841762864
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0024042857157535917
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.023732216719706274
time: 389.5478
Val cmap: 0.8188658
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9479678091643745
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003939354588050526
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.003762205086696028
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04433063116087894
time: 382.5587
Val cmap: 0.8187755
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9893986844689602
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0012167380490140443
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0019312455309110827
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.007453331951114696
time: 347.8019
Val cmap: 0.8188724
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9163294881410629
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006920160652318098
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0066192686422290765
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07013108256438998
time: 389.9822
Val cmap: 0.8187582
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9726705213801805
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0026978054482514036
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.001172946996985786
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.023458726174582303
time: 389.5085
Val cmap: 0.8188709
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8889308353114898
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.008586668024075417
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.009862719447518927
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0926197772169159
time: 365.6070
Val cmap: 0.8187507
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9504682936180511
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00487101496285617
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.003211429066015402
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04144926235307735
time: 392.1628
Val cmap: 0.8187682
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9286864422206517
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006101017936717816
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0063610054424355425
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05885153440019498
time: 399.6970
Val cmap: 0.8187622
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9734213056553059
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.001705810905700789
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.001605618742540058
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.02326726469645322
time: 364.9037
Val cmap: 0.8188674
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9492204897233422
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003251275873542448
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0041364664661633545
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.043391767936952035
time: 271.5256
Val cmap: 0.8187703
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9892312996530798
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0010630792381270482
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0013971346006538018
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008308486508139385
time: 279.1012
Val cmap: 0.8188723
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9766154418719044
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002043149011785804
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0009387923601063526
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.020402616756203435
time: 282.1906
Val cmap: 0.8188786
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9037812575670587
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.008292958066464014
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.00791241990088761
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08001336446558964
time: 269.4000
Val cmap: 0.8187388
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.927243801066609
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004834849949039347
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005462577361528722
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.062458771622822956
time: 274.4909
Val cmap: 0.8187552
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9532133278426167
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0036491733772366043
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0028962254683164825
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.040241273311830215
time: 276.7294
Val cmap: 0.8187705
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9749679960590697
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0025038186436062144
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002496552028536757
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.020031633268787333
time: 271.7617
Val cmap: 0.8188785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9491528146271705
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0039281415779382975
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0044805269358240505
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04243851685906716
time: 274.6892
Val cmap: 0.8187657
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9135209490193734
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006758752579543024
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.006874188043668503
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07284611035741506
time: 276.6043
Val cmap: 0.8187468
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9899363745839315
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009225269654321316
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0010892923523870613
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.00805180609824934
time: 270.4666
Val cmap: 0.8188724
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8895633294215741
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.011025668002627298
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.010798730250640187
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08861227232515839
time: 268.3107
Val cmap: 0.8187382
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9677510772014326
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0017826242537867575
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0019649975815334147
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.02850130096324722
time: 269.0067
Val cmap: 0.8188273
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9359460779608595
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0047060305464658265
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.003896160239293953
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.05545173125338073
time: 269.7478
Val cmap: 0.8187556
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9585897511489535
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0028145681073986906
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0033243578611815584
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.03527132288246625
time: 265.4681
Val cmap: 0.8188091
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9884871259891773
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0014187064686121643
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0013925024470312335
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008701665095179284
time: 267.3576
Val cmap: 0.8188714
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9318272216715694
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0054796767242310685
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005188162725045333
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.057504938879154206
time: 269.7954
Val cmap: 0.8187620
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.856979554989238
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.016081115497942645
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.012995448430268368
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.11394388108255105
time: 279.7316
Val cmap: 0.8187000
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9585145888971757
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002975400207079466
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002453062705552223
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.036056948190192645
time: 265.7248
Val cmap: 0.8187915
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9113397990589774
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.007842046726387338
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.008090543320438317
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.07272761089419691
time: 264.2963
Val cmap: 0.8187388
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9719667039295108
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0023486380708026377
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002006300104732093
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.02367835789495448
time: 273.4685
Val cmap: 0.8188650
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5602416302734696
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.038549209682395696
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.03028168943945028
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.3709274706046844
time: 281.6957
Val cmap: 0.8187344
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9781288170681862
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0020214592372840476
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0009005212660298196
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.018949202428499914
time: 271.7199
Val cmap: 0.8188839
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9413395614486858
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004169563406797864
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.003257798892887035
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.0512330762516293
time: 265.9329
Val cmap: 0.8187414
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.973360471669392
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0019094983106529362
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.001681520125066268
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.023048509894888804
time: 274.3989
Val cmap: 0.8188695
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9532462621355215
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002914515722655636
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0028261098137980084
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.041013112328024806
time: 268.8979
Val cmap: 0.8187677
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9895930316926814
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0012309113444691953
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0012036706379770909
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.00797238632487229
time: 273.8603
Val cmap: 0.8188722
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9277994398851859
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00582145201563366
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.005205450566980176
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06117365753220028
time: 271.9696
Val cmap: 0.8187536
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9671230055745956
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002232060554981277
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0009102014621213224
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.02973473240830177
time: 270.8903
Val cmap: 0.8188265
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8932911601510204
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010194143452422155
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0086179575941004
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.08789673880245705
time: 270.5914
Val cmap: 0.8187499
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9472427656588805
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0038700870806934774
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.004590413253457068
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.04429673400696891
time: 284.3164
Val cmap: 0.8187666
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9206063653317471
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0065648359011596606
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.006237194203365094
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.06659160456372813
time: 265.7016
Val cmap: 0.8187503
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9891308667756519
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0013213963584071445
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.0015331417829216256
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.008014595083019356
time: 269.3706
Val cmap: 0.8188729
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9741217701954444
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0018557378502697987
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.816055.pth
a3: 0.002065302680505203
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a4: 0.021957189273780563
Date :05/22/2023, 08:31:43
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.581619583256291
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.062390990677563804
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.35598942606614514
time: 292.4059
Val cmap: 0.8187965
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6108326283564622
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.13276142718779052
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.25640594445574727
time: 280.9318
Val cmap: 0.8187165
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.385778588891853
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.35752342571348505
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.25669798539466193
time: 276.5111
Val cmap: 0.8185930
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8445559696709665
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.07339389493934785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.08205013538968568
time: 269.3616
Val cmap: 0.8187446
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9089130281554593
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.053487549460911644
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.03759942238362909
time: 267.2212
Val cmap: 0.8187396
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.08387199592959457
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.3675134616074041
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.5486145424630013
time: 266.0324
Val cmap: 0.8182405
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7756563462441542
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04662821347146745
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.1777154402843783
time: 266.2534
Val cmap: 0.8187635
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9283729161884385
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0630702514627307
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.00855683234883077
time: 267.4065
Val cmap: 0.8188236
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5545513394196768
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.22872676089511726
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.21672189968520592
time: 266.5003
Val cmap: 0.8186507
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6754068830820075
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.1985830975053111
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.12601001941268142
time: 267.0491
Val cmap: 0.8186639
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9750105586301413
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002849860079712255
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.022139581290146447
time: 265.6285
Val cmap: 0.8188662
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9752595427107644
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0021929167223237265
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.02254754056691185
time: 264.6395
Val cmap: 0.8188571
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9883691011730122
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0012865989998354138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.010344299827152343
time: 264.9438
Val cmap: 0.8188797
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7713023357497393
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003988008625856765
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.22470965562440395
time: 267.6996
Val cmap: 0.8187870
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9585959394445123
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0020019233825227505
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.03940213717296498
time: 267.9129
Val cmap: 0.8187913
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9813978268461161
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.001250027195110208
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.0173521459587737
time: 267.7146
Val cmap: 0.8188785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7990860462010605
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.026381641856988505
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.174532311941951
time: 266.6026
Val cmap: 0.8188097
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7186725373584663
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.09851573416199552
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.18281172847953822
time: 266.0441
Val cmap: 0.8187415
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8702188996802193
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.01780833622743627
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.11197276409234447
time: 266.9242
Val cmap: 0.8187131
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8497398933573068
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02188084327391998
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.1283792633687732
time: 263.8189
Val cmap: 0.8187367
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4445169665870008
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.1567421099754714
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.3987409234375278
time: 265.1441
Val cmap: 0.8188569
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.983455899586575
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0013945127300736897
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.015149587683351333
time: 262.4494
Val cmap: 0.8188804
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.877889018228323
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.014083765500165022
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.10802721627151199
time: 270.0878
Val cmap: 0.8187087
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9807111691098565
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.001642807228421802
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.017646023661721747
time: 267.6072
Val cmap: 0.8188828
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9845769644191995
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0011093063065050282
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.014313729274295464
time: 266.9781
Val cmap: 0.8188767
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8711578400058951
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.014251941289749978
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.11459021870435489
time: 264.1722
Val cmap: 0.8187178
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7320351635600195
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.035201901761676
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.23276293467830447
time: 267.3086
Val cmap: 0.8187915
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8144246406155173
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.03297005767749159
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.15260530170699108
time: 268.2378
Val cmap: 0.8188005
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9105951645246689
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.009167692973845067
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.080237142501486
time: 265.4378
Val cmap: 0.8187813
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9114872664313869
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.009334772416253202
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.07917796115235991
time: 267.2427
Val cmap: 0.8187862
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7058061557703721
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.03948700875109554
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.25470683547853235
time: 264.0499
Val cmap: 0.8187958
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9670958882713236
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.000961234596906622
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.031942877131769735
time: 265.0000
Val cmap: 0.8188237
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9824904794737302
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.003552710560514185
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.013956809965755566
time: 275.5710
Val cmap: 0.8188653
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9101786932760123
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00830026315124568
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.08152104357274201
time: 279.3760
Val cmap: 0.8187824
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8370748592395915
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.023601957864980698
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.13932318289542783
time: 271.4478
Val cmap: 0.8187803
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.989587040382617
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0014432319436776782
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.0089697276737053
time: 275.6274
Val cmap: 0.8188714
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8254163437380403
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.021950563647225377
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.15263309261473434
time: 332.2210
Val cmap: 0.8188042
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.910747341639528
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010228563977048978
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.07902409438342305
time: 325.6374
Val cmap: 0.8187856
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6521693782603397
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.07535421499822444
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.27247640674143586
time: 283.8912
Val cmap: 0.8187952
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7709302632536172
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04271758521305394
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.18635215153332882
time: 270.3152
Val cmap: 0.8187480
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9249970848673098
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.008197264583609015
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.06680565054908118
time: 266.4444
Val cmap: 0.8187690
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9869137674380839
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009033598500800138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.012182872711836086
time: 264.1633
Val cmap: 0.8188809
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9363841923662668
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005881354126207244
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.05773445350752596
time: 265.6751
Val cmap: 0.8187627
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8738177515468109
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.015413399596939381
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.11076884885624977
time: 270.7931
Val cmap: 0.8187102
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9434035685224418
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005398611002634365
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.051197820474923855
time: 264.9624
Val cmap: 0.8187427
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8639037780098585
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0161088580592248
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.11998736393091669
time: 267.6956
Val cmap: 0.8187277
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9505915595844799
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004540879859766102
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.04486756055575396
time: 268.5216
Val cmap: 0.8187476
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8087954172692055
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.031237470297294092
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.15996711243350045
time: 270.8016
Val cmap: 0.8188149
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8892471706489138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.011672977741359544
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.09907985160972667
time: 273.1772
Val cmap: 0.8187451
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9891788317994831
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0017262191293317339
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.009094949071185195
time: 264.1208
Val cmap: 0.8188843
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9393301956240591
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006828557777771685
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.05384124659816925
time: 264.2634
Val cmap: 0.8187537
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9802546229804044
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002252467566816965
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.01749290945277859
time: 265.2070
Val cmap: 0.8188829
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9352115571083492
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004836036230984003
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.05995240666066675
time: 267.1893
Val cmap: 0.8187529
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9896203504762785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0014440092425239384
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.008935640281197563
time: 271.4169
Val cmap: 0.8188715
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8970566228177571
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.012002709131746631
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.09094066805049626
time: 270.7983
Val cmap: 0.8187612
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8482742403777954
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.019062197935596464
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.13266356168660812
time: 264.2286
Val cmap: 0.8187326
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9619020719377916
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.002989653796358056
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.035108274265850295
time: 278.8063
Val cmap: 0.8187930
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.945052515133875
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0065588782544175215
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.04838860661170748
time: 267.8412
Val cmap: 0.8187484
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7780305575420097
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02947572793351671
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.1924937145244736
time: 270.1648
Val cmap: 0.8187474
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8890138026657842
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.01310403714133097
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.0978821601928848
time: 267.8933
Val cmap: 0.8187446
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8402649566294962
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.025102872109204862
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.13463217126129895
time: 266.1656
Val cmap: 0.8187372
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9815247628306963
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0023013999463601443
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.016173837222943514
time: 275.1581
Val cmap: 0.8188828
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9859031109058641
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0018402469657697845
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.012256642128366083
time: 290.2087
Val cmap: 0.8188829
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9524385529907347
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0031846483317163506
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.044376798677549
time: 291.5690
Val cmap: 0.8187520
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9886806575561747
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0019661325383405277
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.009353209905484737
time: 275.1363
Val cmap: 0.8188837
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9120642471152726
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.007594071570620105
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.08034168131410734
time: 277.5532
Val cmap: 0.8187849
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9570842442152226
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0026018763150453296
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.04031387946973203
time: 268.2929
Val cmap: 0.8187848
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8861263802490033
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.018300715778403902
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.09557290397259284
time: 265.3286
Val cmap: 0.8187309
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9229178901362138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.010568472679944107
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.06651363718384205
time: 265.8037
Val cmap: 0.8187419
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8560184984147776
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.018612559208339784
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.1253689423768826
time: 277.3528
Val cmap: 0.8187415
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9654686400706951
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0037351754700929956
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.0307961844592119
time: 281.5154
Val cmap: 0.8188252
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.988984070955015
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.001727084553551415
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.009288844491433636
time: 269.2863
Val cmap: 0.8188835
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9894014705310502
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0017617738399159817
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.00883675562903381
time: 271.0972
Val cmap: 0.8188717
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9261040843634388
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006320233160689997
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.06757568247587117
time: 268.0632
Val cmap: 0.8187729
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9588563313851958
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004420147522131804
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.03672352109267243
time: 267.4873
Val cmap: 0.8187949
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9898029422465735
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0021910817433296098
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.008005976010096887
time: 265.5264
Val cmap: 0.8188734
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8986639555488887
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.009529428869276102
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.09180661558183523
time: 269.2057
Val cmap: 0.8187605
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9350154386037239
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00505424235863159
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.059930319037644474
time: 268.8556
Val cmap: 0.8187532
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.964319459976109
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0023967882164414958
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.03328375180744949
time: 276.8686
Val cmap: 0.8188101
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8678016811466214
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.014893965426230563
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.11730435342714807
time: 273.9066
Val cmap: 0.8187132
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9125092857180976
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.008120985633713095
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.07936972864818927
time: 295.0230
Val cmap: 0.8187846
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9671853254875789
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0034373857635799504
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.0293772887488412
time: 286.9290
Val cmap: 0.8188259
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9699163278378138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0020850995119159215
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.027998572650270292
time: 276.6511
Val cmap: 0.8188231
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9895452412046293
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0017534362294481765
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.008701322565922546
time: 274.0850
Val cmap: 0.8188706
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9365352139861292
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.006581144003848419
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.056883642010022425
time: 289.2956
Val cmap: 0.8187620
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8979651003647979
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.00977639277894515
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.09225850685625692
time: 273.9644
Val cmap: 0.8187571
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.923744430924892
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0052940936771545
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.0709614753979535
time: 273.1586
Val cmap: 0.8187977
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9538471949412404
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0009575734454300686
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.045195231613329556
time: 268.7605
Val cmap: 0.8187597
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8882674642810191
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.011474036346414432
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.10025849937256646
time: 266.7667
Val cmap: 0.8187283
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8286947314022506
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02077647090274399
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.15052879769500543
time: 267.8841
Val cmap: 0.8188113
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9714716550304052
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0030252946925157474
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.02550305027707903
time: 266.2106
Val cmap: 0.8188566
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9391095403849024
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.004261263964775478
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.05662919565032217
time: 270.7753
Val cmap: 0.8187646
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.9892616783403515
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.001279040200774644
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.817837.pth
a3: 0.009459281458873854
Date :05/22/2023, 15:53:32
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.02896462314422123
Date :05/22/2023, 15:53:55
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.08281032825720361
Date :05/22/2023, 15:54:26
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5345864827145483
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.46541351728545166
time: 312.1061
Val cmap: 0.8160583
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.44637352283250403
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5536264771674959
Date :05/22/2023, 16:02:02
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3259964196806915
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.6740035803193085
time: 304.9693
Val cmap: 0.8152780
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3698918690115497
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.6301081309884503
time: 312.8679
Val cmap: 0.8155588
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.38371830581106325
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.6162816941889367
Date :05/22/2023, 16:13:16
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6654524923122334
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.33454750768776664
time: 322.2608
Val cmap: 0.8158392
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4134577707313966
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5865422292686033
time: 308.0251
Val cmap: 0.8157638
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5749099259947025
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4250900740052975
time: 310.8094
Val cmap: 0.8160340
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4300521543180976
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5699478456819024
time: 310.1970
Val cmap: 0.8157782
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.7688579742957881
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.23114202570421194
time: 310.3250
Val cmap: 0.8157511
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5899466248519385
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4100533751480615
time: 311.0452
Val cmap: 0.8160663
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5267630996764572
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4732369003235428
time: 313.7211
Val cmap: 0.8159929
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.7527126991079194
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.24728730089208062
time: 419.2245
Val cmap: 0.8158575
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.84661275938984
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.15338724061015996
time: 399.7470
Val cmap: 0.8154802
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.8552944694685941
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1447055305314059
Date :05/22/2023, 17:08:06
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5
time: 320.1339
Val cmap: 0.8160115
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5
Date :05/22/2023, 17:16:18
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5899466248519385
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4100533751480615
time: 312.2367
Val cmap: 0.8160663
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5899466248519385
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4100533751480615
time: 331.2290
Val cmap: 0.8160663
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5899466248519385
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4100533751480615
Date :05/22/2023, 17:29:22
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5851551026399254
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.41484489736007457
time: 320.1737
Val cmap: 0.8160638
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.47945619894200414
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5205438010579959
time: 308.4547
Val cmap: 0.8159663
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.46248211897618124
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5375178810238188
time: 306.5744
Val cmap: 0.8158535
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.47556521990142947
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5244347800985705
time: 309.3024
Val cmap: 0.8158906
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4415830843308788
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5584169156691212
Date :05/22/2023, 17:52:05
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.634154281985791
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3450481525676464
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.020797565446562527
time: 311.8377
Val cmap: 0.8160020
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.2434485834119058
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.7112822685757687
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.04526914801232551
time: 313.4666
Val cmap: 0.8149026
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.204053919458773
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3067384803947972
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4892076001464299
time: 316.2603
Val cmap: 0.8152128
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.25743619927142475
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.24509653451672928
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.497467266211846
time: 311.1307
Val cmap: 0.8154587
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.26983458751492545
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.09468595903781143
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.6354794534472631
time: 303.9582
Val cmap: 0.8154298
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6354649979757916
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2656439172388445
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.0988910847853639
time: 309.7376
Val cmap: 0.8161387
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.789943885750422
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.10399075105968021
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.10606536318989783
time: 313.1327
Val cmap: 0.8158901
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5226920456308104
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.08751676974975897
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.38979118461943063
time: 368.5470
Val cmap: 0.8163959
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.7327432268616578
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.03028479419243299
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.23697197894590918
time: 451.4295
Val cmap: 0.8163186
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.43740710229628965
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.09226784146806162
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.47032505623564874
time: 368.1118
Val cmap: 0.8164509
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.43752313503913826
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.18262633481879798
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3798505301420638
time: 329.0909
Val cmap: 0.8163625
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4728939506501141
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.010107961896129669
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.5169980874537563
time: 328.9485
Val cmap: 0.8163592
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.8942404993667046
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.04560840496511286
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.06015109566818256
time: 325.5689
Val cmap: 0.8152020
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4111422566049102
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1407860007511795
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.44807174264391025
time: 314.0032
Val cmap: 0.8162566
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5451883555037385
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.08144996953595698
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3733616749603046
time: 328.5388
Val cmap: 0.8163755
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.33530578048859677
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.18416030777289627
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4805339117385069
time: 335.5719
Val cmap: 0.8159900
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5200715435391245
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.06384623466554892
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4160822217953265
time: 321.0652
Val cmap: 0.8163686
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.45082909317320313
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.009110912519853853
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.5400599943069431
time: 333.4369
Val cmap: 0.8164540
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3631382221773407
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.015395808942221954
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.6214659688804374
time: 318.8435
Val cmap: 0.8160839
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3561058171051037
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.007023307417982304
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.636870875476914
time: 310.8034
Val cmap: 0.8160774
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.466512703036066
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.14043562795468797
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.39305166900924593
time: 303.4170
Val cmap: 0.8164818
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.44728874707203325
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.14270113356777767
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.41001011936018905
time: 332.2846
Val cmap: 0.8164458
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.48404884343817395
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.063952014889219
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.451999141672607
time: 309.4147
Val cmap: 0.8164307
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.42205289391328493
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.11913332650334137
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4588137795833737
time: 300.1585
Val cmap: 0.8163945
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.565324175189426
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.05625424483794106
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3784215799726329
time: 316.5554
Val cmap: 0.8163506
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.36743938278809013
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1714684832697071
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4610921339422027
time: 302.3501
Val cmap: 0.8162000
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.31246044777825654
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.21710314591642163
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4704364063053218
time: 298.5792
Val cmap: 0.8159437
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.39648283518094374
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.14869031761953688
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4548268471995194
time: 313.9106
Val cmap: 0.8161596
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.48695824734942594
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.0029038778722428743
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.5101378747783312
time: 318.4479
Val cmap: 0.8164733
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5954328303533931
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.03469007437198342
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3698770952746235
time: 429.9085
Val cmap: 0.8162766
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4930918233681466
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.008347947012830374
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.498560229619023
time: 365.6243
Val cmap: 0.8164597
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.48550136867654003
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.0009201231254174552
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.5135785081980425
time: 328.4487
Val cmap: 0.8164755
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4755679927494657
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.04839664273221414
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4760353645183202
time: 325.5627
Val cmap: 0.8164172
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5120027084443922
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.005648240470546684
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4823490510850611
time: 319.1398
Val cmap: 0.8163899
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5766007234498471
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.03013552083015129
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.39326375572000155
time: 326.5020
Val cmap: 0.8162978
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5018805909693193
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.07496345795786313
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4231559510728176
time: 312.5185
Val cmap: 0.8164174
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6104454246908729
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.03145842243284665
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.35809615287628044
time: 329.2036
Val cmap: 0.8163574
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5524051552077837
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.10797883870343722
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3396160060887791
time: 328.3759
Val cmap: 0.8162786
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.39414773705481027
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3982254384539342
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.20762682449125547
time: 315.9993
Val cmap: 0.8161171
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6398424673216752
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.003272817262418859
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.356884715415906
time: 317.8348
Val cmap: 0.8164659
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6468387674631942
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.030678509852536853
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3224827226842689
time: 309.8167
Val cmap: 0.8164228
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5315315619140962
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.005190215383706759
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.463278222702197
time: 318.0225
Val cmap: 0.8163538
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4759988191782164
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.05729264438265522
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.46670853643912835
time: 299.6264
Val cmap: 0.8164094
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.65299023941438
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.01891077086808563
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.32809898971753443
time: 312.2700
Val cmap: 0.8164514
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.49917779079944835
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.08185620342042245
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.4189660057801292
time: 420.1355
Val cmap: 0.8164277
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5726859970970237
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.041688665767145465
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_132_0.812763.pth
a3: 0.3856253371358308
Date :05/22/2023, 22:10:53
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5367982604090407
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.4446500336723778
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.018551705918581518
time: 270.9424
Val cmap: 0.8188818
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3885410527376084
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.2441654707207727
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.3672934765416189
time: 264.5042
Val cmap: 0.8188818
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.45662963669171913
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.2555671290967377
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.28780323421154325
Date :05/22/2023, 22:22:08
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7608079996031869
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.20266507182963628
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.03652692856717682
time: 267.5446
Val cmap: 0.8189238
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.42359414828573183
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.28962507835586954
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.28678077335839863
time: 272.7502
Val cmap: 0.8190977
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4572324997012996
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.42155610806875166
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.12121139222994881
time: 268.4496
Val cmap: 0.8191115
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.890780357969212
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04102280643504888
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.06819683559573916
time: 266.2335
Val cmap: 0.8191233
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.37889591288126667
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.33736526226212804
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2837388248566053
time: 280.6526
Val cmap: 0.8190104
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4218352384484853
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.14225619437588777
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.43590856717562687
time: 285.1813
Val cmap: 0.8188668
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7611807582749313
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.1310961272697558
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.10772311445531293
time: 272.9537
Val cmap: 0.8191232
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6527530823184534
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.15813946507471394
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.18910745260683265
time: 276.6472
Val cmap: 0.8191984
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5919706918777488
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.24342783145902258
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.16460147666322866
time: 272.3663
Val cmap: 0.8191157
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.40586014959744177
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.5919696269393976
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.0021702234631606476
time: 272.9579
Val cmap: 0.8183638
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.2509979682161459
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.037155636796442806
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.7118463949874113
time: 270.6814
Val cmap: 0.8174125
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8781216937115711
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.005329127687041732
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.11654917860138715
time: 275.8507
Val cmap: 0.8191835
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6262677657894156
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.012867378875249864
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.3608648553353346
time: 279.4489
Val cmap: 0.8192046
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.599244959999552
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.08243866949431378
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.31831637050613426
time: 275.3960
Val cmap: 0.8192612
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5530141119831291
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.07931296440153937
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.36767292361533155
time: 263.7443
Val cmap: 0.8191819
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.658416129070182
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.09398524226967889
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.24759862866013913
time: 266.9443
Val cmap: 0.8194209
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6804243613319142
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.08573376934935771
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.23384186931872808
time: 268.5682
Val cmap: 0.8193866
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7385501144068881
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.08904114497963124
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.17240874061348066
time: 272.3588
Val cmap: 0.8191886
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6831845446519168
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.11036792809967064
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.20644752724841256
time: 271.5991
Val cmap: 0.8192753
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.516391906362489
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.18003294289905458
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.3035751507384564
time: 264.6148
Val cmap: 0.8192191
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6936183924967305
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.063745836465293
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.24263577103797648
time: 272.1056
Val cmap: 0.8194521
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.684356804384494
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.05694810815315292
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2586950874623531
time: 264.1487
Val cmap: 0.8193838
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.715685240569866
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.06239525493452488
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.22191950449560907
time: 263.3506
Val cmap: 0.8193310
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8182195043593015
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.06655296282117548
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.11522753281952305
time: 267.1354
Val cmap: 0.8191676
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6449274352828862
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.103058282176959
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2520142825401548
time: 270.0502
Val cmap: 0.8194087
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6325680166333406
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.11157389440505394
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.25585808896160545
time: 273.8062
Val cmap: 0.8193437
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7966193108916735
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0990792394278357
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.10430144968049082
time: 279.8729
Val cmap: 0.8191345
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5704344547381789
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02983276493186747
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.39973278032995363
time: 271.3252
Val cmap: 0.8190917
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7017057103827826
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.055422222447267216
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.24287206716995016
time: 267.6159
Val cmap: 0.8194598
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7238500403555593
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.05074222154283311
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.22540773810160755
time: 267.8236
Val cmap: 0.8193594
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7711622893371852
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.01884630225240061
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.20999140841041417
time: 275.6917
Val cmap: 0.8192626
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6564072068530126
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.06675593455015442
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.276836858596833
time: 266.5761
Val cmap: 0.8192699
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7208424777128329
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04800839337944948
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.23114912890771758
time: 267.0795
Val cmap: 0.8194573
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7117373128609156
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.03221748163299167
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2560452055060928
time: 264.8659
Val cmap: 0.8193853
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8074922235645504
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.07070580089223763
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.12180197554321195
time: 265.0016
Val cmap: 0.8191978
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7501123955190552
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04836023209935205
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.20152737238159277
time: 431.0243
Val cmap: 0.8192285
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7017186335801463
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.02346932830330478
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2748120381165489
time: 488.1853
Val cmap: 0.8193112
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6126039816838874
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.12582004939334657
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.261575968922766
time: 410.3943
Val cmap: 0.8193239
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5026149036740628
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.1562940352817445
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.34109106104419273
time: 394.1217
Val cmap: 0.8191697
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6543900997575361
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.0022240430746527373
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.3433858571678111
time: 368.4128
Val cmap: 0.8193020
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.58340998540153
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.13482436002955112
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2817656545689189
time: 370.0776
Val cmap: 0.8192909
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6323994138386079
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.10049856797619307
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2671020181851991
time: 384.4259
Val cmap: 0.8192746
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6692540000105027
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.047206218412549836
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2835397815769474
time: 397.9685
Val cmap: 0.8192587
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7180197522052459
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04152616367980756
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2404540841149465
time: 374.4933
Val cmap: 0.8194867
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7629760138362311
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.03545195914251015
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2015720270212587
time: 374.7704
Val cmap: 0.8192720
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7187574721174418
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04574768354892076
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.23549484433363746
time: 380.0038
Val cmap: 0.8194723
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7246689182614339
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04172963779490736
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.23360144394365878
time: 370.5238
Val cmap: 0.8194500
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7865287945299254
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.055982790964789045
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.15748841450528556
time: 392.1350
Val cmap: 0.8191371
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8263248718931929
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.04172610573748137
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.1319490223693257
time: 373.2200
Val cmap: 0.8192199
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7443928563193981
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.013388513036838544
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.24221863064376334
time: 395.8228
Val cmap: 0.8194910
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.846443298228199
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.030077048753223357
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.12347965301857768
time: 410.1226
Val cmap: 0.8191979
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7554088310383618
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.01613659862423364
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.2284545703374046
time: 404.9912
Val cmap: 0.8194373
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.73736706563981
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.009799918759669634
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.25283301560052035
time: 400.0175
Val cmap: 0.8193657
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7006744617038636
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.07364120416098738
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.22568433413514902
time: 413.2331
Val cmap: 0.8193503
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7874621895654044
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.024202818154679045
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.1883349922799166
time: 396.6912
Val cmap: 0.8192211
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6872197671023415
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.08026650409936772
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.23251372879829083
time: 398.4810
Val cmap: 0.8193799
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7431529406688614
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_158_0.817907.pth
a2: 0.05493393396400618
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_106_0.815234.pth
a3: 0.20191312536713243
Date :05/23/2023, 03:34:33
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.36223507279213446
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.09467893126007731
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5430859959477883
time: 431.4749
Val cmap: 0.8194783
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8214638064136115
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.021555453476825637
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.15698074010956287
time: 434.5943
Val cmap: 0.8191057
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.899539393869401
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.08546521642007318
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.014995389710525865
time: 384.3712
Val cmap: 0.8187874
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.24385116999049358
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.4385481740475103
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.3176006559619961
time: 378.6889
Val cmap: 0.8185530
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3730562370656858
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.17282603166628724
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.45411773126802696
time: 389.3013
Val cmap: 0.8193074
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5972146960556246
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.3186245751358684
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.084160728808507
time: 348.6588
Val cmap: 0.8185221
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4209864299092956
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.036216967410422685
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5427966026802817
time: 372.5071
Val cmap: 0.8195815
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.39513000738066256
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.07258265461802582
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5322873380013117
time: 367.5360
Val cmap: 0.8195369
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3437389253413832
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.5075137534399479
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.14874732121866902
time: 282.4785
Val cmap: 0.8179253
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3780604708885313
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.5084110438591596
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.11352848525230902
time: 276.5254
Val cmap: 0.8179363
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.551206402340488
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.17310278935707302
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.27569080830243897
time: 263.9872
Val cmap: 0.8191251
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5356465204743399
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.07889180474594737
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.3854616747797127
time: 265.3134
Val cmap: 0.8195568
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5176589222957882
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.10626898088613573
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.376072096818076
time: 264.9637
Val cmap: 0.8194559
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6773059978704817
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.12025302658309545
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.20244097554642282
time: 263.1217
Val cmap: 0.8189618
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.48452112891949933
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.11560220212749328
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.39987666895300744
time: 264.0394
Val cmap: 0.8194854
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6544960423554638
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.10536847301211621
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.24013548463242002
time: 267.6281
Val cmap: 0.8191281
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4623132960299411
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.07572489512568448
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.46196180884437443
time: 267.6445
Val cmap: 0.8196224
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.45505536115544504
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.0693118837089513
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.4756327551356036
time: 268.5088
Val cmap: 0.8196429
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.24662411542020096
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.062845418900492
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.6905304656793071
time: 265.0335
Val cmap: 0.8193070
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.465528868786491
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.22938371692796355
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.3050874142855454
time: 274.6414
Val cmap: 0.8191718
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.30597641897666483
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.23097976844666546
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.4630438125766697
time: 272.8653
Val cmap: 0.8192226
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.43061130352737187
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.0698902414083808
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.49949845506424734
time: 266.9927
Val cmap: 0.8195748
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4527536992590308
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.09764734477410181
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.44959895596686733
time: 265.9118
Val cmap: 0.8195938
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4540806965666016
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.20587102139406088
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.34004828203933757
time: 269.9100
Val cmap: 0.8192048
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3084926669455481
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.2631175282620546
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.4283898047923973
time: 265.9461
Val cmap: 0.8191529
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4405693494832661
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.2089064321985491
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.3505242183181848
time: 271.0188
Val cmap: 0.8192338
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5134346789271107
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.07919486393786435
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.40737045713502495
time: 276.6398
Val cmap: 0.8195175
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4709349678818986
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.09438745414627348
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.43467757797182793
time: 272.7298
Val cmap: 0.8195199
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.20169887372119344
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.14597257084684212
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.6523285554319644
time: 272.0302
Val cmap: 0.8191836
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4199716856948478
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.09222482814396898
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.48780348616118324
time: 268.1875
Val cmap: 0.8194512
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5651357167486034
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.08061702681017452
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.35424725644122207
time: 269.2863
Val cmap: 0.8194557
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4207108075049074
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.053299491169863544
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.525989701325229
time: 267.6655
Val cmap: 0.8195453
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4901952147460391
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.07714982784019181
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.4326549574137691
time: 266.0151
Val cmap: 0.8195459
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.39709776087801146
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.04331339988849359
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5595888392334949
time: 268.8284
Val cmap: 0.8196032
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.34204770614044006
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.08597141452885326
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5719808793307066
time: 272.2643
Val cmap: 0.8194354
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3954792620853823
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.14010631304003396
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.46441442487458373
time: 268.1368
Val cmap: 0.8194527
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4910478734774121
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.09797660761494309
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.41097551890764483
time: 273.3728
Val cmap: 0.8194869
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.36081852937727643
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.062184529498632846
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5769969411240907
time: 269.0833
Val cmap: 0.8194946
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5834298654407138
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.05337391128168023
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.3631962232776059
time: 274.5819
Val cmap: 0.8195107
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4026035559459722
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.09540858644643191
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5019878576075959
time: 273.9645
Val cmap: 0.8194640
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.45829103434102836
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.08276416808854337
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.4589447975704283
time: 277.3763
Val cmap: 0.8195925
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4656041529320176
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.815220.pth
a3: 0.07789145981957823
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.45650438724840414
Date :05/23/2023, 07:05:29
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8532108879369662
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1467891120630338
time: 272.7142
Val cmap: 0.8191299
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3468927352289172
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.6531072647710827
time: 269.1899
Val cmap: 0.8194616
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8964008946243494
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.10359910537565065
time: 266.2004
Val cmap: 0.8189846
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7330439161161129
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.26695608388388714
time: 267.0779
Val cmap: 0.8193413
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.284511052312864
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.715488947687136
time: 269.5594
Val cmap: 0.8193054
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7369099527815195
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2630900472184805
Date :05/23/2023, 07:32:12
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5449923811167323
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.16474263186935906
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2902649870139086
time: 275.1205
Val cmap: 0.8198332
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4752415887244403
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.022014346293085407
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5027440649824743
time: 267.0005
Val cmap: 0.8196785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.360392558822367
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.05660179041212943
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5830056507655036
time: 263.6998
Val cmap: 0.8195240
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.2240736577251362
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.25135849018033407
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.5245678520945297
time: 264.8728
Val cmap: 0.8193884
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7891412872992485
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.1146136784808336
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.09624503421991791
time: 264.0718
Val cmap: 0.8192782
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.321640462772635
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.1959061917707003
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.4824533454566647
time: 268.8080
Val cmap: 0.8195279
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5515478923191361
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.40527307153177666
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.04317903614908719
time: 268.1719
Val cmap: 0.8198230
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8119663264365624
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.17060226521486144
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.017431408348576153
time: 270.4370
Val cmap: 0.8192896
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.26365458130461644
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.5961272148139999
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.14021820388138365
time: 267.8112
Val cmap: 0.8192710
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.38109404993274654
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.28746985588174373
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.33143609418550973
time: 266.3794
Val cmap: 0.8197038
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6330502731107597
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.1561619965059639
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.21078773038327642
time: 267.2377
Val cmap: 0.8197088
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5981118912985379
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3973980579121436
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.004490050789318446
time: 263.9440
Val cmap: 0.8197968
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5201651239551678
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.1927942899737592
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.287040586071073
time: 266.5418
Val cmap: 0.8198071
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6684464550235433
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.25619471832875895
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.0753588266476978
time: 267.9912
Val cmap: 0.8196511
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4284779790562125
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.36477311733041073
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.20674890361337672
time: 269.0047
Val cmap: 0.8197213
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5481791225288438
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3022267064322172
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.14959417103893896
time: 266.6689
Val cmap: 0.8198940
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4623127655239816
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18743165258534522
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.3502555818906732
time: 269.6929
Val cmap: 0.8196766
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.676087013104663
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18244292971509277
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.14147005718024422
time: 267.0590
Val cmap: 0.8195358
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5621146635846994
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.1816313314464878
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2562540049688128
time: 268.8165
Val cmap: 0.8198280
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7047025050880782
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18633057599435976
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.10896691891756205
time: 266.1331
Val cmap: 0.8194237
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5128845684301833
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3079706740571667
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.17914475751265
time: 267.5571
Val cmap: 0.8197831
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5710683832956516
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.17465241240046597
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.25427920430388246
time: 262.0460
Val cmap: 0.8198123
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5781328561031643
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.16991217549206894
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2519549684047667
time: 267.8242
Val cmap: 0.8198172
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5047933951762259
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18006558430121383
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.31514102052256027
time: 268.1927
Val cmap: 0.8197315
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4344870082008312
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18971826279766424
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.37579472900150457
time: 301.5577
Val cmap: 0.8196767
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6079092131265255
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.21376084282059143
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1783299440528831
time: 310.1314
Val cmap: 0.8197361
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.540603373365129
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.22013456332197612
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2392620633128949
time: 298.0224
Val cmap: 0.8198862
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7310937160221349
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.140426286200311
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1284799977775541
time: 302.9397
Val cmap: 0.8194296
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6353564973916839
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.15132177190820958
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.21332173070010654
time: 296.7704
Val cmap: 0.8196966
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8900709585854596
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.06436390363154673
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.045565137782993675
time: 310.9512
Val cmap: 0.8191028
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4862603883371139
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.22126200052851996
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2924776111343661
time: 298.3880
Val cmap: 0.8197243
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5439084334428406
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.20535376823530066
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.2507377983218588
time: 282.4134
Val cmap: 0.8198799
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5421043770896095
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.27859988777816114
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.17929573513222938
time: 270.6829
Val cmap: 0.8198800
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5264895905365377
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.2922794451799998
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.18123096428346253
time: 271.4029
Val cmap: 0.8198648
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5360567559309649
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.30760112719293187
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.15634211687610322
time: 270.9151
Val cmap: 0.8198663
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4555409603975408
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3166791358668397
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.22777990373561954
time: 276.5867
Val cmap: 0.8197121
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.47811499667457896
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3579496914974526
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1639353118279684
time: 271.3508
Val cmap: 0.8197146
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5559234574060952
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.24759275925315624
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1964837833407486
time: 272.8183
Val cmap: 0.8199077
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6064114993766719
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.2045776058718291
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.18901089475149896
time: 272.7157
Val cmap: 0.8197384
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5621085774402158
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3246057959805523
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.11328562657923194
time: 272.5453
Val cmap: 0.8198784
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.38590925663485054
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.508529935034567
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.10556080833058246
time: 267.8434
Val cmap: 0.8197153
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5506973969775599
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.29612734622208137
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1531752568003587
time: 272.2170
Val cmap: 0.8199128
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4993466718589439
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.34818433280096284
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1524689953400933
time: 274.7685
Val cmap: 0.8196998
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5855199017860329
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.2830008214839384
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.13147927673002874
time: 270.4834
Val cmap: 0.8198194
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5370729619650849
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3006858963896668
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1622411416452483
time: 269.6394
Val cmap: 0.8198682
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6252940488789522
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18473835156182766
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1899675995592201
time: 268.9324
Val cmap: 0.8196918
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4921514872440045
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.422805113184903
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.08504339957109255
time: 265.0968
Val cmap: 0.8197946
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5537928557074684
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.3166225115115851
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1295846327809465
time: 265.7138
Val cmap: 0.8199063
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5899877009075642
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.28139881766871006
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.1286134814237257
time: 272.5235
Val cmap: 0.8198358
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6567309909664777
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.1975605077616019
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.14570850127192042
time: 276.7812
Val cmap: 0.8196218
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5632607975872325
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.23680255378944237
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.19993664862332516
time: 272.5535
Val cmap: 0.8198832
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5645299864761291
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.23761941916067347
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.19785059436319746
time: 271.7578
Val cmap: 0.8198766
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5243150201777327
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.2507876424353529
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.22489733738691445
time: 276.4451
Val cmap: 0.8198416
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6100076484745023
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.18892378546117278
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.20106856606432494
time: 290.2119
Val cmap: 0.8196860
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5593661076050928
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a3: 0.27524852874177824
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a2: 0.165385363653129
Date :05/23/2023, 11:52:35
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
Date :05/23/2023, 11:52:59
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 4
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.23219362099941404
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.18260964571471464
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.5851967332858714
time: 367.1850
Val cmap: 0.8125288
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7752875276898485
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.18056950413384526
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.044142968176306197
time: 293.9092
Val cmap: 0.8130724
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.20574487484132015
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.19466098379465352
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.5995941413640262
time: 279.7950
Val cmap: 0.8124671
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7140322304871161
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.19809998726257969
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.08786778225030425
time: 287.3048
Val cmap: 0.8129837
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.21502862487522362
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.203271896566006
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.5816994785587705
time: 280.8312
Val cmap: 0.8125171
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6837441276019842
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.1559282978775391
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.1603275745204767
time: 277.0659
Val cmap: 0.8129527
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.495823329426427
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.41583605658562606
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.08834061398794701
time: 279.0401
Val cmap: 0.8128379
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.5231051459145991
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.403402301359935
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.0734925527254659
time: 271.7130
Val cmap: 0.8128837
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.5943649099535706
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.004002932640016633
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.4016321574064128
time: 265.3353
Val cmap: 0.8124446
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.627104582053287
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.12906642278142838
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.2438289951652846
time: 267.8005
Val cmap: 0.8129443
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.87936890359289
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.0018740684662669482
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.11875702794084306
time: 269.8465
Val cmap: 0.8126005
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7872693767990252
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.19773021603908525
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.01500040716188955
time: 263.6304
Val cmap: 0.8130856
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.8991311199341867
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.03330678280162496
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.06756209726418833
time: 267.1149
Val cmap: 0.8127928
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.8107227219141242
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.15682385823973594
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.032453419846139864
time: 267.0541
Val cmap: 0.8130482
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7644939458228988
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2239594850700342
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.011546569107067056
time: 267.4400
Val cmap: 0.8131392
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7782921261523256
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2144045120357779
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.0073033618118965304
time: 271.8010
Val cmap: 0.8130908
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7032828127180821
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.24573266862995552
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.05098451865196235
time: 272.0833
Val cmap: 0.8132135
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6731154941157084
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.24684217721508891
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.08004232866920272
time: 272.3827
Val cmap: 0.8130704
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.5967964286061729
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.26428752373319914
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.13891604766062798
time: 273.2302
Val cmap: 0.8129232
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7225757692219199
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2488360267338303
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.028588204044249804
time: 272.1027
Val cmap: 0.8131887
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.5234952948743601
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.29806014079337206
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.17844456433226785
time: 269.9419
Val cmap: 0.8128264
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7108476511395436
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.24319631516359763
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.045956033696858745
time: 267.4631
Val cmap: 0.8132448
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6621410146051873
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.25766404960018396
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.08019493579462877
time: 264.7856
Val cmap: 0.8130748
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.697383255400334
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.23470016480297606
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.06791657979668997
time: 268.3465
Val cmap: 0.8131329
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7301282931530879
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.11057194476240985
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.15929976208450225
time: 270.3377
Val cmap: 0.8129786
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.8473683354334273
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.059061051228400094
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.09357061333817264
time: 267.8803
Val cmap: 0.8128481
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7398335901250109
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.22414801937856554
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.036018390496423525
time: 264.2642
Val cmap: 0.8131938
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.835475559438565
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.07603240519967086
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.08849203536176414
time: 265.4251
Val cmap: 0.8129166
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.8343385282228335
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.04893372957122112
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.11672774220594538
time: 266.8731
Val cmap: 0.8128024
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.4648352720139799
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.3028595935535472
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.23230513443247292
time: 268.0589
Val cmap: 0.8126498
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6304214761228226
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2769786311402624
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.09259989273691499
time: 269.7482
Val cmap: 0.8129551
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7340413294347289
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.22951543077334197
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.03644323979192915
time: 268.6443
Val cmap: 0.8131901
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7409473632414594
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.21593264855144706
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.04311998820709356
time: 269.0436
Val cmap: 0.8131500
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7539658799994415
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.17523398073825908
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.07080013926229939
time: 272.7469
Val cmap: 0.8130789
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.8031158849490329
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.1796910019243457
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.017193113126621445
time: 279.9449
Val cmap: 0.8130923
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7146500557991061
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.22056833723107888
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.064781606969815
time: 277.8483
Val cmap: 0.8131405
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6612936177234583
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2327929115899226
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.1059134706866191
time: 279.0206
Val cmap: 0.8131682
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7502147315822553
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.20905217411084986
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.04073309430689487
time: 277.7152
Val cmap: 0.8131025
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6982984812951971
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.1916486821849984
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.11005283651980449
time: 270.5957
Val cmap: 0.8130360
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7841230705362856
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.19115946889995694
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.024717460563757454
time: 268.0880
Val cmap: 0.8130457
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7059315304705236
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.23544834529592326
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.058620124233553145
time: 269.5959
Val cmap: 0.8131400
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7393977537711914
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2256451433971948
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.03495710283161377
time: 273.7362
Val cmap: 0.8131812
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7112594943651045
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.24379666239885245
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.04494384323604306
time: 273.6313
Val cmap: 0.8132364
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6473586386193372
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2710454700705267
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.08159589131013611
time: 276.2612
Val cmap: 0.8129900
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6807163374920621
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2425936909504729
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.07668997155746504
time: 268.9206
Val cmap: 0.8130780
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6137098719138128
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.29006443318672326
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.09622569489946398
time: 267.0433
Val cmap: 0.8129556
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.5860788881549417
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.3136041337175672
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.10031697812749113
time: 269.6361
Val cmap: 0.8128888
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7713550357480645
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.208160684342407
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.020484279909528474
time: 270.9901
Val cmap: 0.8130884
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.8069040215828992
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.1849351283037553
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.008160850113345497
time: 272.1223
Val cmap: 0.8130814
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6865858515519188
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.24723209913248306
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.06618204931559818
time: 274.9502
Val cmap: 0.8130971
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7182794043342358
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.20389326216701675
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.07782733349874749
time: 272.9168
Val cmap: 0.8130581
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7337205936985204
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2282028861806292
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.038076520120850416
time: 273.4344
Val cmap: 0.8131915
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.7491726771343483
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.22853556569660086
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.022291757169050824
time: 275.5949
Val cmap: 0.8131844
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_142_0.812497.pth
a1: 0.6454984617244298
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_176_0.811773.pth
a2: 0.2560207134896187
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_4_model_epoch_136_0.811644.pth
a3: 0.09848082478595149
Date :05/23/2023, 16:11:25
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5206223267669783
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2844377951934543
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.19493987803956742
time: 271.4262
Val cmap: 0.8191786
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6564279344809966
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.11425523918337809
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.22931682633562533
time: 258.9401
Val cmap: 0.8193761
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3962786177744956
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.18825143300103572
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.41546994922446867
time: 276.3432
Val cmap: 0.8193265
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2067182080375995
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3978861110487445
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.39539568091365596
time: 270.6651
Val cmap: 0.8191531
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8858071929166342
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03237410838934647
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.0818186986940193
time: 259.8843
Val cmap: 0.8186846
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5638294511326556
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3443707513816022
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.09179979748574219
time: 269.0962
Val cmap: 0.8188386
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4172657847196426
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2289501866821699
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.35378402859818747
time: 266.9679
Val cmap: 0.8194992
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3011667292969254
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2795771467071591
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.41925612399591555
time: 259.2347
Val cmap: 0.8192731
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6799679760105517
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.11378968967761686
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.20624233431183142
time: 262.1753
Val cmap: 0.8193542
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7182478236371268
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.16134547397239463
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.12040670239047857
time: 264.7713
Val cmap: 0.8189782
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4142202559154806
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.5741856077230765
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.011594136361442908
time: 268.0274
Val cmap: 0.8182956
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5284193962535721
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08251069448349732
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.3890699092629305
time: 265.9177
Val cmap: 0.8194385
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.451824983808834
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.050880384617377955
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.49729463157378806
time: 277.6054
Val cmap: 0.8191779
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3114458041834437
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.016994329853754653
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.6715598659628017
Date :05/23/2023, 17:12:07
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6487315021989492
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.33387751675099137
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.017390981050059484
time: 261.8722
Val cmap: 0.8183217
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.826714264541478
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0021707237270621967
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.1711150117314598
time: 264.5701
Val cmap: 0.8190007
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.65975901140445
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0187801505216692
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.32146083807388076
time: 261.7865
Val cmap: 0.8191050
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7317449924262789
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.21610458305646568
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.052150424517255434
time: 260.4876
Val cmap: 0.8184253
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6694958568850813
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3143067945836214
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.01619734853129734
time: 259.7388
Val cmap: 0.8182941
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6695996186524728
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.31667249578746326
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.01372788556006399
time: 259.6033
Val cmap: 0.8182774
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.48670154799118437
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.45127438838587386
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.06202406362294177
time: 262.7106
Val cmap: 0.8185438
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8539612894647981
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.1002334685635121
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.045805241971689795
time: 266.9832
Val cmap: 0.8185699
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.380094979351851
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.35930047702444845
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.26060454362370056
time: 269.8343
Val cmap: 0.8189015
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4194200622788749
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.14817068412000955
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4324092536011156
time: 264.8673
Val cmap: 0.8190198
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2600035773908033
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.6092045910718366
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.13079183153736007
time: 295.5834
Val cmap: 0.8186916
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5155665050753149
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0853196930434405
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3991138018812446
time: 301.2910
Val cmap: 0.8190255
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5457443815442227
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.014854162460545729
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4394014559952316
time: 268.7978
Val cmap: 0.8191007
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5977577810262225
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.012976597726370177
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3892656212474074
time: 267.4179
Val cmap: 0.8190922
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5382191394955259
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.054614087322328024
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.40716677318214606
time: 263.4612
Val cmap: 0.8190566
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7268938649967923
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03504051201628852
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.23806562298691916
time: 261.4208
Val cmap: 0.8190201
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5805580113757226
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0014956163257720916
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4179463722985053
time: 259.6263
Val cmap: 0.8191620
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7818430353647833
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0346919209828732
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.1834650436523435
time: 264.5909
Val cmap: 0.8190358
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6121758793829288
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0768005101219009
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.31102361049517024
time: 263.7369
Val cmap: 0.8190344
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7593657850509861
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03524839321090026
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.20538582173811368
time: 266.0532
Val cmap: 0.8190347
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8671203203720707
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008732423574796068
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.12414725605313329
time: 263.1996
Val cmap: 0.8188071
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5712619574596577
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.11715259590156804
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3115854466387743
time: 263.1902
Val cmap: 0.8190181
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5893304465824779
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05588975168884479
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3547798017286773
time: 259.1698
Val cmap: 0.8189734
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.47942197999279956
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.13663669809357304
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3839413219136274
time: 260.1464
Val cmap: 0.8189909
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6357110410678253
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06502177390268124
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.29926718502949345
time: 265.5360
Val cmap: 0.8190329
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5373721415533348
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0012279448327102858
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.46139991361395494
time: 271.0194
Val cmap: 0.8191352
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8994445501722745
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0022876606407899276
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.09826778918693553
time: 265.7930
Val cmap: 0.8186950
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7054301201621302
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0322813137031197
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.26228856613475005
Date :05/23/2023, 19:17:22
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3011667292969254
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2795771467071591
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_133_0.815334.pth
a3: 0.41925612399591555
Date :05/23/2023, 19:18:00
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3011667292969254
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2795771467071591
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.41925612399591555
time: 355.4091
Val cmap: 0.8192731
{'a1': 0.4307447249716092, 'a2': 0.266609492351633}
time: 469.0157
Val cmap: 0.8190415
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6934726416321814
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.044167740301533503
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.26235961806628516
Date :05/23/2023, 19:27:53
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4172657847196426
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2289501866821699
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.35378402859818747
time: 476.9722
Val cmap: 0.8190465
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.630721602599039
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08597404889012938
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.28330434851083164
time: 349.1015
Val cmap: 0.8194992
{'a1': 0.5985319234385722, 'a2': 0.0634064209895985}
time: 287.3082
Val cmap: 0.8190360
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6527681511165114
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0712606175624012
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.27597123132108736
time: 264.5708
Val cmap: 0.8190168
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5541398164335557
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.005457280315991279
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.440402903250453
time: 263.2677
Val cmap: 0.8190811
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5755398289823167
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02674152980428771
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.39771864121339556
time: 266.5670
Val cmap: 0.8190414
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5278779409377513
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0009131097494607353
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.47120894931278795
time: 274.4448
Val cmap: 0.8190959
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6254052693392419
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.051028606099673066
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.323566124561085
time: 264.1852
Val cmap: 0.8190630
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6895834869179831
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0171841861982272
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.2932323268837897
time: 262.6778
Val cmap: 0.8190520
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6681496103256002
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.023773536437506168
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.30807685323689366
time: 268.1781
Val cmap: 0.8190505
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5883561510229939
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05694981922421402
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3546940297527921
time: 262.1036
Val cmap: 0.8189759
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4822985636874361
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.1642228159097442
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.35347862040281963
time: 261.7931
Val cmap: 0.8189131
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6531732231249046
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.022110799540161652
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3247159773349338
time: 265.2720
Val cmap: 0.8190391
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.44289940427332875
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.11199875264615342
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4451018430805178
time: 266.7435
Val cmap: 0.8190373
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5240021744746235
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.003939350128068319
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.47205847539730816
time: 261.2888
Val cmap: 0.8190763
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5401705804676397
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0870644829614949
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.37276493657086546
time: 263.9700
Val cmap: 0.8190337
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5591162609918994
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0025884049874093876
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.43829533402069126
time: 261.1018
Val cmap: 0.8190894
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5060119023033433
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.10534751713694317
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.38864058055971357
time: 261.3278
Val cmap: 0.8190254
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5950321193477314
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.044977400418610106
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.35999048023365854
time: 261.4434
Val cmap: 0.8190249
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5088440209827362
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06522932490955531
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4259266541077085
time: 261.3331
Val cmap: 0.8190956
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5439406580484282
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.026947900081063406
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4291114418705084
time: 266.8787
Val cmap: 0.8191422
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6077926009620919
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.023816811450994495
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3683905875869136
time: 267.6966
Val cmap: 0.8190706
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5680479421600527
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04255412690757848
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3893979309323688
time: 265.3682
Val cmap: 0.8190389
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.45019084343499816
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.1996323760057086
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.35017678055929324
time: 264.9635
Val cmap: 0.8189311
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5425446996321442
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0013511458591750672
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4561041545086807
time: 269.4281
Val cmap: 0.8191291
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5590928284836283
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0273004599051192
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4136067116112525
time: 262.0395
Val cmap: 0.8191235
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6183794264947879
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.01872921901747649
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3628913544877356
time: 262.4948
Val cmap: 0.8190603
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5445181080026772
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.07818950801789848
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.37729238397942433
time: 263.7035
Val cmap: 0.8190464
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4973289079207528
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.045662783928436514
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.45700830815081067
time: 263.1626
Val cmap: 0.8191227
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.49536810803801506
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0916545959069986
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4129772960549864
time: 299.7684
Val cmap: 0.8190260
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3995268214552563
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.1195265920498615
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4809465864948822
time: 283.2681
Val cmap: 0.8190793
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4627011992297466
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06157992213276684
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4757188786374865
time: 265.0111
Val cmap: 0.8190208
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5098028970071902
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.039612194937194777
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4505849080556151
time: 267.9020
Val cmap: 0.8191221
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.47397143897779764
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.07728967119717298
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4487388898250294
time: 269.0250
Val cmap: 0.8190804
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5177638969332145
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04756671104718267
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.43466939201960286
time: 262.5397
Val cmap: 0.8191069
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4981991390833903
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03807604479265406
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.46372481612395566
time: 268.9515
Val cmap: 0.8191076
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5709221971119407
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.03447826414462665
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.3945995387434327
time: 265.6548
Val cmap: 0.8190689
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5347153866905301
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.017490703627994052
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.44779390968147587
time: 265.2270
Val cmap: 0.8191320
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5456293481825917
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.016948995169949396
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4374216566474589
Date :05/23/2023, 22:23:26
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6991237430672611
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_133_0.811580.pth
a3: 0.2699747357004149
Date :05/23/2023, 22:23:46
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4999893232428259
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.08557453627531986
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_133_0.811580.pth
a3: 0.4144361404818543
time: 334.6271
Val cmap: 0.8190773
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5293715985564026
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05744914855524921
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.4131792528883482
time: 407.4216
Val cmap: 0.8164647
{'a1': 0.4999893232428259, 'a2': 0.08557453627531986}
Date :05/23/2023, 22:33:08
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.8637459097040571
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.11928603392766483
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_133_0.811580.pth
a3: 0.016968056368278098
time: 464.5744
Val cmap: 0.8190924
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5895122738580588
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.02844253020330612
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_152_0.817305.pth
a3: 0.38204519593863506
Date :05/23/2023, 22:35:48
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.18743285115063807
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5343180483573658
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_133_0.811580.pth
a3: 0.27824910049199614
time: 307.2931
Val cmap: 0.8156418
{'a1': 0.18743285115063807, 'a2': 0.5343180483573658}
Date :05/23/2023, 22:41:57
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4361565433262633
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.36436996709235997
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_136_0.811970.pth
a3: 0.19947348958137673
time: 310.2180
Val cmap: 0.8164508
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.1413761402044753
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.31790245480044227
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_136_0.811970.pth
a3: 0.5407214049950824
time: 304.3950
Val cmap: 0.8153328
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5106993242936426
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.39271849469416836
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_136_0.811970.pth
a3: 0.09658218101218902
time: 304.9768
Val cmap: 0.8163656
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4684911285678047
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.5190316679610827
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_136_0.811970.pth
a3: 0.012477203471112586
time: 310.2536
Date :05/23/2023, 23:03:26
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4703273895606145
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.19324624402116922
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3364263664182163
time: 320.6725
Val cmap: 0.8164909
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.10988571814246147
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.8106050696852792
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.07950921217225926
time: 311.5576
Val cmap: 0.8145643
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.2160966833366815
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.395789671398463
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3881136452648555
time: 352.3689
Val cmap: 0.8159097
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.1939930594672168
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.36321720588701045
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.44278973464577276
time: 460.3359
Val cmap: 0.8158584
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.26443821278722
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.6144084833708667
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.12115330384191325
time: 385.7887
Val cmap: 0.8155676
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6610347554747664
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.18688236667469177
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.1520828778505418
time: 340.8535
Val cmap: 0.8163728
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.37004547876035676
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.20968492424010052
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.4202695969995427
time: 335.0717
Val cmap: 0.8163007
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6161758687401742
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2767407466245444
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.10708338463528144
time: 326.2323
Val cmap: 0.8162966
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.15363334241555907
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1526133352172817
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.6937533223671593
time: 329.2721
Val cmap: 0.8150934
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.13893999776111735
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.6053013487412597
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.25575865349762295
time: 325.9302
Val cmap: 0.8154842
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.857714180397871
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.0010866340428951626
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.1411991855592339
time: 326.7770
Val cmap: 0.8152602
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5640196350304937
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.12039025709782938
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.31559010787167696
time: 340.5938
Val cmap: 0.8165985
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5135199938359101
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.09293343308464315
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3935465730794468
time: 333.0208
Val cmap: 0.8163223
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4292480102078601
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.09759020477176297
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.473161785020377
time: 327.9325
Val cmap: 0.8162006
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5619787290730281
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.10996606256535053
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.32805520836162133
time: 337.8238
Val cmap: 0.8166136
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6053120741846197
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.037773135034976424
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.35691479078040383
time: 328.4218
Val cmap: 0.8165161
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.7137575027389872
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.0725848800451398
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.213657617215873
time: 306.5150
Val cmap: 0.8163345
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5310681223447661
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1246682372497403
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3442636404054936
time: 320.0491
Val cmap: 0.8166082
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3317904165844018
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.008022714680309434
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.6601868687352888
time: 310.1793
Val cmap: 0.8155094
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4288522065317013
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.04507815315470032
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.5260696403135984
time: 314.4207
Val cmap: 0.8161665
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5302261327008938
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.13552906760338712
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3342447996957191
time: 306.7270
Val cmap: 0.8166065
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5416933042650677
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.12010156766510753
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3382051280698248
time: 316.0462
Val cmap: 0.8165626
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.49105416416292363
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.14308640907233633
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3658594267647401
time: 314.6987
Val cmap: 0.8165218
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.7240891328282886
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.07555504843384056
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.20035581873787087
time: 308.6481
Val cmap: 0.8163036
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5570118651550773
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.14524772017955154
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.29774041466537116
time: 337.9655
Val cmap: 0.8165158
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.43758010988682494
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.044715150381098176
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.5177047397320769
time: 453.6199
Val cmap: 0.8161154
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.49833152800073743
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1068485212606685
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.39481995073859405
time: 361.3848
Val cmap: 0.8163970
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3767925868487255
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2372021450167371
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3860052681345374
time: 321.5294
Val cmap: 0.8162796
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6236601406207156
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.0695243592292171
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3068155001500673
time: 332.8577
Val cmap: 0.8165387
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4778576305408404
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.17551526326939276
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.34662710618976683
time: 320.4641
Val cmap: 0.8165709
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5532469313680173
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1244078889847728
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.32234517964720993
time: 307.9845
Val cmap: 0.8166008
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.551634155450862
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1363610341447599
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3120048104043781
time: 306.5525
Val cmap: 0.8166035
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.524396053688881
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1475473818602782
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.32805656445084086
time: 305.3675
Val cmap: 0.8166303
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.46638307768131715
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.16443842951944698
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.36917849279923587
time: 305.7568
Val cmap: 0.8164430
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4966309939197768
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.19109410421585943
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.31227490186436374
time: 320.1747
Val cmap: 0.8165615
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6626611714025963
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.11019040662204785
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.22714842197535587
time: 418.1715
Val cmap: 0.8164376
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5262961264749744
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.14395201823178133
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.3297518552932443
time: 396.5529
Val cmap: 0.8165991
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5766154591794409
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1695852443233546
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_142_0.812817.pth
a3: 0.2537992964972045
Date :05/24/2023, 02:41:58
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_s
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4133430165342079
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.20428020502652253
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.38237677843926954
time: 326.6157
Val cmap: 0.8166843
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4045343413657281
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.21230957576084664
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.3831560828734253
time: 326.8998
Val cmap: 0.8167132
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.16653146248589082
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.25278379462605854
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.5806847428880506
time: 330.0386
Val cmap: 0.8158246
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.762260853591228
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.08026000707540465
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.15747913933336738
time: 327.1044
Val cmap: 0.8160353
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.7248875946028102
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.02043090488633895
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.25468150051085087
time: 303.7452
Val cmap: 0.8161474
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.17905309409078393
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.6131567077308537
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2077901981783623
time: 330.3126
Val cmap: 0.8156148
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.39305444379649246
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3595550100359338
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.24739054616757372
time: 312.3877
Val cmap: 0.8165856
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.36012366221247794
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.15508498336494675
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.4847913544225753
time: 305.3291
Val cmap: 0.8163467
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.8100308737528524
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.08248238315302357
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.107486743094124
time: 302.3235
Val cmap: 0.8156558
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6586814992241162
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2900592829621845
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.0512592178136993
time: 320.2578
Val cmap: 0.8160911
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5575381498431947
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.15043739095257147
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2920244592042338
time: 318.7928
Val cmap: 0.8165364
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4704838207895654
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.22138003245115814
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.3081361467592765
time: 319.4297
Val cmap: 0.8167354
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5168862967719189
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3061903531694602
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.17692335005862092
time: 369.0488
Val cmap: 0.8164975
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3204282424891154
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.38276456704029405
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.29680719047059057
time: 335.7872
Val cmap: 0.8164414
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5723590440809516
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.19728795026331575
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.23035300565573263
time: 321.7446
Val cmap: 0.8166144
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4835232389237562
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.23580406541087134
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2806726956653724
time: 306.2064
Val cmap: 0.8166574
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.8583237464554434
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.03748960345211104
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.10418665009244556
time: 312.5118
Val cmap: 0.8153039
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.2717539310845334
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.4255338668428483
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.30271220207261834
time: 329.3207
Val cmap: 0.8164632
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.45911517982454214
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.1495853689084113
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.3912994512670466
time: 317.3885
Val cmap: 0.8164261
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.26789586334548615
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.47855812779767243
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.25354600885684137
time: 343.4042
Val cmap: 0.8163622
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6345542756940414
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.17477323594580027
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.1906724883601583
time: 325.0805
Val cmap: 0.8164805
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.43903932362171966
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2240904365203413
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.33687023985793907
time: 304.0476
Val cmap: 0.8167006
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.43100508021554856
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.25028270329368196
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.31871221649076953
time: 301.8270
Val cmap: 0.8167223
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4955691960607834
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.259053464800048
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2453773391391686
time: 308.5587
Val cmap: 0.8167117
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3898382127913268
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3083065897497663
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.3018551974589069
time: 304.3987
Val cmap: 0.8164534
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.43970430439740477
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.11369816099480538
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.4465975346077899
time: 316.3392
Val cmap: 0.8164432
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3447550848072859
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.27551302578645764
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.37973188940625646
time: 316.7829
Val cmap: 0.8164993
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5545899535590874
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.19883600929259235
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2465740371483203
time: 372.8942
Val cmap: 0.8166685
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.3070461427024457
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.33895963459225237
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.35399422270530195
time: 357.9236
Val cmap: 0.8162832
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.39868770056119235
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.21426494288101045
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.38704735655779715
time: 311.7916
Val cmap: 0.8166710
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4676535667860957
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.24139237850080392
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2909540547131004
time: 320.0575
Val cmap: 0.8167069
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4782406813816137
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2642946221288309
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2574646964895554
time: 315.3753
Val cmap: 0.8167349
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4207245492168272
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2641818083898779
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.31509364239329485
time: 312.3865
Val cmap: 0.8166846
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5162472693227924
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.23834868496249756
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.24540404571471003
time: 323.4531
Val cmap: 0.8167254
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5155323607780681
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.22788530729221773
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2565823319297142
time: 411.2679
Val cmap: 0.8168055
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5193742722724956
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.19094394501663292
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2896817827108715
time: 340.9639
Val cmap: 0.8166902
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5968224190144559
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.22414119402957008
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.17903638695597404
time: 313.6660
Val cmap: 0.8164172
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5334289556198412
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.22886941438809394
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2377016299920649
time: 329.7516
Val cmap: 0.8166968
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4966992476308061
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.28150403255827294
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.22179671981092097
time: 327.4210
Val cmap: 0.8165778
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6063270645972664
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2125339774462692
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.18113895795646442
time: 313.7830
Val cmap: 0.8164542
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.6849386951686787
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.181493761303519
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.13356754352780234
time: 314.3478
Val cmap: 0.8163381
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4652325246829447
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.25513406426980756
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2796334110472477
time: 372.5962
Val cmap: 0.8167099
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5433855008210147
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.24994002490284056
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.20667447427614477
time: 344.8559
Val cmap: 0.8166503
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4328151881716032
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.29799114902586654
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2691936628025303
time: 320.1858
Val cmap: 0.8166766
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5098376577026722
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2448376202641535
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2453247220331743
time: 323.0650
Val cmap: 0.8167122
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5837904131056485
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.21091501759261944
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.20529456930173207
time: 331.8658
Val cmap: 0.8165508
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.37995606106001933
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.3242952696076842
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.2957486693322965
time: 318.0531
Val cmap: 0.8164650
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.4869786265535882
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2660625033305403
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.24695887011587142
time: 318.8502
Val cmap: 0.8166707
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_154_0.813581.pth
a1: 0.5626447959755103
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_171_0.813307.pth
a2: 0.2795882374033032
none: finaltrainv2s/finetune_tf_efficientnetv2_s_fold_1_model_epoch_185_0.813505.pth
a3: 0.1577669666211865
Date :05/24/2023, 07:18:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7192126118229516
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a2: 0.20752162182283998
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.06837835277400091
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a4: 0.004887413580207514
time: 278.4757
Val cmap: 0.8194033
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.7781577210135854
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a2: 0.21280344701256254
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.0053097814215307074
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a4: 0.003729050552321372
time: 273.0121
Val cmap: 0.8193665
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.34187994241877223
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_155_0.818406.pth
a2: 0.20972434564483805
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.43704077085794785
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a4: 0.011354941078441927
Date :05/24/2023, 07:29:38
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3874601802529529
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.21614873472874774
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.39639108501829934
time: 277.3695
Val cmap: 0.8194326
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.10902858025808798
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.45436406073208413
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.43660735900982794
time: 281.3282
Val cmap: 0.8190067
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.1951074117600843
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.26614882012294183
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.5387437681169739
time: 270.2203
Val cmap: 0.8190195
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.34094894306787926
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.06099328733102638
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.5980577696010944
time: 270.0131
Val cmap: 0.8193479
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5478443213136449
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.05175196585594244
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.40040371283041265
time: 271.8958
Val cmap: 0.8193554
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3587442908605968
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.31968868222493557
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.32156702691446765
time: 265.9937
Val cmap: 0.8193273
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.613761043660327
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.09708618477898506
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.2891527715606879
time: 269.6751
Val cmap: 0.8193251
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.2394552125004295
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.24411772028495538
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.5164270672146152
time: 265.2474
Val cmap: 0.8191194
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.6222864877191847
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.17764645016515007
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.20006706211566522
time: 276.8571
Val cmap: 0.8193288
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.724033409845826
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.1226574565102885
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.15330913364388551
time: 286.8728
Val cmap: 0.8190847
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.8922251404412533
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.08610966827767613
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.021665191281070535
time: 263.3659
Val cmap: 0.8190805
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4651429513167359
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.13765376832448478
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.39720328035877933
time: 268.7016
Val cmap: 0.8193470
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4734377766791854
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.154897012123847
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.3716652111969676
time: 266.7016
Val cmap: 0.8192513
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.36471089946764823
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.17537252009678483
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.45991658043556694
time: 284.9352
Val cmap: 0.8193774
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.3742029666839797
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.13830216061396333
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.487494872702057
time: 281.8369
Val cmap: 0.8193832
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.41095979439063435
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.1080279941718284
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.48101221143753725
time: 276.5950
Val cmap: 0.8195099
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.44134502160140915
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.21158506736927435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.34706991102931645
time: 279.0007
Val cmap: 0.8193564
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.22655504027452125
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.04200158219468231
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.7314433775307965
time: 266.5496
Val cmap: 0.8193152
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.2807033239165925
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.13255693518254363
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.5867397409008639
time: 262.9621
Val cmap: 0.8191633
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.4158798868649785
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.28420722474439414
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.2999128883906274
time: 266.5771
Val cmap: 0.8193816
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_176_0.818862.pth
a1: 0.5213580249584996
none: finaltrainv2b2/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_182_0.818910.pth
a3: 0.23446750372383765
none: finaltrainv2b1/finetune_tf_efficientnetv2_b2_fold_1_model_epoch_157_0.818312.pth
a2: 0.24417447131766276
Date :05/24/2023, 09:04:47
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
Date :05/24/2023, 09:04:57
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
Date :05/24/2023, 09:05:36
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.4768758383926789
0.3724220104501806
0.15070215115714053
Date :05/24/2023, 09:05:57
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.5943113427612857
0.348959060862853
0.05672959637586128
Date :05/24/2023, 09:06:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.4399409242657303
0.0336948975507746
0.5263641781834951
Date :05/24/2023, 09:06:42
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.1089124934806569
0.7311942503282568
0.1598932561910863
Date :05/24/2023, 09:09:18
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.21297417843009586
0.42744320528579094
0.35958261628411325
time: 542.2207
Val cmap: 0.8194992
0.21323663474616536
0.5413886345272779
0.2453747307265567
time: 664.4856
Val cmap: 0.8194992
0.1806743514985116
0.43585503268209946
0.3834706158193889
Date :05/24/2023, 09:31:57
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.7620941956111508
0.05935298094807921
0.17855282344077
Date :05/24/2023, 09:32:08
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.42935727828832027
0.14295073607374525
0.4276919856379345
time: 436.8977
Val cmap: 0.8336551
0.5616643638166429
0.11787340150486159
0.32046223467849555
time: 453.3699
Val cmap: 0.8330104
0.5278368131137849
0.012342423996417703
0.45982076288979734
time: 441.3379
Val cmap: 0.8307073
0.3964127532035425
0.0928187376560907
0.5107685091403668
time: 441.6782
Val cmap: 0.8325324
0.7622927337580433
0.052815467829891806
0.1848917984120649
time: 521.9263
Val cmap: 0.8296969
0.8284449634357445
0.05803987147476693
0.1135151650894886
time: 664.3300
Val cmap: 0.8281284
0.3754946848752839
0.1385365224475543
0.48596879267716175
time: 620.3923
Val cmap: 0.8333705
0.1488215921108581
0.3605790899170338
0.4905993179721081
Date :05/24/2023, 10:39:48
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.31151447157680023
0.6884855284231998
Date :05/24/2023, 10:40:05
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.6262930431350404
0.3737069568649596
Date :05/24/2023, 10:40:51
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.5709766412517955
0.4290233587482045
time: 339.4379
Val cmap: 0.8306517
0.10532629490965172
0.8946737050903483
time: 322.7228
Val cmap: 0.8244541
0.42930287673800993
0.5706971232619901
time: 326.4377
Val cmap: 0.8301526
0.5761304192872941
0.42386958071270586
time: 331.6092
Val cmap: 0.8305902
0.8714305532345183
0.12856944676548165
Date :05/24/2023, 11:04:05
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.8733658523335708
0.1226615365055446
0.003972611160884626
Date :05/24/2023, 11:04:17
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b2
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
0.30564299056059296
0.12805941272407026
0.5662975967153367
time: 548.7785
Val cmap: 0.8325313
0.47123047968263665
0.39180679727012124
0.1369627230472421
time: 675.9245
Val cmap: 0.8339213
0.4444256100798707
0.4528626620948406
0.1027117278252887
time: 614.2316
Val cmap: 0.8332803
0.19088661050582864
0.593017843402084
0.21609554609208736
time: 592.9403
Val cmap: 0.8328017
0.2535745216519373
0.23605156329895155
0.5103739150491111
time: 601.6243
Val cmap: 0.8339281
0.5258305037981468
0.18106238240757866
0.29310711379427457
time: 591.7194
Val cmap: 0.8339279
0.8799613222655126
0.11189057058029052
0.00814810715419688
time: 624.6890
Val cmap: 0.8255483
0.6510102291470689
0.046503171384181786
0.30248659946874934
time: 614.6058
Val cmap: 0.8313120
0.15824818952987896
0.026882451596455786
0.8148693588736653
time: 610.1259
Val cmap: 0.8270553
0.6317661113236819
0.2794460355094084
0.08878785316690974
time: 638.3690
Val cmap: 0.8320043
0.2866564577961369
0.236225593177407
0.4771179490264561
time: 595.0167
Val cmap: 0.8342509
0.2959732986922161
0.2513877128247016
0.45263898848308226
time: 620.2248
Val cmap: 0.8345103
0.10252889921743369
0.7821690203851551
0.11530208039741119
time: 610.8714
Val cmap: 0.8291727
0.33929003988557116
0.30017886724807785
0.360531092866351
time: 605.9206
Val cmap: 0.8349071
0.3596454197735309
0.3343402830692467
0.3060142971572224
time: 576.2660
Val cmap: 0.8349885
0.4059141304194686
0.3365631779688548
0.2575226916116765
time: 578.5363
Val cmap: 0.8348550
0.3729663858936656
0.36230792023951147
0.26472569386682293
time: 618.8839
Val cmap: 0.8346908
0.36333690333773944
0.31247230818532834
0.3241907884769323
time: 618.4339
Val cmap: 0.8349350
0.213724738056828
0.44873489574762604
0.33754036619554595
time: 616.9378
Val cmap: 0.8340785
0.36746374902676526
0.17840831927206563
0.4541279317011691
Date :05/24/2023, 14:21:01
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2546320387237313
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3246843319341122
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.30724730568998143
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.11343632365217504
time: 264.0915
Val cmap: 0.2405150
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.18096688894797996
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.573495928980337
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.10052478199589579
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.14501240007578728
time: 258.5427
Val cmap: 0.2408582
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6816630960895645
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.233069716694016
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.012529132180696264
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.0727380550357232
time: 257.7398
Val cmap: 0.2402455
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3762244041635292
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2671906515287082
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.0015580805411721404
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.3550268637665905
time: 273.3690
Val cmap: 0.2413272
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2206670453026959
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.5903880334350993
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.13609397296126874
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.05285094830093612
time: 263.9794
Val cmap: 0.2405708
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7411715965177073
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06895873241029281
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.08720834352880781
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.10266132754319211
Date :05/24/2023, 14:49:04
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.657685329815937
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.23581796686989334
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.014920068409621253
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.09157663490454844
Date :05/24/2023, 14:54:23
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.8569401416615546
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08499549137098786
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.04601027257740819
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.01205409439004932
time: 274.4957
Val cmap: 0.8185853
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.28907868641257817
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.18174338657620015
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.002214722067991112
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.5269632049432306
time: 269.6668
Val cmap: 0.8194547
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7442457259472579
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.1284953090285389
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.05934890950286993
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.06791005552133327
time: 272.6678
Val cmap: 0.8191829
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5109694239534582
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.1197517122124291
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.3650051653203641
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.004273698513748592
time: 268.7562
Val cmap: 0.8195224
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.35318636909915757
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.26136763000377733
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.1700910342039879
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.2153549666930772
time: 260.8511
Val cmap: 0.8200874
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5083767844341924
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.43993197037220494
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.012316010313400835
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.039375234880201795
time: 267.8843
Val cmap: 0.8185089
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4830670074622513
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.24294433856063358
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.07499385869753215
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.19899479527958297
time: 269.6901
Val cmap: 0.8198156
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.18045926811458657
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.7776981062881919
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.027805594897603224
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.014037030699618293
time: 260.8576
Val cmap: 0.8184249
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7226395743148888
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.10452649804115273
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.1594479893989552
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.01338593824500331
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                time: 271.1713
Val cmap: 0.8192938
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.7361819488900269
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06666427636904237
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.0097475171677565
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.18740625757317425
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         time: 259.2561
Val cmap: 0.8193756
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.111597098276209
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.33102399186575227
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.5563057956123543
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.001073114245684459
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               time: 268.0309
Val cmap: 0.8188475
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3635158287847031
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.25404295612169586
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.11643014876452504
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.266011066329076
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             time: 278.4410
Val cmap: 0.8200046
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3384064012677718
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.28697159393487953
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.1679730573316223
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.2066489474657264
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           time: 264.2111
                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Val cmap: 0.8200137
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.29803264934836243
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3930291419061872
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.15934306680003688
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.14959514194541343
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               time: 266.3035
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Val cmap: 0.8198540
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               time: 261.7591
Val cmap: 0.8204165
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4472355617037801
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.0017203301599868215
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.2688384730967288
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.28220563503950424
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            time: 262.1946
Val cmap: 0.8202043
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.458661476032944
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.003486249330218208
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.2744562966180231
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.2633959780188147
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          time: 263.2065
Val cmap: 0.8201514
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5885389748529855
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.004795886537552514
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.245668213881338
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.16099692472812402
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              time: 269.8409
Val cmap: 0.8199524
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6085063758084426
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.034427525796877786
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.22447221698314357
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.13259388141153605
time: 144.3681
Val cmap: 0.8192377
Date :05/24/2023, 09:22:15
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.42830862223810306
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.11939870882470187
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.0025371665969042513
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.4497555023402908
time: 145.1419
Val cmap: 0.8198386
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3313556008346388
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.28269619937701956
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.027277910778776712
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.35867028900956494
time: 275.8069
Val cmap: 0.8200028
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.412687675493399
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.062151363358336355
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.32771944381724366
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.19744151733102094
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               time: 269.2380
                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Val cmap: 0.8200129
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.23376560882575192
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.16335009306639667
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.3895993212130383
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.21328497689481307
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              time: 269.2748
Val cmap: 0.8200685
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4223372947949894
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.015221937154824245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.293074680677761
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.2693660873724254
time: 142.8327
Val cmap: 0.8192248
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3984992012974934
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.5172419940952726
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.0013750710806364965
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.0828837335265975
time: 142.9354
Val cmap: 0.8186485
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.6945026900586759
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.2697901498757253
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.033240989822863165
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.002466170242735599
time: 268.9724
Val cmap: 0.8201296
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3984385964337713
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.009204286418983361
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.2737571603419756
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.31859995680526965
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             time: 266.8413
Val cmap: 0.8203200
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40633813115020956
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.049781121960438865
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.22617719202191056
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.31770355486744106
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                time: 275.6143
Val cmap: 0.8203322
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3837395987594731
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06775876657071173
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.2276414931601879
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.32086014150962716
time: 143.0098
Val cmap: 0.8199202
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.11009294132325564
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3641773291977795
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.4576446196741272
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.06808510980483773
time: 144.5751
Val cmap: 0.8193243
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.12899066476480758
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.43867504439037247
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.008642708696159084
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.4236915821486609
time: 272.0881
Val cmap: 0.8203601
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2680160179128125
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.16890174430096444
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.21303047387682764
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.3500517639093954
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           time: 270.6668
Val cmap: 0.8202210
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3432109138147337
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.06688533542320492
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.21678163905882603
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.37312211170323534
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           time: 269.1222
Val cmap: 0.8202483
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.2190139672036558
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.19871876403007455
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.1015451403306841
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.4807221284355857
time: 141.6923
Val cmap: 0.8195035
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.31035021761048837
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.3036001948085064
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.15018447060840256
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.2358651169726026
               time: 264.1357
                                                                                                                                                                                                                                                                                                                                                                                                                                                                Val cmap: 0.8197436
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3958353765707618
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04902437808142422
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.3135635656342506
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.24157667971356334
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    time: 266.1923
Val cmap: 0.8201047
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.537458264274437
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08709761864995125
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.19610394388646663
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.17934017318914514
time: 262.1628
Val cmap: 0.8199705
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.44746840860053194
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04139398550255179
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.2399640520255996
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.2711735538713167
Date :05/24/2023, 10:16:48
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
Val cmap: 0.925729
Val cmap: 0.9257293
{'a1': 0.26040949782277134, 'a2': 0.5116068557840232, 'a3': 0.1801592874838625}
Date :05/24/2023, 10:17:32
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
Val cmap: 0.926190
Val cmap: 0.9261896
{'a1': 0.3991007874256297, 'a2': 0.5838659390879196, 'a3': 0.007501891421033844}
Date :05/24/2023, 10:18:12
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
Val cmap: 0.924716
Val cmap: 0.9247156
{'a1': 0.47006322063565675, 'a2': 0.49727041165549263, 'a3': 0.020362752091965093}
Date :05/24/2023, 10:18:49
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
Val cmap: 0.923431
Val cmap: 0.9234306
{'a1': 0.806709060941987, 'a2': 0.14905043612060073, 'a3': 0.01762517265302089}
Date :05/24/2023, 10:19:41
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
Val cmap: 0.930057
Val cmap: 0.9300572
{'a1': 0.5213973434187861, 'a2': 0.16039808721222018, 'a3': 0.0030279684446269744}
time: 263.9270
Val cmap: 0.8202761
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.39854688181206155
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.08917658007841361
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.25071816639496813
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.26155837171455676
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   time: 269.2471
Val cmap: 0.8202693
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3035751816110609
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.14100712207474383
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.2814274646576057
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.27399023165658953
time: 278.3781
Val cmap: 0.8201975
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.38610993492501466
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.05041565119586522
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.20113883724911266
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.3623355766300075
Date :05/24/2023, 10:30:59
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
Date :05/24/2023, 10:32:34
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
                                                                                                                    time: 279.3496
Val cmap: 0.8203511
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.3342631960554958
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.09313887366189262
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.1874773391595893
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.3851205911230222
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       time: 271.1883
Val cmap: 0.8202203
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.36558832013905884
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.128961786212702
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.19486287903303595
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.31058701461520327
Date :05/24/2023, 10:43:53
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 128
validbs: 512
epochwarmup: 0
totalepoch: 200
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.8
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.40989891246747245
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.008132664901508435
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.24370326756579005
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.33826515506522903
time: 265.9862
Val cmap: 0.8203272
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.4776122055165426
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.04207804331847421
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.13631382142886345
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.34399592973611975
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       time: 269.4274
Val cmap: 0.8202302
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_176_0.818317.pth
a1: 0.5249056489861048
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_158_0.817900.pth
a2: 0.031425660975524725
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_133_0.816851.pth
a3: 0.22527894756946457
none: finaltrainv2b1/finetune_tf_efficientnetv2_b1_fold_1_model_epoch_137_0.816355.pth
a4: 0.21838974246890588
time: 150.3221
Val cmap: 0.8077935
{'a1': 0.8667817883998562, 'a2': 0.10011423337231026, 'a3': 0.02737731981610213}
