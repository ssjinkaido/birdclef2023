Date :05/01/2023, 11:52:23
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_v2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Date :05/01/2023, 11:52:54
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_v2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Date :05/01/2023, 11:53:28
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnet_v2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:53:41
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:54:49
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:55:09
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:55:51
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:56:14
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:57:24
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:57:50
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:58:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:58:52
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 11:59:31
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/01/2023, 12:00:46
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
f1: 0.0
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
f1: 0.0
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
Date :05/01/2023, 12:11:11
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
f1: 0.8451797385620915
Date :05/01/2023, 12:16:17
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
f1: 0.84544280568205
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
Date :05/01/2023, 12:21:09
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.01
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.84544280568205
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
Date :05/01/2023, 12:28:08
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Date :05/01/2023, 12:29:52
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.8436343702891599
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
Date :05/01/2023, 12:39:43
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.7702349869451697
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
Date :05/01/2023, 12:53:18
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Date :05/01/2023, 12:55:17
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.7643430201461937
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.7718295951474116
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
61125
f1: 0.7769314472252448
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
61125
f1: 0.033547557840616964
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
61125
f1: 0.7711759940830488
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
61125
f1: 0.7706758951903383
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
61125
f1: 0.770179804423259
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
61125
f1: 0.7681118486089534
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
61125
f1: 0.7702253939094185
a1: 0.2572813990258973
a2: 0.43339924750918973
a3: 0.006022677214322562
a4: 0.3032966762505904
61125
f1: 0.7711709172889955
a1: 0.37938796293965765
a2: 0.43620702950173984
a3: 0.020459289537260658
a4: 0.16394571802134178
61125
f1: 0.7563417171970865
a1: 0.5374693055029864
a2: 0.005749713019784275
a3: 0.0009596062744174148
a4: 0.45582137520281185
61125
f1: 0.7674180689314566
a1: 0.9666295757170381
a2: 0.010423528939959082
a3: 0.0009390639417059163
a4: 0.022007831401296887
61125
f1: 0.7696615275562644
a1: 0.04471410225500949
a2: 0.7797942962315907
a3: 0.003515431031363815
a4: 0.171976170482036
61125
f1: 0.7697273779867373
a1: 0.38168917431758326
a2: 0.18531405818887525
a3: 0.00798258483590704
a4: 0.4250141826576345
61125
f1: 0.7677992386860285
a1: 0.5894754936479072
a2: 0.14355052983223168
a3: 0.003190786689894715
a4: 0.2637831898299664
61125
f1: 0.7689812039355362
a1: 0.4268095033873548
a2: 0.297527962577126
a3: 0.0020339329656967266
a4: 0.2736286010698225
61125
f1: 0.7709607140347179
a1: 0.2955024869306634
a2: 0.32610908503303043
a3: 0.002237785416177571
a4: 0.3761506426201286
61125
f1: 0.7727432384966633
a1: 0.267528988704805
a2: 0.3513957437371243
a3: 0.010058618518617356
a4: 0.37101664903945336
61125
f1: 0.7718108957384459
a1: 0.3080416331059865
a2: 0.16991277255823312
a3: 0.042372456120756304
a4: 0.47967313821502405
61125
f1: 0.6714792899408284
a1: 0.16749719584880982
a2: 0.35313462420829134
a3: 0.4647143725573553
a4: 0.014653807385543505
61125
f1: 0.0
a1: 0.44756150617662394
a2: 0.24856264860620653
a3: 0.002098906883766886
a4: 0.30177693833340263
61125
f1: 0.7706972639011473
a1: 0.5536770032057912
a2: 0.06551661974139823
a3: 0.003848086595037588
a4: 0.376958290457773
61125
f1: 0.770922935909187
a1: 0.3406814090277941
a2: 0.18451145867844604
a3: 0.0016351866849083248
a4: 0.47317194560885156
61125
f1: 0.7698362499121514
a1: 0.6366076115775926
a2: 0.03381061898928922
a3: 0.00273770477052271
a4: 0.32684406466259547
61125
f1: 0.7717057682130887
a1: 0.5025646289684824
a2: 0.12570926231842675
a3: 0.0009106389407112521
a4: 0.3708154697723796
61125
f1: 0.7686724915445322
a1: 0.4415965900593068
a2: 0.05382090534794505
a3: 0.00571813411266579
a4: 0.4988643704800823
61125
f1: 0.7684010152284263
a1: 0.6042115811197396
a2: 0.04494610351259337
a3: 0.0015820436303246358
a4: 0.34926027173734236
61125
f1: 0.7716225247089445
a1: 0.8003078975000563
a2: 0.02656885828579344
a3: 0.0012956549017731115
a4: 0.17182758931237718
61125
f1: 0.764672606420591
a1: 0.6676546662152011
a2: 0.04759328249874943
a3: 0.0023941895360292055
a4: 0.28235786175002026
61125
f1: 0.7700670667137309
a1: 0.6768371567739025
a2: 0.06174141159775329
a3: 0.0013509199801870072
a4: 0.2600705116481572
61125
f1: 0.7719878881768889
a1: 0.6720753943278475
a2: 0.08093533523529234
a3: 0.0015216455720700323
a4: 0.24546762486479018
61125
f1: 0.7650698249955806
a1: 0.7505156675426732
a2: 0.022652574953173188
a3: 0.0012327128483202187
a4: 0.22559904465583341
61125
f1: 0.762555299946912
a1: 0.5681561946369026
a2: 0.06428536198852505
a3: 0.002266620826365073
a4: 0.36529182254820725
61125
f1: 0.7672006209865219
a1: 0.48241689275485755
a2: 0.12181048905914765
a3: 0.004678778230485406
a4: 0.3910938399555094
61125
f1: 0.773675875417913
a1: 0.4123222588927313
a2: 0.123395292470864
a3: 0.004194367390932701
a4: 0.46008808124547196
61125
f1: 0.7681997742663657
a1: 0.4809795227585962
a2: 0.11458154817569174
a3: 0.0029606314968694827
a4: 0.4014782975688425
61125
f1: 0.7730359216127785
a1: 0.48411474256091763
a2: 0.11840369406180906
a3: 0.0047362732473894085
a4: 0.39274529012988396
61125
f1: 0.772558845325899
a1: 0.4870044489798187
a2: 0.0880699860272844
a3: 0.003267380103386967
a4: 0.42165818488951
61125
f1: 0.7679000141222991
a1: 0.36836840358543066
a2: 0.1998417574952674
a3: 0.006587001843624551
a4: 0.4252028370756774
61125
f1: 0.7679220641699905
a1: 0.3040734754327322
a2: 0.21999653866868835
a3: 0.011519664932211595
a4: 0.46441032096636786
61125
f1: 0.7718009394977571
a1: 0.4689182023769474
a2: 0.15207957787397508
a3: 0.004842601138788353
a4: 0.3741596186102892
61125
f1: 0.7661031306250662
a1: 0.5101456295327107
a2: 0.11582155020703268
a3: 0.00447949191696238
a4: 0.36955332834329424
61125
f1: 0.7707217366788836
a1: 0.414697459453667
a2: 0.10246807620736677
a3: 0.0025839254725441257
a4: 0.48025053886642216
61125
f1: 0.7692091091478652
a1: 0.524374088377273
a2: 0.14589263865803576
a3: 0.001875338632218363
a4: 0.32785793433247296
61125
f1: 0.7679876335019674
a1: 0.4614357111084995
a2: 0.09044203218405959
a3: 0.0076190319800846324
a4: 0.4405032247273563
61125
f1: 0.7659394196144885
a1: 0.38052016060040517
a2: 0.004602006340612058
a3: 0.0032102997236481616
a4: 0.6116675333353346
61125
f1: 0.7722562909706069
a1: 0.5262344580683078
a2: 0.11169241492936163
a3: 0.005652920820303436
a4: 0.3564202061820271
61125
f1: 0.7709678557566776
a1: 0.2507004454676215
a2: 0.16543101720582157
a3: 0.009522212040967773
a4: 0.5743463252855892
61125
f1: 0.7700610207752813
a1: 0.34326874371046734
a2: 0.1413627538831507
a3: 0.015848232128334822
a4: 0.4995202702780472
61125
f1: 0.7648602638672152
a1: 0.4820128250275494
a2: 0.07735132414509738
a3: 0.002864257621455852
a4: 0.43777159320589737
61125
f1: 0.7680129468055165
a1: 0.3958880062483329
a2: 0.0020260044233963576
a3: 0.0039345924716503765
a4: 0.5981513968566202
61125
f1: 0.7703254896435113
a1: 0.4408101150639681
a2: 0.02981867969051498
a3: 0.0030374606498556295
a4: 0.5263337445956613
61125
f1: 0.7728679988741908
a1: 0.43966592995714093
a2: 0.03126919862351136
a3: 0.0019637454151836715
a4: 0.527101126004164
61125
f1: 0.7715897074374338
a1: 0.5564829807371374
a2: 0.10274094642851177
a3: 0.004917598489969894
a4: 0.3358584743443809
61125
f1: 0.7690951407010367
a1: 0.4162923760175887
a2: 0.04892185261227219
a3: 0.0025138411452550686
a4: 0.532271930224884
61125
f1: 0.770600865922771
a1: 0.48146226510002005
a2: 0.07518564905583065
a3: 0.0011472722089704054
a4: 0.44220481363517894
61125
f1: 0.7677931567484017
a1: 0.3606657762936889
a2: 0.24088229302793263
a3: 0.0019325979154107642
a4: 0.3965193327629677
61125
f1: 0.771210038419513
a1: 0.5923665954016775
a2: 0.09449766281914021
a3: 0.0033973288409458887
a4: 0.30973841293823645
61125
f1: 0.7720894154149919
a1: 0.32433377883897735
a2: 0.13192178993623271
a3: 0.0016714744850277723
a4: 0.5420729567397622
61125
f1: 0.7701824060731733
a1: 0.4348175930134723
a2: 0.018982799098406847
a3: 0.00687974527506615
a4: 0.5393198626130546
61125
f1: 0.7662721893491125
a1: 0.38270371251859064
a2: 0.007038397277069647
a3: 0.003098480413698039
a4: 0.6071594097906416
61125
f1: 0.7724395047833426
a1: 0.3872507359202184
a2: 0.04372847082665758
a3: 0.0037920209053630286
a4: 0.565228772347761
61125
f1: 0.7695186976941276
a1: 0.5032639394815628
a2: 0.012679633260201552
a3: 0.0029398958113465725
a4: 0.4811165314468891
61125
f1: 0.7700056353902508
a1: 0.45242645917616064
a2: 0.027878114794349956
a3: 0.0022961301934495883
a4: 0.5173992958360398
61125
f1: 0.767319065052098
a1: 0.2947117266194014
a2: 0.17421259467505107
a3: 0.005128295505250863
a4: 0.5259473832002967
61125
f1: 0.7703541696063214
a1: 0.3422085498057966
a2: 0.06417257345422303
a3: 0.0010509710254394513
a4: 0.5925679057145409
61125
f1: 0.7716684818887679
a1: 0.5308541398827236
a2: 0.04167838597479792
a3: 0.003941405976354785
a4: 0.42352606816612376
61125
f1: 0.7714799027723959
a1: 0.3967656093444346
a2: 0.07576080079620243
a3: 0.0027837057197098915
a4: 0.5246898841396531
61125
f1: 0.7720311234728725
a1: 0.4721667837913555
a2: 0.055201441695514164
a3: 0.0013586169443700743
a4: 0.4712731575687603
61125
f1: 0.7677605228023329
a1: 0.42049714307105335
a2: 0.12494670405286785
a3: 0.0017242931073547768
a4: 0.45283185976872403
61125
f1: 0.771673457917662
a1: 0.3863266148963297
a2: 0.01007473155697368
a3: 0.003305062855460311
a4: 0.6002935906912363
61125
f1: 0.7707966471789814
a1: 0.35561811561443446
a2: 0.009412718027134098
a3: 0.005741883880966165
a4: 0.6292272824774653
61125
f1: 0.7717506164142303
a1: 0.44963727307856605
a2: 0.0019887104980691973
a3: 0.002263668424694114
a4: 0.5461103479986706
61125
f1: 0.7721991409055701
a1: 0.5014241059369928
a2: 0.0349010057304274
a3: 0.003234466752083933
a4: 0.4604404215804958
61125
f1: 0.7678747708362712
a1: 0.2831967590187347
a2: 0.19699751355608536
a3: 0.004388442373708644
a4: 0.5154172850514713
61125
f1: 0.7720484643561567
a1: 0.3754710602643531
a2: 0.06355811363447157
a3: 0.0022203553921922893
a4: 0.5587504707089829
61125
f1: 0.7726040896772605
a1: 0.31129193183110615
a2: 0.10641084699509887
a3: 0.0014618168826731914
a4: 0.5808354042911218
61125
f1: 0.7682161024381688
a1: 0.26270113240741144
a2: 0.15538672022894992
a3: 0.0021700899555573156
a4: 0.5797420574080813
61125
f1: 0.7696254128891701
a1: 0.32949439940925995
a2: 0.06457983812995877
a3: 0.0026303326295538687
a4: 0.6032954298312273
61125
f1: 0.7707550152829991
a1: 0.4133209478701594
a2: 0.08738983132581615
a3: 0.0018473264200447343
a4: 0.49744189438397973
61125
f1: 0.7711275026343519
a1: 0.3799775679565937
a2: 0.027191195522832924
a3: 0.0030193813715011053
a4: 0.5898118551490722
61125
f1: 0.7693227792436235
a1: 0.3643236806032581
a2: 0.05100826190191965
a3: 0.004352359613668013
a4: 0.5803156978811542
61125
f1: 0.7698102580349914
a1: 0.4562300341475204
a2: 0.019046133815518826
a3: 0.0037752891556328346
a4: 0.520948542881328
61125
f1: 0.7696379419860258
a1: 0.43611643056517563
a2: 0.036536496166613114
a3: 0.0023740860621452456
a4: 0.5249729872060659
61125
f1: 0.7708443318199415
a1: 0.4802862689058311
a2: 0.0009251561754849906
a3: 0.002097858496485151
a4: 0.5166907164221988
61125
f1: 0.7692849594927792
a1: 0.3989089079793543
a2: 0.07330678593384117
a3: 0.0033452166708923792
a4: 0.5244390894159121
61125
f1: 0.7691657866948257
a1: 0.36607194365550705
a2: 0.05841804456275403
a3: 0.0015330512980580926
a4: 0.5739769604836807
61125
f1: 0.7712367764383369
a1: 0.5383178153093435
a2: 0.02259925400103855
a3: 0.002710482241237618
a4: 0.4363724484483803
61125
f1: 0.7691062062167775
a1: 0.23659162795016964
a2: 0.11683226757504481
a3: 0.0012140584989315582
a4: 0.645362045975854
61125
f1: 0.7683338016296712
a1: 0.33499760236813125
a2: 0.09355952728404848
a3: 0.00541172494050084
a4: 0.5660311454073195
61125
f1: 0.7710308370044052
a1: 0.44696439191458565
a2: 0.011268835138673569
a3: 0.0022756235392047525
a4: 0.5394911494075361
61125
f1: 0.7679758095706901
a1: 0.4628611622577128
a2: 0.03432742713324531
a3: 0.0017821407338116941
a4: 0.5010292698752302
61125
f1: 0.7710767065446869
a1: 0.42852878230554653
a2: 0.04226398872127792
a3: 0.0024620581781867753
a4: 0.5267451707949887
61125
f1: 0.7718817034145654
a1: 0.5151332132018439
a2: 0.024784052792181
a3: 0.003612587480190498
a4: 0.4564701465257846
61125
f1: 0.7689702614033231
a1: 0.4016688978994708
a2: 0.005996718781799643
a3: 0.004641241079173473
a4: 0.587693142239556
61125
f1: 0.7698328749735561
a1: 0.4897399318243769
a2: 0.017519658056328956
a3: 0.00293045443211416
a4: 0.48980995568718
61125
f1: 0.7651640644274487
a1: 0.42666226448221023
a2: 0.056477645543519875
a3: 0.0020170242004602687
a4: 0.5148430657738097
61125
f1: 0.7739050837910153
a1: 0.3714113206586328
a2: 0.08365567887344837
a3: 0.001977824500531311
a4: 0.5429551759673875
61125
f1: 0.7671261780841186
a1: 0.41552531540931636
a2: 0.052957469444978325
a3: 0.006649516892154726
a4: 0.5248676982535505
61125
f1: 0.7706835799859055
{'a1': 0.4100382340998717, 'a2': 0.029604937720546853, 'a3': 0.0017115421256902786}
Date :05/01/2023, 23:15:45
Duration: 5
Sample rate: 32000
nfft: 1024
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.7764900092856896
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.7755900109769486
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
61125
f1: 0.7739574703120684
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
61125
Date :05/01/2023, 23:30:46
Duration: 5
Sample rate: 32000
nfft: 1024
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Val cmap: 0.8506992511275049
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
Val cmap: 0.8497592413435915
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
61125
Val cmap: 0.8477983871001366
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
61125
Val cmap: 0.8451768520375245
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
61125
Val cmap: 0.8458529592142413
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
61125
Val cmap: 0.8500000046256044
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
61125
Val cmap: 0.8423582517269438
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
61125
Val cmap: 0.8471353662602353
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
61125
Val cmap: 0.8500831298986788
a1: 0.2572813990258973
a2: 0.43339924750918973
a3: 0.006022677214322562
a4: 0.3032966762505904
61125
Val cmap: 0.8414981430090634
a1: 0.9668420528346353
a2: 0.002126840167033182
a3: 0.013939370282586292
a4: 0.01709173671574521
61125
Val cmap: 0.8449844563360834
a1: 0.9659940140792287
a2: 0.020205261899979607
a3: 0.002546867149479257
a4: 0.011253856871312445
61125
Val cmap: 0.8514283642559755
a1: 0.9707932707973176
a2: 0.006606232317611335
a3: 0.0030869886732382223
a4: 0.019513508211832856
61125
Val cmap: 0.850051317989644
a1: 0.8227761745893607
a2: 0.04699356151430966
a3: 0.013921860628997076
a4: 0.11630840326733256
61125
Val cmap: 0.849135516648168
a1: 0.612607286857323
a2: 0.1856375185879186
a3: 0.027725480764090555
a4: 0.1740297137906678
61125
Val cmap: 0.847754107937458
a1: 0.8642381499727905
a2: 0.025704454524471794
a3: 0.007840165705206405
a4: 0.10221722979753134
61125
Val cmap: 0.8466675992793642
a1: 0.6294012265141498
a2: 0.1365716649099802
a3: 0.03153535607872492
a4: 0.2024917524971451
61125
Val cmap: 0.8462987047175967
a1: 0.9849709219171903
a2: 0.0009389008185324973
a3: 0.002390320975162341
a4: 0.011699856289114893
61125
Val cmap: 0.8493095823591227
a1: 0.8338548081453007
a2: 0.054221378592581686
a3: 0.004371861486445534
a4: 0.10755195177567212
61125
Val cmap: 0.8457555007705617
a1: 0.6456157289299096
a2: 0.16396856389813913
a3: 0.008522839000438629
a4: 0.18189286817151265
61125
Val cmap: 0.8489975759813317
a1: 0.7739039524081988
a2: 0.07296535527117415
a3: 0.003769062478371242
a4: 0.14936162984225584
61125
Val cmap: 0.8466689204561736
a1: 0.8846710829925848
a2: 0.019400704134829395
a3: 0.001466927233600792
a4: 0.09446128563898502
61125
Val cmap: 0.8432891477902527
a1: 0.8990776056038785
a2: 0.013892293382824907
a3: 0.0023499361638350735
a4: 0.08468016484946152
61125
Val cmap: 0.8474417246670153
a1: 0.8867650465172857
a2: 0.03310411993806231
a3: 0.0013775363249082613
a4: 0.07875329721974371
61125
Val cmap: 0.847634560327004
a1: 0.9259274127121828
a2: 0.014641989731735125
a3: 0.002056891718746372
a4: 0.057373705837335684
61125
Val cmap: 0.8479979777815935
a1: 0.988621986451994
a2: 0.0021019242965237724
a3: 0.00202372706571059
a4: 0.007252362185771687
61125
Val cmap: 0.8416445339427686
a1: 0.7884574459356719
a2: 0.059480988485118166
a3: 0.003589418811217916
a4: 0.148472146767992
61125
Val cmap: 0.8448762421350595
a1: 0.8393791941683677
a2: 0.04009997857597533
a3: 0.0012335053548989995
a4: 0.11928732190075797
61125
Val cmap: 0.848127428961361
a1: 0.9197298847978027
a2: 0.02290296518140582
a3: 0.0009523789804996058
a4: 0.05641477104029186
61125
Val cmap: 0.8460251184987208
a1: 0.7235676642499564
a2: 0.07186995459035253
a3: 0.005799905522796364
a4: 0.19876247563689467
61125
Val cmap: 0.8487227749087216
a1: 0.7143084541921101
a2: 0.07696795775669585
a3: 0.00306475812618325
a4: 0.2056588299250108
61125
Val cmap: 0.8509604377446247
a1: 0.7075152223367954
a2: 0.10054353437952415
a3: 0.0009294903863178645
a4: 0.19101175289736255
61125
Val cmap: 0.8479456066952603
a1: 0.5558667243504084
a2: 0.12892751447080802
a3: 0.003000454493493019
a4: 0.31220530668529056
61125
Val cmap: 0.8458083475152224
a1: 0.6845277932271358
a2: 0.07576301565494126
a3: 0.0018580174300600913
a4: 0.2378511736878629
61125
Val cmap: 0.8456644950453621
a1: 0.7909099102523673
a2: 0.040572558559018264
a3: 0.0013972370406097894
a4: 0.1671202941480046
61125
Val cmap: 0.8470868124652947
a1: 0.4878388843843027
a2: 0.2819823011087105
a3: 0.0035130576294584498
a4: 0.2266657568775284
61125
Val cmap: 0.8472141274104361
a1: 0.7507201745533522
a2: 0.09065887032125519
a3: 0.0016869845541337717
a4: 0.15693397057125888
61125
Val cmap: 0.8462027542418805
a1: 0.8154310396535023
a2: 0.03406465642810016
a3: 0.0027546374384889087
a4: 0.14774966647990864
61125
Val cmap: 0.8464376675374137
a1: 0.6705768797718178
a2: 0.05867891534875696
a3: 0.005761367042660375
a4: 0.26498283783676485
61125
Val cmap: 0.8482149035135116
a1: 0.7345571122891301
a2: 0.11278203550178818
a3: 0.001224868217607342
a4: 0.15143598399147437
61125
Val cmap: 0.8466564312962344
a1: 0.9228365287420051
a2: 0.02858629224220874
a3: 0.002301540608830642
a4: 0.04627563840695556
61125
Val cmap: 0.8461095617818511
a1: 0.9466357406018745
a2: 0.005498414456318348
a3: 0.002962582429358338
a4: 0.04490326251244881
61125
Val cmap: 0.8471772593770246
a1: 0.8520982931642592
a2: 0.01413840865156683
a3: 0.0017790506045175123
a4: 0.13198424757965643
61125
Val cmap: 0.8482284175440068
a1: 0.9877700442603407
a2: 0.003537593161981394
a3: 0.0015681150301406549
a4: 0.0071242475475373
61125
Val cmap: 0.8476045037363088
a1: 0.9319317839711605
a2: 0.00795690639750367
a3: 0.0030932124082155665
a4: 0.05701809722312027
61125
Val cmap: 0.8492032481321999
a1: 0.8739303815427931
a2: 0.017640932023211167
a3: 0.004475463062506797
a4: 0.1039532233714889
61125
Val cmap: 0.8480672312382329
a1: 0.8095142113657012
a2: 0.028162631229255705
a3: 0.0011348221857730627
a4: 0.16118833521926998
61125
Val cmap: 0.8496279624920594
a1: 0.9384726397530706
a2: 0.009296001598580562
a3: 0.002519038037216538
a4: 0.0497123206111323
61125
Val cmap: 0.8461508928969487
a1: 0.7592904707819959
a2: 0.047911701576831264
a3: 0.009532573831655426
a4: 0.18326525380951744
61125
Val cmap: 0.8518570339256529
a1: 0.751814618613572
a2: 0.04860211358741289
a3: 0.0119654038567426
a4: 0.18761786394227248
61125
Val cmap: 0.8483711043225473
a1: 0.5854544738558982
a2: 0.0835323930701402
a3: 0.007890318835423389
a4: 0.32312281423853817
61125
Val cmap: 0.8492773621125546
a1: 0.8717017450133787
a2: 0.020001202474548493
a3: 0.01837263699903425
a4: 0.08992441551303854
61125
Val cmap: 0.8467982355244691
a1: 0.8352042325485706
a2: 0.023195937671664682
a3: 0.004902118893076396
a4: 0.13669771088668836
61125
Val cmap: 0.8469317470231666
a1: 0.7762541852725467
a2: 0.06771168281303791
a3: 0.010390893306902436
a4: 0.1456432386075129
61125
Val cmap: 0.8451456583802286
a1: 0.9594199059536063
a2: 0.01121149289598292
a3: 0.004123701153546178
a4: 0.025244899996864634
61125
Val cmap: 0.8485637549866293
a1: 0.6672197841212302
a2: 0.04842766688216019
a3: 0.0066934932892851705
a4: 0.27765905570732446
61125
Val cmap: 0.8481643185734957
a1: 0.9052632390403899
a2: 0.007315649276244043
a3: 0.00981545155257265
a4: 0.07760566013079345
61125
Val cmap: 0.8460775995984249
a1: 0.8645906520162908
a2: 0.03241312387637812
a3: 0.0032837202481225698
a4: 0.09971250385920849
61125
Val cmap: 0.8496848656668732
a1: 0.795644487601102
a2: 0.04097177549608159
a3: 0.0020946146636574062
a4: 0.16128912223915906
61125
Val cmap: 0.8539117181394811
a1: 0.6994022147505361
a2: 0.055082065715114786
a3: 0.002165503107351144
a4: 0.24335021642699797
61125
Date :05/02/2023, 03:19:16
Duration: 5
Sample rate: 32000
nfft: 1024
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnet_b1_ns
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.048424551038700525
61125
Val cmap: 0.850674219315441
a1: 0.6700726782423115
a2: 0.23965732913884027
a3: 0.09026999261884819
61125
Val cmap: 0.8497823121464034
a1: 0.9419919199144295
a2: 0.0016127519965695235
a3: 0.05639532808900093
61125
Val cmap: 0.8495831844149055
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.5603568281795814
61125
Val cmap: 0.8457639167024605
a1: 0.09982934714667809
a2: 0.4572810521741044
a3: 0.44288960067921745
61125
Date :05/02/2023, 03:36:50
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
Date :05/02/2023, 03:37:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Val cmap: 0.8416627906180252
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
Val cmap: 0.8432822900516886
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
61125
Val cmap: 0.8478624516241459
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
61125
Val cmap: 0.8420053877100372
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
61125
Val cmap: 0.8427222291131703
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
61125
Val cmap: 0.8426514297898169
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
61125
Val cmap: 0.8414246856993358
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
61125
Val cmap: 0.8416039252192876
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
61125
Date :05/02/2023, 04:08:58
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Date :05/02/2023, 04:09:55
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Date :05/02/2023, 04:10:49
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Date :05/02/2023, 04:11:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
Val cmap: 0.9993750288623299
Date :05/02/2023, 04:12:22
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.7711748394117028
Val cmap: 0.842082534844123
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.7741732503670559
Val cmap: 0.8438689470516803
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
61125
Date :05/02/2023, 04:46:56
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.8284518828451882
Val cmap: 0.9993750288623299
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.8223140495867769
Val cmap: 0.998966512534073
{'a1': 0.6937323135173985, 'a2': 0.257843135443901, 'a3': 0.013153408823788099}
Date :05/02/2023, 04:48:38
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.8284518828451882
Val cmap: 0.9993750288623299
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.8223140495867769
Val cmap: 0.998966512534073
{'a1': 0.6937323135173985, 'a2': 0.257843135443901, 'a3': 0.013153408823788099}
Date :05/02/2023, 04:50:57
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.8284518828451882
Val cmap: 0.9993750288623299
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.8284518828451882
Val cmap: 0.9993750288623299
{'a1': 0.6937323135173985, 'a2': 0.257843135443901, 'a3': 0.013153408823788099}
Date :05/02/2023, 04:53:36
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.8191268191268191
Val cmap: 0.9990619395170416
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.8191268191268191
Val cmap: 0.9990619395170416
{'a1': 0.6937323135173985, 'a2': 0.257843135443901, 'a3': 0.013153408823788099}
Date :05/02/2023, 04:55:16
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/02/2023, 04:56:23
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
61125
f1: 0.7704416880424471
Val cmap: 0.8422125808223967
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
61125
f1: 0.7703880764904386
Val cmap: 0.8421501684674506
{'a1': 0.6937323135173985, 'a2': 0.257843135443901, 'a3': 0.013153408823788099}
Date :05/02/2023, 05:06:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 0
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
61125
f1: 0.7707843893544654
Val cmap: 0.8425264101548516
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
61125
f1: 0.7710455388708041
Val cmap: 0.8429305523481329
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
61125
f1: 0.7711467151752607
Val cmap: 0.8429748793551497
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
61125
f1: 0.7705533527492192
Val cmap: 0.842545533573586
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.0010230441271738824
a4: 0.09686100652216048
61125
f1: 0.7710303285003853
Val cmap: 0.842591199736654
a1: 0.6640923675664397
a2: 0.14028298904179887
a3: 0.018145055328930255
a4: 0.17747958806283112
61125
f1: 0.7703110736605574
Val cmap: 0.8422855535207393
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.18330951110581858
a4: 0.5059257539633242
61125
f1: 0.77136468450842
Val cmap: 0.8432795138961199
a1: 0.9586106983864842
a2: 0.013276901904298664
a3: 0.009509026216147827
a4: 0.01860337349306935
61125
f1: 0.7691278476109997
Val cmap: 0.8418942392141466
a1: 0.8677488716207818
a2: 0.117512988043294
a3: 0.0011347706749306656
a4: 0.013603369660993481
61125
f1: 0.7695122809486946
Val cmap: 0.8420157995733734
a1: 0.039625180617320656
a2: 0.16367818071783483
a3: 0.348091804863963
a4: 0.4486048338008815
61125
f1: 0.7718331473214286
Val cmap: 0.8436345827063979
a1: 0.011795920638234685
a2: 0.9337231897051602
a3: 0.003691632785109343
a4: 0.05078925687149579
61125
f1: 0.7704579645243677
Val cmap: 0.8425910968737547
a1: 0.024121484169013253
a2: 0.3421961214662401
a3: 0.36097834337095264
a4: 0.27270405099379397
61125
f1: 0.7718013115669038
Val cmap: 0.8435427301248669
a1: 0.024878223773343255
a2: 0.3624995512472188
a3: 0.3861981796331276
a4: 0.2264240453463104
61125
f1: 0.7718710757639179
Val cmap: 0.8435076915500436
a1: 0.01133213910386043
a2: 0.5210000520268895
a3: 0.12145394800945507
a4: 0.346213860859795
61125
f1: 0.7710094306671323
Val cmap: 0.8432098644910649
a1: 0.30882797842110765
a2: 0.28100211007046805
a3: 0.07930686561663375
a4: 0.33086304589179055
61125
f1: 0.7709164741300847
Val cmap: 0.8428294858604393
a1: 0.15101037283830865
a2: 0.013537772727911512
a3: 0.7982719347880829
a4: 0.037179919645697
61125
f1: 0.7723792287345119
Val cmap: 0.8436630839973956
a1: 0.1368213106078541
a2: 0.005627156193772321
a3: 0.7085862194890241
a4: 0.1489653137093495
61125
f1: 0.7721228155677783
Val cmap: 0.843624572174825
a1: 0.28666278183169813
a2: 0.06820948597644039
a3: 0.20316968024229162
a4: 0.44195805194956983
61125
f1: 0.7715164650772566
Val cmap: 0.843141365437758
a1: 0.408433257831984
a2: 0.046882514960600426
a3: 0.05458166960852067
a4: 0.4901025575988948
61125
f1: 0.7715206275828255
Val cmap: 0.8428245586209833
a1: 0.12073748894868436
a2: 0.23987243723337728
a3: 0.5857306934821378
a4: 0.053659380335800644
61125
f1: 0.7720570293164151
Val cmap: 0.8436151302001965
a1: 0.23020514762637007
a2: 0.08839560504889947
a3: 0.2469323462746892
a4: 0.4344669010500414
61125
f1: 0.771391635512386
Val cmap: 0.8432514422275247
a1: 0.11734522343354536
a2: 0.050598029304897166
a3: 0.7506468614826294
a4: 0.08140988577892805
61125
f1: 0.7722289890377587
Val cmap: 0.8436505249989847
a1: 0.09117933138131916
a2: 0.0017549312947690004
a3: 0.8734873625441145
a4: 0.033578374779797304
61125
f1: 0.7724632135527186
Val cmap: 0.8437581663681977
a1: 0.14691616328848556
a2: 0.027184441716043548
a3: 0.6639542879433246
a4: 0.16194510705214638
61125
f1: 0.7721399965174996
Val cmap: 0.8435949915131498
a1: 0.09326700685968636
a2: 0.10523842947425602
a3: 0.4824881903090494
a4: 0.31900637335700827
61125
f1: 0.7718111444312713
Val cmap: 0.8435655411904529
a1: 0.2236750327880464
a2: 0.05926904643380339
a3: 0.2655618691674026
a4: 0.4514940516107477
61125
f1: 0.7715633187772926
Val cmap: 0.8433035850082004
a1: 0.09417297997207293
a2: 0.0025892305496226977
a3: 0.8444337896567236
a4: 0.0588039998215808
61125
f1: 0.7722228020735484
Val cmap: 0.8437247391447836
a1: 0.10105720025398962
a2: 0.2091439802048906
a3: 0.11757100113428315
a4: 0.5722278184068366
61125
f1: 0.7712888578414251
Val cmap: 0.8433072889333716
a1: 0.2563011188832218
a2: 0.0048792065121700005
a3: 0.44443216051399365
a4: 0.29438751409061453
61125
f1: 0.7720449626474901
Val cmap: 0.8434128361946002
a1: 0.3886921148133505
a2: 0.08781639909034697
a3: 0.26423991138986197
a4: 0.2592515747064406
61125
f1: 0.7715775111080013
Val cmap: 0.8429571623322656
a1: 0.32930370028645417
a2: 0.1389696527098427
a3: 0.1893420687382278
a4: 0.3423845782654753
61125
f1: 0.7712326850426753
Val cmap: 0.8430217307051857
a1: 0.08160610838398118
a2: 0.049648026004874474
a3: 0.8536830108876301
a4: 0.015062854723514207
61125
f1: 0.7724521739130433
Val cmap: 0.8437285924781945
a1: 0.08071215894551806
a2: 0.13543184293491417
a3: 0.6698070881418863
a4: 0.11404890997768147
61125
f1: 0.7722524028416214
Val cmap: 0.8437083255889612
a1: 0.07158736063895652
a2: 0.12184603418883368
a3: 0.5073138523721707
a4: 0.29925275280003905
61125
f1: 0.7719334936735334
Val cmap: 0.8436337020004501
a1: 0.1793485829808866
a2: 0.06667804946533813
a3: 0.41017054483995385
a4: 0.34380282271382134
61125
f1: 0.7720816611411622
Val cmap: 0.8434660747785531
a1: 0.06742215839044072
a2: 0.17775804725418076
a3: 0.5419155147482427
a4: 0.21290427960713576
61125
f1: 0.7721426330649378
Val cmap: 0.8436223819602153
a1: 0.1901296336874022
a2: 0.09233891054425902
a3: 0.3107657489384176
a4: 0.4067657068299212
61125
f1: 0.7715512726510945
Val cmap: 0.8433723219272496
a1: 0.0697432709906885
a2: 0.19972008212934764
a3: 0.47062761705843087
a4: 0.259909029821533
61125
f1: 0.771730413862836
Val cmap: 0.8436019933127241
a1: 0.19364581703516326
a2: 0.14502139300577283
a3: 0.30975691108058895
a4: 0.351575878878475
61125
f1: 0.7713687150837989
Val cmap: 0.8433410164032077
a1: 0.47422949360927935
a2: 0.03487664473259998
a3: 0.20559028934450504
a4: 0.2853035723136156
61125
f1: 0.7713095529807121
Val cmap: 0.8428290765755817
a1: 0.25709002593562935
a2: 0.11411901743034766
a3: 0.15565618013810872
a4: 0.47313477649591423
61125
f1: 0.7714685314685314
Val cmap: 0.8431303741212515
a1: 0.15081727940548745
a2: 0.01535189684275975
a3: 0.7941098733696313
a4: 0.039720950382121534
61125
f1: 0.7723792287345119
Val cmap: 0.843664437646435
a1: 0.08154344691117281
a2: 0.0059837878044662176
a3: 0.8826595420370779
a4: 0.029813223247283194
61125
f1: 0.7725059134548491
Val cmap: 0.8437486570486259
a1: 0.06309401579250751
a2: 0.16502722056014288
a3: 0.5889371599790987
a4: 0.18294160366825096
61125
f1: 0.7720888083371091
Val cmap: 0.8436456064277631
a1: 0.0153717315608084
a2: 0.0009249886748882127
a3: 0.9649954969632939
a4: 0.018707782801009487
61125
f1: 0.7726956763520089
Val cmap: 0.8439215255111703
a1: 0.003933839473823574
a2: 0.06858850724813634
a3: 0.9102976908677332
a4: 0.017179962410306948
61125
f1: 0.7725676943932704
Val cmap: 0.8438797221791109
a1: 0.016802923679610695
a2: 0.07844066385781201
a3: 0.8084141138315559
a4: 0.0963422986310214
61125
f1: 0.7722166185523982
Val cmap: 0.8437782150652495
a1: 0.0012885463518490323
a2: 0.22985438661745472
a3: 0.34920921807666294
a4: 0.4196478489540333
61125
f1: 0.7717732375706017
Val cmap: 0.843642977637996
a1: 0.033088680752164285
a2: 0.08672102481258813
a3: 0.5672468356693804
a4: 0.31294345876586716
61125
f1: 0.7721951219512194
Val cmap: 0.8437468460149393
a1: 0.03508754782827429
a2: 0.17498188353262428
a3: 0.43580616680155776
a4: 0.3541244018375436
61125
f1: 0.7716057987175912
Val cmap: 0.8436166316689766
a1: 0.01105737014859786
a2: 0.263482322998527
a3: 0.37842380210078297
a4: 0.34703650475209213
61125
f1: 0.771633777281919
Val cmap: 0.8436035144971092
a1: 0.042107906547516526
a2: 0.09731925117641951
a3: 0.609288694562291
a4: 0.25128414771377305
61125
f1: 0.7722048066875654
Val cmap: 0.8437165717953287
a1: 0.04202068683941658
a2: 0.07096316234458008
a3: 0.8139016323842835
a4: 0.07311451843171979
61125
f1: 0.7721849236442064
Val cmap: 0.8437459470144261
a1: 0.012791335421648
a2: 0.050173393843805286
a3: 0.9055489207399137
a4: 0.03148634999463307
61125
f1: 0.7725360681383626
Val cmap: 0.8438441768386622
a1: 0.15686340707649787
a2: 0.03890824729959394
a3: 0.5505617286330332
a4: 0.253666616990875
61125
f1: 0.7722723944349523
Val cmap: 0.8435519870668502
a1: 0.007590269426347473
a2: 0.002516436599490142
a3: 0.8587809071067827
a4: 0.1311123868673797
61125
f1: 0.7723116503841742
Val cmap: 0.8438730794977145
a1: 0.11658392433550764
a2: 0.0460538869861884
a3: 0.6311235571593636
a4: 0.20623863151894029
61125
f1: 0.7721571906354514
Val cmap: 0.8436252871418148
a1: 0.006799377356561305
a2: 0.13127698394432252
a3: 0.4334749120833583
a4: 0.42844872661575784
61125
f1: 0.7716057987175912
Val cmap: 0.843703224237344
a1: 0.003135127851007451
a2: 0.205627940134783
a3: 0.5160753856907349
a4: 0.27516154632347467
61125
f1: 0.7717610983343787
Val cmap: 0.843718312003631
a1: 0.11666108840266935
a2: 0.06913974577223667
a3: 0.3372731628449164
a4: 0.4769260029801776
61125
f1: 0.7716568398283501
Val cmap: 0.8435115189106133
a1: 0.04349598552481687
a2: 0.15640937630229745
a3: 0.021737932685394406
a4: 0.7783567054874913
61125
f1: 0.771266936723006
Val cmap: 0.8433442982437921
a1: 0.054837229374426366
a2: 0.006632402065389385
a3: 0.9203079063562443
a4: 0.01822246220393997
61125
f1: 0.7726703755215577
Val cmap: 0.843804545232632
a1: 0.0014720016793685871
a2: 0.002223363679431549
a3: 0.9149797114174998
a4: 0.08132492322370011
61125
f1: 0.7724492632749514
Val cmap: 0.843906405506001
a1: 0.0023383896810080457
a2: 0.043371035332348075
a3: 0.9258500166529693
a4: 0.028440558333674537
61125
f1: 0.7726372136674893
Val cmap: 0.8438966147903735
a1: 0.05036472110435007
a2: 0.037904175616044485
a3: 0.9019813474988257
a4: 0.009749755780779634
61125
f1: 0.7725850198205717
Val cmap: 0.8438245309001862
a1: 0.12327908400925126
a2: 0.04029346475530614
a3: 0.6645206905636774
a4: 0.17190676067176525
61125
f1: 0.7721668872327088
Val cmap: 0.8436035760355951
a1: 0.04549430949733166
a2: 0.10994363057617951
a3: 0.6604869198914071
a4: 0.18407514003508174
61125
f1: 0.7721558658634258
Val cmap: 0.8437049445832412
a1: 0.1025071689687414
a2: 0.04551632584380136
a3: 0.673037551182504
a4: 0.1789389540049533
61125
f1: 0.7720055710306406
Val cmap: 0.8436086337287825
a1: 0.03130861979638889
a2: 0.03462000579627409
a3: 0.9278915446876227
a4: 0.006179829719714314
61125
f1: 0.7728094575799722
Val cmap: 0.843835143113542
a1: 0.004665672276069271
a2: 0.10908220973586633
a3: 0.46531127655873034
a4: 0.420940841429334
61125
f1: 0.7715789106875284
Val cmap: 0.8437194321290334
a1: 0.16952399383065053
a2: 0.02513476667012411
a3: 0.5410357720157591
a4: 0.26430546748346617
61125
f1: 0.7721867698852738
Val cmap: 0.8435357519226558
a1: 0.04660465633053064
a2: 0.05978036366029798
a3: 0.75079666356974
a4: 0.14281831643943144
61125
f1: 0.7720836377552796
Val cmap: 0.8437576800890777
a1: 0.13537611733528937
a2: 0.026064526624736625
a3: 0.667757390264428
a4: 0.17080196577554596
61125
f1: 0.7721827552583925
Val cmap: 0.8436121007926097
a1: 0.06315463710167174
a2: 0.08058609826855942
a3: 0.41251318715511287
a4: 0.4437460774746559
61125
f1: 0.7717144949266014
Val cmap: 0.8436477354285048
a1: 0.02977831324290369
a2: 0.0011580107979382859
a3: 0.9014630290744979
a4: 0.06760064688466005
61125
f1: 0.7723811841602057
Val cmap: 0.8438672329819809
a1: 0.027270213733212804
a2: 0.006041760088974439
a3: 0.8897791910324127
a4: 0.07690883514540015
61125
f1: 0.7724348944751573
Val cmap: 0.8438734790435992
a1: 0.09425499222183406
a2: 0.06394563804814593
a3: 0.6829546158317953
a4: 0.15884475389822472
61125
f1: 0.7720800696257616
Val cmap: 0.8436729213666668
a1: 0.0013326092809863143
a2: 0.12176708013273721
a3: 0.5231990144354478
a4: 0.3537012961508287
61125
f1: 0.7718247056364521
Val cmap: 0.8437627444350321
a1: 0.07840231907216441
a2: 0.02512251029489426
a3: 0.7281949624893145
a4: 0.16828020814362687
61125
f1: 0.7719127318278297
Val cmap: 0.8437211514289922
a1: 0.09636784918820226
a2: 0.011096511162938937
a3: 0.2896867178211824
a4: 0.6028489218276764
61125
f1: 0.7718013115669038
Val cmap: 0.8435670221793714
a1: 0.13756951073881415
a2: 0.0036829361178732957
a3: 0.387584916106737
a4: 0.4711626370365755
61125
f1: 0.7716887012941711
Val cmap: 0.8435337822397531
a1: 0.025385639613195544
a2: 0.08945021834209411
a3: 0.7450690296851499
a4: 0.14009511235956051
61125
f1: 0.7721752444583638
Val cmap: 0.8437554685858106
a1: 0.030009658927288768
a2: 0.044641647900130636
a3: 0.8825855013075568
a4: 0.042763191865023864
61125
f1: 0.7724617524339361
Val cmap: 0.8438165878862133
a1: 0.0654375885769523
a2: 0.0690324374837827
a3: 0.6110424327829571
a4: 0.2544875411563079
61125
f1: 0.7720606166173141
Val cmap: 0.8436953190400425
a1: 0.03199683471816727
a2: 0.003994309758876098
a3: 0.9204869672255004
a4: 0.04352188829745629
61125
f1: 0.7725360681383626
Val cmap: 0.8438549903344934
a1: 0.06448686601227133
a2: 0.003115222089946459
a3: 0.7854731534064143
a4: 0.146924758491368
61125
f1: 0.7720567770665181
Val cmap: 0.8437514234779888
a1: 0.02462094855915127
a2: 0.1372262242927219
a3: 0.47978597914109355
a4: 0.3583668480070332
61125
f1: 0.7715898794172998
Val cmap: 0.8436551512097793
a1: 0.08364849713241854
a2: 0.02613801719878556
a3: 0.605887095466868
a4: 0.28432639020192785
61125
f1: 0.7721095546727995
Val cmap: 0.8436798696311067
a1: 0.026253561121205
a2: 0.09907341024191559
a3: 0.7157871860085577
a4: 0.15888584262832162
61125
f1: 0.7722289890377587
Val cmap: 0.8437160587470072
a1: 0.10936144953416665
a2: 0.056917824940420414
a3: 0.5373433059711674
a4: 0.29637741955424557
61125
f1: 0.7721377771579975
Val cmap: 0.8436008817710304
a1: 0.15704441310354894
a2: 0.022182828176578163
a3: 0.37145561653764475
a4: 0.44931714218222824
61125
f1: 0.7717914718403237
Val cmap: 0.8435094437933316
a1: 0.0018409325097564772
a2: 0.05622000290404989
a3: 0.9028656053456365
a4: 0.03907345924055705
61125
f1: 0.7725676943932704
Val cmap: 0.8438623412235117
a1: 0.0010087009733193986
a2: 0.08213175937154055
a3: 0.9143809024916965
a4: 0.0024786371634435422
61125
f1: 0.7726640711902113
Val cmap: 0.8438817946290877
a1: 0.05206061022988206
a2: 0.0787584222034565
a3: 0.7618799678225993
a4: 0.10730099974406215
61125
f1: 0.7720409157330735
Val cmap: 0.8437350503706024
a1: 0.001466285099786854
a2: 0.11782719275270573
a3: 0.5953038614745869
a4: 0.2854026606729205
61125
f1: 0.7720324523834395
Val cmap: 0.8437598431921303
a1: 0.02602174544327069
a2: 0.0015980278151529886
a3: 0.9290065059231795
a4: 0.043373720818396855
61125
f1: 0.7725676943932704
Val cmap: 0.8438717325532513
a1: 0.07894504182756314
a2: 0.06059304436795524
a3: 0.485908068114384
a4: 0.3745538456900977
61125
f1: 0.7718001464384086
Val cmap: 0.8436117841480572
a1: 0.018928064910754966
a2: 0.09412095136390142
a3: 0.7512440853754703
a4: 0.13570689834987337
61125
f1: 0.7721215073593374
Val cmap: 0.8437649850064497
a1: 0.04834313210892895
a2: 0.02576949584118697
a3: 0.7951432575210932
a4: 0.13074411452879098
61125
f1: 0.7720299182466516
Val cmap: 0.8437568223004988
a1: 0.001340222791017792
a2: 0.148946390565035
a3: 0.6018361223689223
a4: 0.247877264275025
61125
f1: 0.7720275823640036
Val cmap: 0.8437595207702967
a1: 0.0926751569153664
a2: 0.046779295057573556
a3: 0.45323738643137496
a4: 0.4073081615956851
61125
f1: 0.7718918918918919
Val cmap: 0.8435970122343907
a1: 0.027534237027023768
a2: 0.003855865318182855
a3: 0.9212289326247596
a4: 0.04738096503003386
61125
f1: 0.7725676943932704
Val cmap: 0.8438536089373667
a1: 0.06189063065939119
a2: 0.02655133555930927
a3: 0.7277690558282901
a4: 0.18378897795300952
61125
f1: 0.7720201844440578
Val cmap: 0.8437117517277923
a1: 0.03498036133513356
a2: 0.07369142532752761
a3: 0.6435357319220201
a4: 0.24779248141531873
61125
f1: 0.7721179624664879
Val cmap: 0.8437325145470345
a1: 0.05803672357698482
a2: 0.05308077744646142
a3: 0.5510878307346201
a4: 0.3377946682419336
61125
f1: 0.7721095546727995
Val cmap: 0.8437114990921057
a1: 0.021821749474178025
a2: 0.0046085274617656945
a3: 0.9536937008801208
a4: 0.01987602218393547
61125
f1: 0.7726909305801787
Val cmap: 0.8438649859790242
a1: 0.12445779106204664
a2: 0.03698246468529491
a3: 0.6781140721563246
a4: 0.16044567209633387
61125
f1: 0.7721020926912496
Val cmap: 0.8436041236589954
a1: 0.0752093715281344
a2: 0.019697610747542223
a3: 0.7722633145773083
a4: 0.13282970314701514
61125
f1: 0.7720409157330735
Val cmap: 0.8437360129736103
a1: 0.01628509858278434
a2: 0.10213011735211391
a3: 0.779905282794889
a4: 0.10167950127021264
61125
f1: 0.7720836377552796
Val cmap: 0.8437785569745622
a1: 0.1061394811803533
a2: 0.07994091521769667
a3: 0.5930922407011834
a4: 0.22082736290076665
61125
f1: 0.7721585166079955
Val cmap: 0.8436179113015131
a1: 0.052981765653372696
a2: 0.06009187424772331
a3: 0.418878797162533
a4: 0.468047562936371
61125
f1: 0.7715152148907246
Val cmap: 0.843657235825117
a1: 0.024111865359184408
a2: 0.0010100883440243877
a3: 0.9631846575143616
a4: 0.011693388782429648
61125
f1: 0.7727762522159268
Val cmap: 0.8438952221865282
a1: 0.01811543092685419
a2: 0.01992135570678555
a3: 0.9274029216969129
a4: 0.03456029166944741
61125
f1: 0.7725945494994437
Val cmap: 0.8438755351444289
a1: 0.024703648255324596
a2: 0.017245739949937094
a3: 0.8857664486806351
a4: 0.07228416311410324
61125
f1: 0.7724348944751573
Val cmap: 0.8438596907518959
a1: 0.04500469440221447
a2: 0.003196546520992709
a3: 0.9178619308561025
a4: 0.03393682822069044
61125
f1: 0.7725629258795716
Val cmap: 0.8438166731492909
a1: 0.06960424815186816
a2: 0.03505986487130719
a3: 0.6808995621552303
a4: 0.21443632482159436
61125
f1: 0.7720580557585883
Val cmap: 0.8436856781256197
a1: 0.01938401939211863
a2: 0.0025271905510060835
a3: 0.9488481821840422
a4: 0.029240607872833113
61125
f1: 0.7726103580118179
Val cmap: 0.8439013180344552
a1: 0.0846478132113439
a2: 0.03499838615930307
a3: 0.5071284404792605
a4: 0.37322536015009244
61125
f1: 0.7718637805430654
Val cmap: 0.8436153344075725
a1: 0.03775843864917931
a2: 0.0863448015068929
a3: 0.7003141774000089
a4: 0.1755825824439189
61125
f1: 0.7722779170147591
Val cmap: 0.8437545960287314
a1: 0.002198749416696219
a2: 0.12458304187045825
a3: 0.7546231439965989
a4: 0.1185950647162467
61125
f1: 0.7722655162816588
Val cmap: 0.8438106636588042
a1: 0.0984070028497614
a2: 0.02016063796674511
a3: 0.620828538023478
a4: 0.26060382116001535
61125
f1: 0.7720019510835483
Val cmap: 0.8436266124861254
a1: 0.017953196405590656
a2: 0.004973537586052293
a3: 0.9578271033802133
a4: 0.019246162628143715
61125
f1: 0.7727335928809789
Val cmap: 0.8438995445765222
a1: 0.04424180221073816
a2: 0.045020504967211335
a3: 0.8072475141894581
a4: 0.10349017863259247
61125
f1: 0.7721849236442064
Val cmap: 0.8437416709555395
a1: 0.020088001950573916
a2: 0.00317348918370898
a3: 0.9674884820514416
a4: 0.009250026814275558
61125
f1: 0.7727493917274939
Val cmap: 0.8439067612329577
a1: 0.018993130412260098
a2: 0.07155098589539372
a3: 0.7838270631229233
a4: 0.12562882056942282
61125
f1: 0.7721043478260871
Val cmap: 0.8437790365797369
a1: 0.061958751817170414
a2: 0.022017836496617777
a3: 0.8009528901997949
a4: 0.11507052148641694
61125
f1: 0.7721959365432787
Val cmap: 0.8437352921769958
a1: 0.0011694658029192924
a2: 0.0490424148075744
a3: 0.9125783105503843
a4: 0.03720980883912195
61125
f1: 0.7725676943932704
Val cmap: 0.8438833507331567
a1: 0.04899598296331079
a2: 0.04562158944702465
a3: 0.5666416963442138
a4: 0.3387407312454508
61125
f1: 0.772098533152155
Val cmap: 0.843748374874366
a1: 0.01473604857538913
a2: 0.10333574227729929
a3: 0.6658592080665956
a4: 0.21606900108071603
61125
f1: 0.7722889469103568
Val cmap: 0.8437614475950284
a1: 0.002955759464885168
a2: 0.06725264057660754
a3: 0.8154058384858267
a4: 0.11438576147268065
61125
f1: 0.7722483046426708
Val cmap: 0.8438215722373963
a1: 0.07477274848255003
a2: 0.03248881267281158
a3: 0.6830086428607166
a4: 0.20972979598392183
61125
f1: 0.7719994430520747
Val cmap: 0.8436786289928739
a1: 0.035491064839135916
a2: 0.01833544236044641
a3: 0.9050514474545099
a4: 0.0411220453459078
61125
f1: 0.7726435103090992
Val cmap: 0.8438198768393521
a1: 0.01959488488912823
a2: 0.05378529179953218
a3: 0.8090873586926725
a4: 0.11753246461866718
61125
f1: 0.7721629047403749
Val cmap: 0.8437958034133893
a1: 0.05205576220454251
a2: 0.0015406782719257456
a3: 0.9030564945970581
a4: 0.043347064926473666
61125
f1: 0.7725802524953918
Val cmap: 0.8437951898810612
a1: 0.03352341894583284
a2: 0.043842385142884785
a3: 0.5343650727641038
a4: 0.38826912314717854
61125
f1: 0.7719212680717645
Val cmap: 0.8437233439289272
a1: 0.06771026417364341
a2: 0.02133125084290728
a3: 0.6917496722473344
a4: 0.2192088127361148
61125
f1: 0.7720690615427458
Val cmap: 0.8437027621000299
a1: 0.01815934590390315
a2: 0.0013820678602903674
a3: 0.9752785980881671
a4: 0.005179988147639425
61125
f1: 0.772792047547878
Val cmap: 0.8439310695953135
a1: 0.0016182597223498357
a2: 0.08532222801447409
a3: 0.5979608214443155
a4: 0.31509869081886055
61125
f1: 0.7719249382028339
Val cmap: 0.8437831636043354
a1: 0.08854681336645298
a2: 0.029654239542577107
a3: 0.7213851589096248
a4: 0.1604137881813451
61125
f1: 0.7720311847417513
Val cmap: 0.8436995729263378
a1: 0.21447229660695036
a2: 0.013534927333663321
a3: 0.5762005078060203
a4: 0.19579226825336604
61125
f1: 0.7721757322175732
Val cmap: 0.8435375415589002
a1: 0.1129911281541238
a2: 0.32507765436628877
a3: 0.47289390825490857
a4: 0.08903730922467884
61125
f1: 0.7719090147920737
Val cmap: 0.8434591843199438
a1: 0.019470110318311924
a2: 0.05796108931349099
a3: 0.8011022315842699
a4: 0.12146656878392725
61125
f1: 0.7721202003338898
Val cmap: 0.8437971338775457
a1: 0.04189967860557972
a2: 0.0034900968575453124
a3: 0.931178455782825
a4: 0.023431768754049953
61125
f1: 0.7725092122644789
Val cmap: 0.8438252397647341
a1: 0.025271579641501042
a2: 0.03793173393034075
a3: 0.8365405866279562
a4: 0.100256099800202
61125
f1: 0.7721518987341772
Val cmap: 0.8438106596480952
a1: 0.002430238123730607
a2: 0.001120324716734108
a3: 0.976380577977881
a4: 0.020068859181654353
61125
f1: 0.7727272727272726
Val cmap: 0.8439466948786439
a1: 0.004613785547088451
a2: 0.07597701839446541
a3: 0.766331627573474
a4: 0.15307756848497212
61125
f1: 0.7721422110902386
Val cmap: 0.8437802462451923
a1: 0.05664504065512713
a2: 0.024320619021959016
a3: 0.09723907843606755
a4: 0.8217952618868463
61125
f1: 0.7715023736386485
Val cmap: 0.8434352668791468
a1: 0.002102569185395222
a2: 0.05838445077907326
a3: 0.9223572344178577
a4: 0.017155745617673857
61125
f1: 0.7726751260212062
Val cmap: 0.8438864481673632
a1: 0.03960697333582507
a2: 0.4637355689823948
a3: 0.42920768869374853
a4: 0.06744976898803157
61125
f1: 0.7718881948564051
Val cmap: 0.843447974298866
a1: 0.001500741322826813
a2: 0.10985241518945749
a3: 0.6609014116461187
a4: 0.227745431841597
61125
f1: 0.7721655585337837
Val cmap: 0.843770088397059
a1: 0.07788475826040119
a2: 0.05987303746727272
a3: 0.7040413129597444
a4: 0.15820089131258175
61125
f1: 0.7722241559345632
Val cmap: 0.8437116787396239
a1: 0.026303955506187072
a2: 0.041174181708831345
a3: 0.8217154098307877
a4: 0.11080645295419389
61125
f1: 0.7721091984002784
Val cmap: 0.8438021748535626
a1: 0.01815063875124312
a2: 0.0026104596739402685
a3: 0.9425840091167195
a4: 0.036654892458097166
61125
f1: 0.7725676943932704
Val cmap: 0.8439042705795743
a1: 0.054473836156070515
a2: 0.02135530198991996
a3: 0.795242826023488
a4: 0.1289280358305216
61125
f1: 0.772153219914414
Val cmap: 0.8437474869541267
a1: 0.35794432179312585
a2: 0.01220730416871906
a3: 0.5353490615946174
a4: 0.09449931244353771
61125
f1: 0.7724003072840283
Val cmap: 0.8433075021953369
a1: 0.020297149039389867
a2: 0.05751498969924656
a3: 0.634832934528911
a4: 0.28735492673245266
61125
f1: 0.7719994430520747
Val cmap: 0.8437481305651369
a1: 0.2420194530726224
a2: 0.019019249319476142
a3: 0.6033624700040038
a4: 0.13559882760389763
61125
f1: 0.7722344245720462
Val cmap: 0.8435381217093229
a1: 0.03986550164802395
a2: 0.03884688314508833
a3: 0.7561410624654569
a4: 0.16514655274143086
61125
f1: 0.771955462769659
Val cmap: 0.8437654524158326
a1: 0.4463830980905503
a2: 0.013637031902180213
a3: 0.45567528006818186
a4: 0.08430458993908757
61125
f1: 0.7721837633731907
Val cmap: 0.8430935948892097
a1: 0.6474359590073209
a2: 0.010701704123812565
a3: 0.31769288250193983
a4: 0.024169454366926746
61125
f1: 0.7713073659853452
Val cmap: 0.8427252773543562
a1: 0.0015269206350504419
a2: 0.08368050331195291
a3: 0.04813864833064379
a4: 0.866653927722353
61125
f1: 0.7713089005235602
Val cmap: 0.8434303672911029
a1: 0.2743103900236848
a2: 0.030867792949165775
a3: 0.5914170185017574
a4: 0.10340479852539208
61125
f1: 0.7721439531315385
Val cmap: 0.8434869445635647
a1: 0.01765110180688231
a2: 0.0021712836281828074
a3: 0.9671408098744556
a4: 0.013036804690479187
61125
f1: 0.7727493917274939
Val cmap: 0.8439305644285315
a1: 0.01790127667450178
a2: 0.0023786836583522403
a3: 0.9555894718060958
a4: 0.024130567861050167
61125
f1: 0.7726640711902113
Val cmap: 0.8439050787236755
a1: 0.01771025602194294
a2: 0.05052966917813676
a3: 0.9106389585900844
a4: 0.021121116209835922
61125
f1: 0.7726593192643327
Val cmap: 0.8438596793406666
a1: 0.05850237300810454
a2: 0.0015957610719600328
a3: 0.9042802765739939
a4: 0.03562158934594151
61125
f1: 0.7725533838770259
Val cmap: 0.8437853097907763
a1: 0.042631265019637155
a2: 0.066008555446228
a3: 0.7174632789535285
a4: 0.17389690058060636
61125
f1: 0.7720897859752915
Val cmap: 0.8437352841655847
a1: 0.002157343591514385
a2: 0.16120036526733045
a3: 0.6832933722484468
a4: 0.1533489188927083
61125
f1: 0.7721386800334169
Val cmap: 0.8437230761583638
a1: 0.06942318296482047
a2: 0.03892573991955629
a3: 0.7422237384218484
a4: 0.1494273386937749
61125
f1: 0.7721215073593374
Val cmap: 0.8437363928671088
a1: 0.0227166957136172
a2: 0.09790754167026183
a3: 0.729582066134674
a4: 0.14979369648144691
61125
f1: 0.7721752444583638
Val cmap: 0.843739620897723
a1: 0.0012376390238643745
a2: 0.5408421676114163
a3: 0.401017527315582
a4: 0.05690266604913724
61125
f1: 0.7717057509771076
Val cmap: 0.8434162554230205
a1: 0.039062533402791755
a2: 0.0032582926121884725
a3: 0.9128687421138278
a4: 0.044810431871191936
61125
f1: 0.7725629258795716
Val cmap: 0.8438298174757187
a1: 0.022682812603437814
a2: 0.028115287461176294
a3: 0.9472620135164275
a4: 0.0019398864189583698
61125
f1: 0.7727715199554999
Val cmap: 0.8438666258908162
a1: 0.04415550934869903
a2: 0.0015570182175467804
a3: 0.9306788440718514
a4: 0.023608628361902695
61125
f1: 0.7725360681383626
Val cmap: 0.8438262857716212
a1: 0.023632224665080817
a2: 0.04599694037663588
a3: 0.819669086539527
a4: 0.11070174841875624
61125
f1: 0.7721360506364332
Val cmap: 0.8437992386455402
a1: 0.06361888039928466
a2: 0.029140573338495658
a3: 0.7829921771180144
a4: 0.12424836914420534
61125
f1: 0.7720409157330735
Val cmap: 0.8437405963589476
a1: 0.018730678277348974
a2: 0.06879159392451499
a3: 0.7908320226525968
a4: 0.1216457051455393
61125
f1: 0.7721202003338898
Val cmap: 0.8437749691971992
a1: 0.040342202898875815
a2: 0.1847912473439468
a3: 0.640927998298262
a4: 0.13393855145891542
61125
f1: 0.7720813597102256
Val cmap: 0.843683618758882
a1: 0.1965408285014047
a2: 0.019199078297062667
a3: 0.6496003795788915
a4: 0.13465971362264106
61125
f1: 0.7723186284758519
Val cmap: 0.8436105046827209
a1: 0.09188421521740248
a2: 0.03757483097724801
a3: 0.7238378105110511
a4: 0.14670314329429845
61125
f1: 0.7721007935403035
Val cmap: 0.8436944875756961
a1: 0.002505738930103545
a2: 0.000935987223890003
a3: 0.9911196747540163
a4: 0.005438599091990182
61125
f1: 0.7727004204746847
Val cmap: 0.8439534737476175
a1: 0.0032912742325365077
a2: 0.002287938844551186
a3: 0.99138617505661
a4: 0.0030346118663023836
61125
f1: 0.7727541268462206
Val cmap: 0.8439459854171288
a1: 0.003721840852818882
a2: 0.0537816790188831
a3: 0.9310093565811253
a4: 0.01148712354717274
61125
f1: 0.7727288530403644
Val cmap: 0.8438826469516597
a1: 0.003966791188869046
a2: 0.055588779403289934
a3: 0.8309620763755978
a4: 0.1094823530322433
61125
f1: 0.7722751617166307
Val cmap: 0.8438345153895762
a1: 0.0022883574794452174
a2: 0.07558830181285957
a3: 0.8074284858927026
a4: 0.11469485481499264
61125
f1: 0.7722214494366393
Val cmap: 0.8438055427073069
a1: 0.035381457201619795
a2: 0.036307544264108746
a3: 0.14536497319695754
a4: 0.7829460253373139
61125
f1: 0.7715123176774373
Val cmap: 0.8435181060578071
a1: 0.054782095810946604
a2: 0.21044287467008546
a3: 0.6104085448371662
a4: 0.12436648468180167
61125
f1: 0.7721682171352914
Val cmap: 0.8436876951215452
a1: 0.026381534740734968
a2: 0.0017681228705480221
a3: 0.9536259535677896
a4: 0.018224388820927362
61125
f1: 0.7727604546876629
Val cmap: 0.8438701126194313
a1: 0.30259898677361835
a2: 0.015119512244134612
a3: 0.5520299444892088
a4: 0.1302515564930382
61125
f1: 0.7719677678166533
Val cmap: 0.8433706276705436
a1: 0.01981879418849216
a2: 0.0551226780974166
a3: 0.7727765281956126
a4: 0.15228199951847865
61125
f1: 0.7719762062128221
Val cmap: 0.8437576824720477
a1: 0.0014980381914493955
a2: 0.1379823816672344
a3: 0.6978915854556347
a4: 0.16262799468568145
61125
f1: 0.7720897859752915
Val cmap: 0.8437381394445055
a1: 0.018309898769652826
a2: 0.02625153842239827
a3: 0.9276575986500496
a4: 0.027780964157899324
61125
f1: 0.772648265313217
Val cmap: 0.8438379093043429
a1: 0.040575074944609726
a2: 0.0012793068050428497
a3: 0.9561803299024607
a4: 0.0019652883478866734
61125
f1: 0.772787318361955
Val cmap: 0.8438476166178732
a1: 0.024287614392648312
a2: 0.02518113947357594
a3: 0.9304495964243342
a4: 0.020081649709441596
61125
f1: 0.7727288530403644
Val cmap: 0.8438360352658281
a1: 0.056352488166997186
a2: 0.044053698593198715
a3: 0.7820842846671244
a4: 0.1175095285726796
61125
f1: 0.771987197328138
Val cmap: 0.8437355476258871
a1: 0.016043120629429187
a2: 0.0018924351838062528
a3: 0.9637759719884949
a4: 0.01828847219826979
61125
f1: 0.7727493917274939
Val cmap: 0.8439142752364132
a1: 0.0023893027526604234
a2: 0.07538098352693887
a3: 0.015424728070624567
a4: 0.9068049856497761
61125
f1: 0.7712929349343759
Val cmap: 0.843405806367464
a1: 0.03859828410015273
a2: 0.022675511567387365
a3: 0.059876949847006186
a4: 0.8788492544854537
61125
f1: 0.7714215908694286
Val cmap: 0.8434394134444144
a1: 0.05868295293568279
a2: 0.23680376276201395
a3: 0.5940540233794179
a4: 0.11045926092288527
61125
f1: 0.7721951219512194
Val cmap: 0.8436571186147673
a1: 0.08113293762863348
a2: 0.020237942976402686
a3: 0.7501402513675445
a4: 0.14848886802741934
61125
f1: 0.7720519155155016
Val cmap: 0.8437262566677382
{'a1': 0.002505738930103545, 'a2': 0.000935987223890003, 'a3': 0.9911196747540163}
Date :05/07/2023, 09:24:18
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 0
nmels: 128
fmax: None
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
61125
f1: 0.7638233429597802
Val cmap: 0.8359113477351546
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
61125
f1: 0.7631913092550789
Val cmap: 0.8352249031218563
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
61125
Date :05/07/2023, 09:34:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
61125
f1: 0.765792506198275
Val cmap: 0.83742619290766
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
61125
f1: 0.7651949140701411
Val cmap: 0.837377480563914
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
61125
f1: 0.7647511185682326
Val cmap: 0.8372420228671625
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
61125
Date :05/07/2023, 09:46:11
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.1645165464223856
61125
f1: 0.7656915450673741
Val cmap: 0.8375770948122759
a1: 0.0011131166943540928
a2: 0.30232160930999574
a3: 0.6965652739956502
61125
f1: 0.7659203459580107
Val cmap: 0.8366952942829119
a1: 0.1461415760181248
a2: 0.079568643671926
a3: 0.7742897803099492
61125
f1: 0.7659055255359943
Val cmap: 0.8367211499122821
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.5329862577210289
61125
f1: 0.7663955882866218
Val cmap: 0.8371317163229615
a1: 0.39340303201413257
a2: 0.32672084535187756
a3: 0.2798761226339898
61125
f1: 0.7658356030449054
Val cmap: 0.8375309115539652
a1: 0.41558337474485857
a2: 0.40005175093013445
a3: 0.18436487432500703
61125
f1: 0.7660614525139665
Val cmap: 0.8375740794585735
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.09788405064933436
61125
f1: 0.7652137439267364
Val cmap: 0.8370223660866729
a1: 0.028086329672748975
a2: 0.6512626503833255
a3: 0.32065101994392553
61125
f1: 0.765343212638054
Val cmap: 0.8368786950025018
a1: 0.41371444954108855
a2: 0.3273902629320654
a3: 0.2588952875268461
61125
f1: 0.7657019166986698
Val cmap: 0.8375475969447692
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.6892352650691428
61125
f1: 0.766027206138821
Val cmap: 0.8368678913886084
a1: 0.7633264157020823
a2: 0.029391505379986096
a3: 0.20728207891793166
61125
f1: 0.7670593155363491
Val cmap: 0.8380048288273679
a1: 0.7913879505866583
a2: 0.00924970437863007
a3: 0.1993623450347116
61125
f1: 0.7671671950667178
Val cmap: 0.8380372123648754
a1: 0.8781806427354155
a2: 0.010103246748408505
a3: 0.11171611051617597
61125
f1: 0.7672587948450018
Val cmap: 0.8381013136652663
a1: 0.8962140478817192
a2: 0.002507044079655735
a3: 0.10127890803862505
61125
f1: 0.7673503499669184
Val cmap: 0.8380904182723731
a1: 0.9171857039786483
a2: 0.001735759498315267
a3: 0.08107853652303644
61125
f1: 0.7671576308367283
Val cmap: 0.8380884767713617
a1: 0.9865107677786839
a2: 0.000990890263881705
a3: 0.012498341957434444
61125
f1: 0.7670450588481093
Val cmap: 0.8380851580241793
a1: 0.6452581865306631
a2: 0.0565289562487676
a3: 0.2982128572205693
61125
f1: 0.766887417218543
Val cmap: 0.8378497011193609
a1: 0.8677088677420451
a2: 0.020677575697497508
a3: 0.11161355656045735
61125
f1: 0.7671729134735962
Val cmap: 0.8380862261647886
a1: 0.6377602445746076
a2: 0.07728775239350727
a3: 0.28495200303188517
61125
f1: 0.7669838614102966
Val cmap: 0.8378562912782614
a1: 0.9846849600072879
a2: 0.002925084304564992
a3: 0.012389955688147117
61125
f1: 0.7670450588481093
Val cmap: 0.8380868111298527
a1: 0.8445334197924226
a2: 0.02281501378031639
a3: 0.13265156642726103
61125
f1: 0.7674677812608847
Val cmap: 0.8380813893765203
a1: 0.9095433086692141
a2: 0.009723453913207983
a3: 0.08073323741757794
61125
f1: 0.7670612813370473
Val cmap: 0.8380596583203826
a1: 0.9137101458150999
a2: 0.0009168281274312815
a3: 0.08537302605746881
61125
f1: 0.7672272711445385
Val cmap: 0.8380866912788443
a1: 0.7648063814705998
a2: 0.03586065260972606
a3: 0.19933296591967417
61125
f1: 0.7669466420381278
Val cmap: 0.8380067825170089
a1: 0.6660749968503614
a2: 0.04631798511551515
a3: 0.2876070180341234
61125
f1: 0.7668769386261457
Val cmap: 0.8378648378969933
a1: 0.9193128692165755
a2: 0.007872941340749194
a3: 0.07281418944267529
61125
f1: 0.7671681292659146
Val cmap: 0.8380778593835905
a1: 0.8226675073042445
a2: 0.015968075575263987
a3: 0.1613644171204915
61125
f1: 0.7670230921946293
Val cmap: 0.8380376364262486
a1: 0.7159831215761528
a2: 0.05072228750610571
a3: 0.23329459091774143
61125
Date :05/10/2023, 08:09:33
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 64
validbs: 256
epochwarmup: 0
totalepoch: 250
learningrate: 0.0003
weightdecay: 0.0
thrupsample: 10
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
61286
f1: 0.3115562080536913
Val cmap: 0.5992997671526308
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
Date :05/10/2023, 08:11:44
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65256
f1: 0.8337204996128337
Val cmap: 0.9014697455050713
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65256
Date :05/10/2023, 08:14:06
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 128
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65256
f1: 0.8337204996128337
Val cmap: 0.9014697455050713
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65256
f1: 0.8330800661871476
Val cmap: 0.9010173749536834
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
65256
f1: 0.8330244313395115
Val cmap: 0.9012991815543592
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
65256
f1: 0.8327428552147652
Val cmap: 0.9012180484606124
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.0010230441271738824
a4: 0.09686100652216048
65256
f1: 0.8332717934946796
Val cmap: 0.9016583718522907
a1: 0.6640923675664397
a2: 0.14028298904179887
a3: 0.018145055328930255
a4: 0.17747958806283112
65256
f1: 0.8330012495356456
Val cmap: 0.9009693807111882
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.18330951110581858
a4: 0.5059257539633242
65256
f1: 0.8329182093571188
Val cmap: 0.9012911189394719
a1: 0.9586106983864842
a2: 0.013276901904298664
a3: 0.009509026216147827
a4: 0.01860337349306935
65256
f1: 0.8334235819683228
Val cmap: 0.9004795135355479
a1: 0.8677488716207818
a2: 0.117512988043294
a3: 0.0011347706749306656
a4: 0.013603369660993481
65256
f1: 0.8332995335631718
Val cmap: 0.9007000797539352
a1: 0.039625180617320656
a2: 0.16367818071783483
a3: 0.348091804863963
a4: 0.4486048338008815
65256
f1: 0.8327959156254199
Val cmap: 0.9013857325389546
a1: 0.014008310158715065
a2: 0.7915050477683468
a3: 0.0035199323339136735
a4: 0.1909667097390244
65256
f1: 0.8330035217172564
Val cmap: 0.9017733058509614
a1: 0.02230373590767523
a2: 0.8003960885677195
a3: 0.0029011650172207403
a4: 0.17439901050738457
65256
f1: 0.8330426616581701
Val cmap: 0.901834197904825
a1: 0.024878223773343255
a2: 0.9676891387465723
a3: 0.0022251109042302087
a4: 0.005207526575854283
65256
f1: 0.8332439678284181
Val cmap: 0.9017950986859876
a1: 0.01926813087470992
a2: 0.9762785104832243
a3: 0.0017278781294143817
a4: 0.0027254805126513707
65256
f1: 0.8332551437571208
Val cmap: 0.9017928476815781
a1: 0.30882797842110765
a2: 0.6840395046918339
a3: 0.0021589964926447157
a4: 0.004973520394413689
65256
f1: 0.8330310967828599
Val cmap: 0.9016274423634134
a1: 0.15101037283830865
a2: 0.8169313659241795
a3: 0.0032044585873509633
a4: 0.028853802650160913
65256
f1: 0.8333333333333334
Val cmap: 0.9017011510484412
a1: 0.019355488756947994
a2: 0.9145378200348796
a3: 0.0047871204737969224
a4: 0.06131957073437544
65256
f1: 0.8333165744930451
Val cmap: 0.9017914461819163
a1: 0.3034230920831171
a2: 0.5095502897790586
a3: 0.006012254808176216
a4: 0.18101436332964807
65256
f1: 0.8334342007934906
Val cmap: 0.9015095969332811
a1: 0.11733673142372004
a2: 0.6353261017718546
a3: 0.0029126468209658032
a4: 0.2444245199834596
65256
Date :05/10/2023, 17:51:55
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65256
f1: 0.8366464416211324
Val cmap: 0.9044886966741544
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65256
f1: 0.835345405767941
Val cmap: 0.9040649403465411
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
65256
f1: 0.8356417049532177
Val cmap: 0.9041298105623955
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
65256
f1: 0.8363161069776794
Val cmap: 0.9043877511114607
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.0010230441271738824
a4: 0.09686100652216048
65256
f1: 0.8363343727995172
Val cmap: 0.9044020610010437
a1: 0.6640923675664397
a2: 0.14028298904179887
a3: 0.018145055328930255
a4: 0.17747958806283112
65256
Date :05/10/2023, 17:59:00
Duration: 5
Sample rate: 32000
nfft: 2048
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 1
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65256
f1: 0.8363758164461564
Val cmap: 0.9045225198195846
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65256
f1: 0.8364927322660594
Val cmap: 0.9045257929242957
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65256
f1: 0.8356247065924486
Val cmap: 0.9041729003656518
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
65256
f1: 0.8360320493479501
Val cmap: 0.9043566547898236
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
65256
f1: 0.8366477749086154
Val cmap: 0.9043326383813389
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
65256
f1: 0.8363819095477386
Val cmap: 0.9044961756752605
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
65256
f1: 0.8352613754484794
Val cmap: 0.90396404149767
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
65256
f1: 0.8362698465867221
Val cmap: 0.9044864644356009
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
65256
f1: 0.8365487674169346
Val cmap: 0.9045822872201762
a1: 0.2572813990258973
a2: 0.43339924750918973
a3: 0.006022677214322562
a4: 0.3032966762505904
65256
f1: 0.8361881138336741
Val cmap: 0.9043313534504138
a1: 0.9668420528346353
a2: 0.007307555267900133
a3: 0.000903647768267352
a4: 0.0249467441291972
65256
f1: 0.8368946346037913
Val cmap: 0.9046116420422456
a1: 0.970844264484628
a2: 0.006385627516713351
a3: 0.000915465783616718
a4: 0.021854642215041915
65256
f1: 0.8368946346037913
Val cmap: 0.9046177483036381
a1: 0.9749482105408024
a2: 0.004909703576014727
a3: 0.0009362514386056667
a4: 0.01920583444457722
65256
f1: 0.8369226647017449
Val cmap: 0.904614213591097
a1: 0.969862754727477
a2: 0.0019779271783800633
a3: 0.0022671920175768604
a4: 0.025892126076566113
65256
f1: 0.8369506966773848
Val cmap: 0.9046137510212354
a1: 0.8434174993773473
a2: 0.02694202860815516
a3: 0.003788414672159105
a4: 0.1258520573423384
65256
f1: 0.8363538909919266
Val cmap: 0.904544079942104
a1: 0.8777102101358683
a2: 0.014128816507137293
a3: 0.010459205966603182
a4: 0.09770176739039127
65256
f1: 0.8362808145766345
Val cmap: 0.9045504855329688
a1: 0.6195509645313702
a2: 0.06166983367780872
a3: 0.03846140888646592
a4: 0.2803177929043552
65256
f1: 0.836037002279126
Val cmap: 0.9044029932992784
a1: 0.9849709219171903
a2: 0.0039068910530680855
a3: 0.0012418807724981107
a4: 0.009880306257243536
65256
f1: 0.8369787305308993
Val cmap: 0.9046181272748274
a1: 0.8537577717971722
a2: 0.019911497988839538
a3: 0.00310259043549312
a4: 0.12322813977849519
65256
f1: 0.8363928714993969
Val cmap: 0.9045512518207873
a1: 0.6059771598076937
a2: 0.13662738102035185
a3: 0.0075214862847000335
a4: 0.24987397288725435
65256
f1: 0.8362210529843493
Val cmap: 0.9044115881183015
a1: 0.8283740293672957
a2: 0.04646245000525324
a3: 0.0023226462281042163
a4: 0.1228408743993469
65256
f1: 0.8364988443372526
Val cmap: 0.9045353931527642
a1: 0.9715881159170662
a2: 0.0038647270566969536
a3: 0.0012413097384395891
a4: 0.02330584728779728
65256
f1: 0.8369226647017449
Val cmap: 0.904615636012509
a1: 0.96261741889331
a2: 0.000948432693650034
a3: 0.0013878197245371473
a4: 0.03504632868850284
65256
f1: 0.8369506966773848
Val cmap: 0.9045961214794517
a1: 0.7999340613969338
a2: 0.03266606392826546
a3: 0.0019486475741147117
a4: 0.16545122710068605
65256
f1: 0.8364598686855151
Val cmap: 0.9045128907834645
a1: 0.8869979942903908
a2: 0.010682355175701699
a3: 0.0013110918290654937
a4: 0.10100855870484197
65256
f1: 0.8363867769702248
Val cmap: 0.9045260972471506
a1: 0.9886541239906734
a2: 0.003611236951756957
a3: 0.0011566643111386794
a4: 0.0065779747464309365
65256
f1: 0.8370067662624775
Val cmap: 0.904618957418597
a1: 0.9177134843164573
a2: 0.010105209223529362
a3: 0.0017748414565060748
a4: 0.0704064650035073
65256
f1: 0.8366376423308773
Val cmap: 0.9045673761672574
a1: 0.7801589184391224
a2: 0.035232584666334076
a3: 0.0035009161557546307
a4: 0.18110758073878885
65256
f1: 0.8363538909919266
Val cmap: 0.9044980358740525
a1: 0.9159799667563285
a2: 0.013344861980579225
a3: 0.001216881311915558
a4: 0.06945828995117669
65256
f1: 0.8365986804648515
Val cmap: 0.9045783424678054
a1: 0.7887773728452712
a2: 0.02297981568759909
a3: 0.002769198397596514
a4: 0.18547361306953322
65256
f1: 0.8364379522916108
Val cmap: 0.9044999891674859
a1: 0.6768371567739025
a2: 0.05831817735792809
a3: 0.005016274102030502
a4: 0.25982839176613887
65256
f1: 0.8360128617363345
Val cmap: 0.9044392877158097
a1: 0.9804268402203131
a2: 0.0038180524749191723
a3: 0.0010970543613163795
a4: 0.014658052943451325
65256
f1: 0.8370176848874599
Val cmap: 0.9046135655835404
a1: 0.9305773790429103
a2: 0.006763175537832952
a3: 0.0013683506851326693
a4: 0.061291094734124106
65256
f1: 0.8366827438370846
Val cmap: 0.9046131900816423
a1: 0.8638928701450916
a2: 0.017937735780439508
a3: 0.0018687347134659453
a4: 0.11630065936100291
65256
f1: 0.8363648544534888
Val cmap: 0.9045624102418225
a1: 0.9893388681705759
a2: 0.003213633266153321
a3: 0.0010655153613297523
a4: 0.006381983201941002
65256
f1: 0.8369787305308993
Val cmap: 0.9046200082454422
a1: 0.915295069679299
a2: 0.010247057712128102
a3: 0.0010748722225519102
a4: 0.07338300038602102
65256
f1: 0.8366656619444724
Val cmap: 0.904568994398971
a1: 0.9896880720106199
a2: 0.0031675404172134395
a3: 0.0009932816239695578
a4: 0.0061511059481970795
65256
f1: 0.8369787305308993
Val cmap: 0.9046194296085338
a1: 0.8269662854063164
a2: 0.0226035050455438
a3: 0.0017438640664240571
a4: 0.1486863454817157
65256
f1: 0.8364379522916108
Val cmap: 0.9045306036708641
a1: 0.7443903925879429
a2: 0.04393928859003637
a3: 0.0023242995563213047
a4: 0.2093460192656994
65256
f1: 0.8362588771271607
Val cmap: 0.9044823685813078
a1: 0.8740913293271058
a2: 0.01583603227105644
a3: 0.0016677154591058791
a4: 0.10840492294273192
65256
f1: 0.8363478027867095
Val cmap: 0.9045414867322619
a1: 0.9265741919827414
a2: 0.0021790056010394265
a3: 0.0014365583150284084
a4: 0.06981024410119079
65256
f1: 0.8367497320471596
Val cmap: 0.9045779611741671
a1: 0.980002452000546
a2: 0.0032047512531340233
a3: 0.0010169483811805534
a4: 0.015775848365139393
65256
f1: 0.8369896506681851
Val cmap: 0.9046148902843673
a1: 0.9119560804589173
a2: 0.007435996887122914
a3: 0.0009238515408884333
a4: 0.07968407111307135
65256
f1: 0.8365597159890147
Val cmap: 0.9045467296153187
a1: 0.98804602136209
a2: 0.0028630530538230614
a3: 0.0011625237073796101
a4: 0.007928401876707363
65256
f1: 0.8369787305308993
Val cmap: 0.904616067152315
a1: 0.838114580937259
a2: 0.017733565086291245
a3: 0.001537047476226614
a4: 0.14261480650022312
65256
f1: 0.8364550175908864
Val cmap: 0.9045593699946218
a1: 0.9342953394823741
a2: 0.006449977452835419
a3: 0.0009287657226537207
a4: 0.058325917342136775
65256
f1: 0.836710768715458
Val cmap: 0.9045992576154743
a1: 0.8745741044903673
a2: 0.01179971792031756
a3: 0.0021209246967047743
a4: 0.11150525289261035
65256
f1: 0.8363758164461564
Val cmap: 0.9045510413253679
a1: 0.9880058624594571
a2: 0.004101154714726296
a3: 0.001021233941106781
a4: 0.006871748884709828
65256
f1: 0.8370067662624775
Val cmap: 0.904620375875128
a1: 0.8113549947752952
a2: 0.027607865978547915
a3: 0.002725719048746436
a4: 0.15831142019741049
65256
f1: 0.8364208904224314
Val cmap: 0.9045210236970195
a1: 0.9480378460758765
a2: 0.0009217646369301586
a3: 0.0011882280989027967
a4: 0.049852161188290556
65256
f1: 0.8368447496231787
Val cmap: 0.904601317406016
a1: 0.9891160046195019
a2: 0.003561749038235066
a3: 0.0010280615738303652
a4: 0.006294184768432682
65256
f1: 0.8369787305308993
Val cmap: 0.9046200912496036
a1: 0.8929788702143904
a2: 0.008421088671041134
a3: 0.0015049729479991334
a4: 0.09709506816656936
65256
f1: 0.8364147909967846
Val cmap: 0.9045317133143399
a1: 0.9881465575361874
a2: 0.0037199631912115064
a3: 0.0010022007751220251
a4: 0.007131278497479059
65256
f1: 0.8370067662624775
Val cmap: 0.9046191338038524
a1: 0.9435747341550907
a2: 0.005125819750343682
a3: 0.0010543924335216462
a4: 0.05024505366104393
65256
f1: 0.8368447496231787
Val cmap: 0.9046052535947258
a1: 0.9896560343339676
a2: 0.0033373279193839754
a3: 0.0009929309613277368
a4: 0.006013706785320639
65256
f1: 0.8369787305308993
Val cmap: 0.9046192867542651
a1: 0.8904386430977063
a2: 0.01496677315464252
a3: 0.001528644910827724
a4: 0.09306593883682349
65256
f1: 0.836425748543104
Val cmap: 0.9045239824666197
a1: 0.9538361094416942
a2: 0.0047313694618066225
a3: 0.0010118125883669417
a4: 0.04042070850813227
65256
f1: 0.8369226647017449
Val cmap: 0.9045878166816307
a1: 0.8393623797556828
a2: 0.020717066814636868
a3: 0.0009067652820075683
a4: 0.13901378814767273
65256
f1: 0.8364550175908864
Val cmap: 0.9045648531702453
a1: 0.948982805911071
a2: 0.005769973169627915
a3: 0.0012823072520476279
a4: 0.043964913667253476
65256
f1: 0.8368727808668855
Val cmap: 0.9045991827832335
a1: 0.863813879859767
a2: 0.01359576748215014
a3: 0.002101525166409606
a4: 0.12048882749167328
65256
f1: 0.8363928714993969
Val cmap: 0.9045654332795383
a1: 0.9054726866377842
a2: 0.008839929559243231
a3: 0.0016939025912693641
a4: 0.08399348121170316
65256
f1: 0.8365487674169346
Val cmap: 0.9045462309244381
a1: 0.9773130941827214
a2: 0.002841829128060543
a3: 0.0011542479577624396
a4: 0.018690828731455632
65256
f1: 0.8369506966773848
Val cmap: 0.9046114756881893
a1: 0.9899806846878133
a2: 0.003536329199203602
a3: 0.0010074570941486741
a4: 0.005475529018834418
65256
f1: 0.8369397735646814
Val cmap: 0.9046163151706921
a1: 0.9465252963228646
a2: 0.005590658657367825
a3: 0.001325233156550178
a4: 0.04655881186321736
65256
f1: 0.8368727808668855
Val cmap: 0.9046023361425668
a1: 0.9390750229610181
a2: 0.0010664170292845458
a3: 0.0009036969603862816
a4: 0.05895486304931109
65256
f1: 0.8367606671578808
Val cmap: 0.904605140052454
a1: 0.9009866975508085
a2: 0.011075528326380632
a3: 0.0012096071057836868
a4: 0.08672816701702717
65256
f1: 0.8364817792068595
Val cmap: 0.9045407894534273
a1: 0.9882890061192205
a2: 0.004166305584630209
a3: 0.0009917092092499497
a4: 0.006552979086899294
65256
f1: 0.8369397735646814
Val cmap: 0.904619622209782
a1: 0.9499829044827013
a2: 0.005099368384982896
a3: 0.0010626291803960436
a4: 0.043855097951919775
65256
f1: 0.8368727808668855
Val cmap: 0.9045978209193644
a1: 0.8516841996087026
a2: 0.017408536124000003
a3: 0.0014288378190875522
a4: 0.12947842644820987
65256
f1: 0.8364208904224314
Val cmap: 0.9045517240130965
a1: 0.9892594154622986
a2: 0.0041902601939336525
a3: 0.0009778984114242875
a4: 0.0055724259323434965
65256
f1: 0.836911740077039
Val cmap: 0.9046184471662517
a1: 0.8035341627310222
a2: 0.02753314495662445
a3: 0.0018366847637723408
a4: 0.16709600754858103
65256
f1: 0.8364208904224314
Val cmap: 0.9045061634011693
a1: 0.9130890896190595
a2: 0.008611932042940612
a3: 0.001178685922574587
a4: 0.07712029241542526
65256
f1: 0.8366157556270097
Val cmap: 0.9045524829099807
a1: 0.9604624781002263
a2: 0.001932937212223677
a3: 0.0010934128045041649
a4: 0.03651117188304582
65256
f1: 0.8369787305308993
Val cmap: 0.9045910888658145
a1: 0.9885910198699327
a2: 0.003401509521838697
a3: 0.0009905055431205557
a4: 0.00701696506510805
65256
f1: 0.8370067662624775
Val cmap: 0.9046197918569623
a1: 0.885449440290337
a2: 0.013660831493706525
a3: 0.0015483144292515302
a4: 0.09934141378670493
65256
f1: 0.8363587648201486
Val cmap: 0.9045281521313792
a1: 0.922504692896616
a2: 0.007790521057106391
a3: 0.0013306559860906293
a4: 0.06837413006018701
65256
f1: 0.8366936834349252
Val cmap: 0.9045777938417255
a1: 0.9569985548389334
a2: 0.006290890717117462
a3: 0.0010812033202910435
a4: 0.03562935112365812
65256
f1: 0.8369506966773848
Val cmap: 0.9046004689194909
a1: 0.9275286544636954
a2: 0.009626502547238616
a3: 0.0013375549354860878
a4: 0.06150728805357993
65256
f1: 0.8366547208359848
Val cmap: 0.9046129533178071
a1: 0.9686492666107025
a2: 0.004288086516116861
a3: 0.0009790207762430513
a4: 0.02608362609693759
65256
f1: 0.8369226647017449
Val cmap: 0.9046137731323
a1: 0.8890345880391638
a2: 0.012040348481871764
a3: 0.0016441850756709888
a4: 0.09728087840329344
65256
f1: 0.8364147909967846
Val cmap: 0.9045297980414149
a1: 0.764053189643056
a2: 0.034108693937224856
a3: 0.0018474286928696797
a4: 0.19999068772684944
65256
f1: 0.8362978595116067
Val cmap: 0.9044828438886123
a1: 0.9893234453938646
a2: 0.0034903777391470043
a3: 0.0009809551147251395
a4: 0.006205221752263225
65256
f1: 0.8369787305308993
Val cmap: 0.9046200732747337
a1: 0.9711068166346635
a2: 0.0028992878160207635
a3: 0.0009887225945041864
a4: 0.025005172954811576
65256
f1: 0.8369506966773848
Val cmap: 0.9046100044173648
a1: 0.9573509714490893
a2: 0.0021177367162051163
a3: 0.000900448835253931
a4: 0.03963084299945163
65256
f1: 0.8369787305308993
Val cmap: 0.9045981718878454
a1: 0.928986395852235
a2: 0.007511908064186668
a3: 0.0012253227486513022
a4: 0.06227637333492706
65256
f1: 0.8366827438370846
Val cmap: 0.9046138667555474
a1: 0.9829967133089293
a2: 0.003522072873011376
a3: 0.0011068896766249475
a4: 0.012374324141434329
65256
f1: 0.8370176848874599
Val cmap: 0.9046113044146643
a1: 0.9899106154358888
a2: 0.0033328127337530823
a3: 0.0009530686576381815
a4: 0.0058035031727199735
65256
f1: 0.8369397735646814
Val cmap: 0.9046191502089698
a1: 0.8642063579278827
a2: 0.015462427003664011
a3: 0.0014408490012708128
a4: 0.11889036606718248
65256
f1: 0.8363928714993969
Val cmap: 0.9045626269198768
a1: 0.9176056480970904
a2: 0.009662657702542219
a3: 0.0012335854035865016
a4: 0.07149810879678083
65256
f1: 0.8366656619444724
Val cmap: 0.9045695490723978
a1: 0.9354946373962589
a2: 0.007130397200329452
a3: 0.001074086196223884
a4: 0.05630087920718773
65256
f1: 0.8366827438370846
Val cmap: 0.9046108783335162
a1: 0.899005581252788
a2: 0.0009095007926917145
a3: 0.001381924194129859
a4: 0.09870299376039048
65256
f1: 0.8365097973538771
Val cmap: 0.9045402438694597
a1: 0.9608817602409249
a2: 0.004768226382537461
a3: 0.0010295355448123086
a4: 0.03332047783172536
65256
Date :05/11/2023, 07:48:42
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.8423113271229917
Val cmap: 0.9090988543174409
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
Date :05/11/2023, 07:50:32
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7662702402829307
Val cmap: 0.840816014793396
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
f1: 0.7662702402829307
Val cmap: 0.840816014793396
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65200
Date :05/11/2023, 07:54:24
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7662702402829307
Val cmap: 0.840816014793396
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
Date :05/11/2023, 07:57:55
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7662702402829307
Val cmap: 0.840816014793396
f1: 0.7662702402829307
Val cmap: 0.840816014793396
Date :05/12/2023, 10:58:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7941787941787942
Val cmap: 0.9989395728632732
Date :05/12/2023, 10:59:04
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7941787941787942
Date :05/12/2023, 10:59:49
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7941787941787942
Date :05/12/2023, 11:01:10
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7941787941787942
Val cmap: 0.9989395728632732
Date :05/12/2023, 11:02:04
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7662702402829307
Val cmap: 0.840816014793396
Date :05/12/2023, 11:33:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7725629282738198
Val cmap: 0.8439658602854336
f1: 0.7725629282738198
Date :05/12/2023, 11:36:53
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
Date :05/12/2023, 11:37:46
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7725629282738198
Date :05/12/2023, 11:45:01
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7725629282738198
Val cmap: 0.8439658602854336
Date :05/12/2023, 11:51:05
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
f1: 0.7845303867403315
Val cmap: 0.9848096462766558
f1: 0.7845303867403315
Date :05/12/2023, 11:53:47
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
Date :05/12/2023, 11:54:20
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 256
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
Date :05/12/2023, 11:55:00
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
f1: 0.7839195979899497
Val cmap: 0.9890752001610339
Date :05/12/2023, 11:56:03
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
f1: 0.7701782150966766
Val cmap: 0.8436312684974023
Date :05/12/2023, 11:58:08
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
f1: 0.7698393588111865
Val cmap: 0.8435414298301046
Date :05/12/2023, 12:14:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
f1: 0.7698393588111865
Date :05/12/2023, 12:18:11
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
f1: 0.0005910165484633571
Date :05/12/2023, 12:19:54
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
1000
f1: 0.0036968576709796672
Val cmap: 0.9257139766321486
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
1000
f1: 0.0036968576709796672
Val cmap: 0.9257139766321486
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65200
1000
f1: 0.0036968576709796672
Val cmap: 0.9257139766321486
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
Date :05/12/2023, 09:08:07
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
Date :05/12/2023, 09:08:57
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Date :05/12/2023, 09:10:11
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.9109986097485356
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Date :05/12/2023, 09:15:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.9107010355603594
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Date :05/12/2023, 09:20:12
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65200
15282
Val cmap: 0.9105981146528724
Valid loss: 1.3928
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65200
15282
Val cmap: 0.9106715204837251
Valid loss: 1.4018
a1: 0.18521134905251652
a2: 0.2818023932264547
a3: 0.011322601317751651
a4: 0.5216636564032773
65200
15282
Val cmap: 0.910490962645256
Valid loss: 1.4014
a1: 0.53388974992932
a2: 0.19549439035941074
a3: 0.0447909843686722
a4: 0.22582487534259701
65200
15282
Val cmap: 0.9107690740837343
Valid loss: 1.3935
a1: 0.20320327498447074
a2: 0.6989126743661949
a3: 0.0010230441271738824
a4: 0.09686100652216048
65200
15282
Val cmap: 0.9099583759891403
Valid loss: 1.3970
a1: 0.6640923675664397
a2: 0.14028298904179887
a3: 0.018145055328930255
a4: 0.17747958806283112
65200
15282
Val cmap: 0.9108513975972379
Valid loss: 1.3910
a1: 0.1398426822706862
a2: 0.17092205266017102
a3: 0.18330951110581858
a4: 0.5059257539633242
65200
15282
Date :05/12/2023, 21:19:17
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65200
15282
Val cmap: 0.842341647334826
Valid loss: 1.9340
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65200
15282
Date :05/12/2023, 21:24:33
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65200
15282
Val cmap: 0.842341647334826
Valid loss: 1.9340
Date :05/12/2023, 21:31:40
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65200
15282
Val cmap: 0.842341647334826
Valid loss: 1.9340
0.7682346089280208
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65200
15282
Date :05/12/2023, 21:36:51
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.41343476265084567
a2: 0.4220486909267687
a3: 0.0009005356676447506
a4: 0.16361601075474086
65200
15282
Val cmap: 0.842341647334826
Valid loss: 1.9340
0.7682346089280208
a1: 0.3000069143328895
a2: 0.10334927266034401
a3: 0.0016394797550796066
a4: 0.5950043332516869
65200
15282
Date :05/12/2023, 21:44:12
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.15198443381740748
a2: 0.25672863401172846
a3: 0.0013458230556526122
a4: 0.5899411091152115
65200
15282
Val cmap: 0.9074591871859226
Valid loss: 1.3983
0.8434099153567111
a1: 0.4558018778512702
a2: 0.4538563418988969
a3: 0.06386772170527977
a4: 0.026474058544553092
65200
15282
Val cmap: 0.9075682121832129
Valid loss: 1.3750
0.8434573187048435
a1: 0.7199921054915603
a2: 0.21462486621604113
a3: 0.002841129848104657
a4: 0.06254189844429388
65200
15282
Val cmap: 0.9075367527119849
Valid loss: 1.3697
0.8433565966540889
a1: 0.6379449698582085
a2: 0.03452884812776798
a3: 0.0014395028153539864
a4: 0.32608667919866957
65200
15282
Val cmap: 0.9075630787275923
Valid loss: 1.3780
0.8434089844011515
a1: 0.5841280021678498
a2: 0.1430333685445009
a3: 0.2551075173548874
a4: 0.017731111932761945
65200
15282
Date :05/13/2023, 05:28:09
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.15198443381740748
a2: 0.25672863401172846
a3: 0.0013458230556526122
a4: 0.5899411091152115
65200
15282
Val cmap: 0.9126318993116136
Valid loss: 1.3867
0.8481118506873601
a1: 0.4558018778512702
a2: 0.4538563418988969
a3: 0.06386772170527977
a4: 0.026474058544553092
65200
15282
Date :05/13/2023, 05:33:29
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
Date :05/13/2023, 05:33:42
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.38137110642854644
a2: 0.0939984179052928
a3: 0.15143814240973819
a4: 0.37319233325642254
65200
15282
Val cmap: 0.9129454524182772
Valid loss: 1.3800
0.8473918426071536
a1: 0.3408098571191773
a2: 0.19252621931509742
a3: 0.31634467215129725
a4: 0.15031925141442803
65200
15282
Val cmap: 0.9129005523597051
Valid loss: 1.3803
0.8481784087864987
a1: 0.8566868846754462
a2: 0.02215482373304442
a3: 0.0009565649307538181
a4: 0.12020172666075558
65200
15282
Val cmap: 0.9124741448570496
Valid loss: 1.3793
0.8462130593393353
a1: 0.37768118151776403
a2: 0.03714075485789275
a3: 0.0015104555735735946
a4: 0.5836676080507697
65200
15282
Date :05/13/2023, 05:45:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.5492199126283009
a2: 0.12031236746205241
a3: 0.0055589175081276945
a4: 0.3249088024015189
65200
15282
Val cmap: 0.9127068005099407
Valid loss: 1.3798
0.8485173037017203
a1: 0.7248588879928006
a2: 0.02371042881420981
a3: 0.009957479968336196
a4: 0.24147320322465335
65200
15282
Date :05/13/2023, 05:52:37
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6078450096194813
a2: 0.1153370649496368
a3: 0.01335134064923832
a4: 0.08042091758948948
a4: 0.1830456671921541
65200
15282
Val cmap: 0.9127241183664064
Valid loss: 1.3839
0.8484990462166594
a1: 0.5109448570686435
a2: 0.25104101505272236
a3: 0.025058538768934376
a4: 0.009166081117818234
a4: 0.20378950799188156
65200
15282
Val cmap: 0.9127861456581856
Valid loss: 1.3819
0.8477322175732219
a1: 0.5514451341601395
a2: 0.090219404703635
a3: 0.010751521441875833
a4: 0.04835432952064157
a4: 0.2992296101737081
65200
15282
Val cmap: 0.9127011492479061
Valid loss: 1.3849
0.8484016736401674
a1: 0.5828073702269285
a2: 0.11336884705105707
a3: 0.0023018533741596494
a4: 0.019117526300350185
a4: 0.2824044030475045
65200
15282
Val cmap: 0.9126569424256559
Valid loss: 1.3847
0.8482961772779006
a1: 0.8235543612166141
a2: 0.049876474391032724
a3: 0.0021925246464130715
a4: 0.013309400778212459
a4: 0.11106723896772769
65200
15282
Date :05/13/2023, 06:08:14
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.05530425674991414
a2: 0.7419109619488354
a3: 0.052676358115853535
a4: 0.1501084231853969
65200
15282
Val cmap: 0.9125379197474511
Valid loss: 1.3784
0.846424149124862
a1: 0.4542313010664235
a2: 0.1745616730406021
a3: 0.11839900236396327
a4: 0.2528080235290111
65200
15282
Val cmap: 0.9127396268053821
Valid loss: 1.3822
0.8482089052561098
a1: 0.818405048160885
a2: 0.16465126952340445
a3: 0.00211766559810788
a4: 0.014826016717602676
65200
15282
Val cmap: 0.9127743810470413
Valid loss: 1.3833
0.8482232483437061
a1: 0.3045238866108749
a2: 0.5192759658654148
a3: 0.15329026682858538
a4: 0.022909880695124896
65200
15282
Val cmap: 0.9127674717738964
Valid loss: 1.3777
0.8475903614457831
a1: 0.9884510612229749
a2: 0.0050088681448921014
a3: 0.0015114741072805523
a4: 0.005028596524852466
65200
15282
Val cmap: 0.9126273312587974
Valid loss: 1.3865
0.8480529907667603
Date :05/13/2023, 06:30:34
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.912737011116607
Valid loss: 1.3817
0.8479271924248001
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Val cmap: 0.9127332374141827
Valid loss: 1.3817
0.8478500920194076
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65200
15282
Val cmap: 0.9126487119884107
Valid loss: 1.3876
0.8482474640956111
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
65200
15282
Val cmap: 0.9126651981468407
Valid loss: 1.3842
0.8484889052511798
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
65200
15282
Val cmap: 0.9127495104822198
Valid loss: 1.3792
0.8475677123439016
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
65200
15282
Val cmap: 0.9125959984943425
Valid loss: 1.3872
0.8481360016063182
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
65200
15282
Val cmap: 0.9126330771727592
Valid loss: 1.3839
0.8479185505207809
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
65200
15282
Val cmap: 0.9127048039415555
Valid loss: 1.3850
0.8485274431057563
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
65200
15282
Val cmap: 0.9127191260930161
Valid loss: 1.3845
0.8485294609696524
a1: 0.2572813990258973
a2: 0.43339924750918973
a3: 0.006022677214322562
a4: 0.3032966762505904
65200
15282
Val cmap: 0.9128787730145752
Valid loss: 1.3802
0.847644872953701
a1: 0.06457995832924607
a2: 0.8029075858627228
a3: 0.010328252596560604
a4: 0.12218420321147046
65200
15282
Val cmap: 0.9124803019818617
Valid loss: 1.3790
0.8465271966527196
a1: 0.23973430215700886
a2: 0.5083180743151083
a3: 0.005076533338167781
a4: 0.246871090189715
65200
15282
Val cmap: 0.9127812932314443
Valid loss: 1.3795
0.8478355485620543
a1: 0.2697656747189047
a2: 0.45054544942505587
a3: 0.005107076068095936
a4: 0.2745817997879434
65200
15282
Val cmap: 0.912861884225125
Valid loss: 1.3800
0.8477889733203897
a1: 0.34491932833212463
a2: 0.4031807724750453
a3: 0.032971432888352095
a4: 0.21892846630447804
65200
15282
Val cmap: 0.9128981709298845
Valid loss: 1.3800
0.8475234270414993
a1: 0.3937663661641463
a2: 0.3674341322686559
a3: 0.039780128994737846
a4: 0.19901937257245997
65200
15282
Val cmap: 0.9128558434000751
Valid loss: 1.3803
0.847258005152742
a1: 0.054054634477054914
a2: 0.6008831899748253
a3: 0.33829545773873043
a4: 0.0067667178093893665
65200
15282
Val cmap: 0.9126954111327013
Valid loss: 1.3758
0.8473691257196412
a1: 0.33467667655604794
a2: 0.38078472114758527
a3: 0.021480708538886267
a4: 0.2630578937574805
65200
15282
Val cmap: 0.9128612048631657
Valid loss: 1.3805
0.8471910864255362
a1: 0.49352216450711817
a2: 0.33231837284802934
a3: 0.00977548524938552
a4: 0.16438397739546698
65200
15282
Val cmap: 0.9128136302755274
Valid loss: 1.3810
0.8476107616115648
a1: 0.012205529078995664
a2: 0.6675967542725812
a3: 0.024956542245754092
a4: 0.295241174402669
65200
15282
Val cmap: 0.9126077539996692
Valid loss: 1.3787
0.8468052347959969
a1: 0.1688059896541606
a2: 0.5048654464335582
a3: 0.0635621453327664
a4: 0.26276641857951477
65200
15282
Val cmap: 0.9128300342468358
Valid loss: 1.3789
0.8478537467354182
a1: 0.2627312092701719
a2: 0.4352700534532486
a3: 0.007851991102866423
a4: 0.29414674617371306
65200
15282
Val cmap: 0.9128648486925741
Valid loss: 1.3801
0.8476164970540976
a1: 0.28553233555484653
a2: 0.42840947157418174
a3: 0.008327784514246898
a4: 0.2777304083567249
65200
15282
Val cmap: 0.912883204338548
Valid loss: 1.3802
0.8475983263598327
a1: 0.1305074307198972
a2: 0.43085333580229773
a3: 0.015969024671180523
a4: 0.42267020880662454
65200
15282
Val cmap: 0.9128370588025033
Valid loss: 1.3803
0.8475007532893637
a1: 0.32451357665031777
a2: 0.32920584998455404
a3: 0.003089872034908013
a4: 0.34319070133022017
65200
15282
Val cmap: 0.9127758758959615
Valid loss: 1.3815
0.8476085282993607
a1: 0.20589774255982257
a2: 0.4889701756078063
a3: 0.00606422778406027
a4: 0.2990678540483109
65200
15282
Val cmap: 0.9127820848810847
Valid loss: 1.3797
0.8478435574604876
a1: 0.3123638320493052
a2: 0.39193869013469274
a3: 0.009120748159215358
a4: 0.2865767296567867
65200
15282
Val cmap: 0.9128602184469482
Valid loss: 1.3805
0.847420196747641
a1: 0.15225456332972231
a2: 0.29286967145774856
a3: 0.01935969755258591
a4: 0.5355160676599432
65200
15282
Val cmap: 0.9127644546798994
Valid loss: 1.3822
0.8480058935806851
a1: 0.4086994506756087
a2: 0.40265869961671963
a3: 0.0030262954673310047
a4: 0.18561555424034062
65200
15282
Val cmap: 0.9128496803880655
Valid loss: 1.3803
0.8475438361665105
a1: 0.2343126600067202
a2: 0.46354675988248495
a3: 0.012605625753601893
a4: 0.2895349543571929
65200
15282
Val cmap: 0.9128366324276558
Valid loss: 1.3798
0.8478355485620543
a1: 0.5350275710189343
a2: 0.3375117840213001
a3: 0.013464173482410467
a4: 0.11399647147735514
65200
15282
Val cmap: 0.9128141356908207
Valid loss: 1.3808
0.8475154759913001
a1: 0.5976497375919358
a2: 0.20542424844641516
a3: 0.007717941953516506
a4: 0.1892080720081325
65200
15282
Val cmap: 0.9127501333471173
Valid loss: 1.3829
0.8481826092777294
a1: 0.2729642987219327
a2: 0.42061978033015
a3: 0.007246568967827481
a4: 0.29916935198008976
65200
15282
Val cmap: 0.9129013564521798
Valid loss: 1.3803
0.8475699558173784
a1: 0.3246342047634253
a2: 0.4096974115841455
a3: 0.003963196739856433
a4: 0.2617051869125727
65200
15282
Val cmap: 0.91290771757346
Valid loss: 1.3804
0.8473430598313479
a1: 0.3921912809408445
a2: 0.3553740825400078
a3: 0.004203080488446503
a4: 0.24823155603070116
65200
15282
Date :05/13/2023, 08:29:03
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Date :05/13/2023, 08:30:51
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.912737011116607
Valid loss: 1.3817
0.8479271924248001
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Date :05/13/2023, 08:36:35
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.912737011116607
Valid loss: 1.3817
0.8479271924248001
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Val cmap: 0.9127332374141827
Valid loss: 1.3817
0.8478500920194076
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65200
15282
Val cmap: 0.9126487119884107
Valid loss: 1.3876
0.8482474640956111
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
65200
15282
Val cmap: 0.9126651981468407
Valid loss: 1.3842
0.8484889052511798
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
65200
15282
Val cmap: 0.9127495104822198
Valid loss: 1.3792
0.8475677123439016
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
65200
15282
Val cmap: 0.9125959984943425
Valid loss: 1.3872
0.8481360016063182
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
65200
15282
Val cmap: 0.9126330771727592
Valid loss: 1.3839
0.8479185505207809
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
65200
15282
Val cmap: 0.9127048039415555
Valid loss: 1.3850
0.8485274431057563
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
65200
15282
Val cmap: 0.9127191260930161
Valid loss: 1.3845
0.8485294609696524
a1: 0.2572813990258973
a2: 0.43339924750918973
a3: 0.006022677214322562
a4: 0.3032966762505904
65200
15282
Val cmap: 0.9128787730145752
Valid loss: 1.3802
0.847644872953701
a1: 0.06457995832924607
a2: 0.8029075858627228
a3: 0.010328252596560604
a4: 0.12218420321147046
65200
15282
Val cmap: 0.9124803019818617
Valid loss: 1.3790
0.8465271966527196
a1: 0.23973430215700886
a2: 0.5083180743151083
a3: 0.005076533338167781
a4: 0.246871090189715
65200
15282
Val cmap: 0.9127812932314443
Valid loss: 1.3795
0.8478355485620543
a1: 0.2697656747189047
a2: 0.45054544942505587
a3: 0.005107076068095936
a4: 0.2745817997879434
65200
15282
Val cmap: 0.912861884225125
Valid loss: 1.3800
0.8477889733203897
a1: 0.34491932833212463
a2: 0.4031807724750453
a3: 0.032971432888352095
a4: 0.21892846630447804
65200
15282
Val cmap: 0.9128981709298845
Valid loss: 1.3800
0.8475234270414993
a1: 0.3937663661641463
a2: 0.3674341322686559
a3: 0.039780128994737846
a4: 0.19901937257245997
65200
15282
Val cmap: 0.9128558434000751
Valid loss: 1.3803
0.847258005152742
a1: 0.054054634477054914
a2: 0.6008831899748253
a3: 0.33829545773873043
a4: 0.0067667178093893665
65200
15282
Val cmap: 0.9126954111327013
Valid loss: 1.3758
0.8473691257196412
a1: 0.33467667655604794
a2: 0.38078472114758527
a3: 0.021480708538886267
a4: 0.2630578937574805
65200
15282
Val cmap: 0.9128612048631657
Valid loss: 1.3805
0.8471910864255362
a1: 0.49352216450711817
a2: 0.33231837284802934
a3: 0.00977548524938552
a4: 0.16438397739546698
65200
15282
Val cmap: 0.9128136302755274
Valid loss: 1.3810
0.8476107616115648
a1: 0.012205529078995664
a2: 0.6675967542725812
a3: 0.024956542245754092
a4: 0.295241174402669
65200
15282
Val cmap: 0.9126077539996692
Valid loss: 1.3787
0.8468052347959969
a1: 0.1688059896541606
a2: 0.5048654464335582
a3: 0.0635621453327664
a4: 0.26276641857951477
65200
15282
Val cmap: 0.9128300342468358
Valid loss: 1.3789
0.8478537467354182
a1: 0.2627312092701719
a2: 0.4352700534532486
a3: 0.007851991102866423
a4: 0.29414674617371306
65200
15282
Val cmap: 0.9128648486925741
Valid loss: 1.3801
0.8476164970540976
a1: 0.28553233555484653
a2: 0.42840947157418174
a3: 0.008327784514246898
a4: 0.2777304083567249
65200
15282
Val cmap: 0.912883204338548
Valid loss: 1.3802
0.8475983263598327
a1: 0.1305074307198972
a2: 0.43085333580229773
a3: 0.015969024671180523
a4: 0.42267020880662454
65200
15282
Val cmap: 0.9128370588025033
Valid loss: 1.3803
0.8475007532893637
a1: 0.32451357665031777
a2: 0.32920584998455404
a3: 0.003089872034908013
a4: 0.34319070133022017
65200
15282
Val cmap: 0.9127758758959615
Valid loss: 1.3815
0.8476085282993607
a1: 0.20589774255982257
a2: 0.4889701756078063
a3: 0.00606422778406027
a4: 0.2990678540483109
65200
15282
Val cmap: 0.9127820848810847
Valid loss: 1.3797
0.8478435574604876
a1: 0.3123638320493052
a2: 0.39193869013469274
a3: 0.009120748159215358
a4: 0.2865767296567867
65200
15282
Val cmap: 0.9128602184469482
Valid loss: 1.3805
0.847420196747641
a1: 0.15225456332972231
a2: 0.29286967145774856
a3: 0.01935969755258591
a4: 0.5355160676599432
65200
15282
Val cmap: 0.9127644546798994
Valid loss: 1.3822
0.8480058935806851
a1: 0.4086994506756087
a2: 0.40265869961671963
a3: 0.0030262954673310047
a4: 0.18561555424034062
65200
15282
Val cmap: 0.9128496803880655
Valid loss: 1.3803
0.8475438361665105
a1: 0.2343126600067202
a2: 0.46354675988248495
a3: 0.012605625753601893
a4: 0.2895349543571929
65200
15282
Val cmap: 0.9128366324276558
Valid loss: 1.3798
0.8478355485620543
a1: 0.5350275710189343
a2: 0.3375117840213001
a3: 0.013464173482410467
a4: 0.11399647147735514
65200
15282
Val cmap: 0.9128141356908207
Valid loss: 1.3808
0.8475154759913001
a1: 0.5976497375919358
a2: 0.20542424844641516
a3: 0.007717941953516506
a4: 0.1892080720081325
65200
15282
Val cmap: 0.9127501333471173
Valid loss: 1.3829
0.8481826092777294
a1: 0.2729642987219327
a2: 0.42061978033015
a3: 0.007246568967827481
a4: 0.29916935198008976
65200
15282
Val cmap: 0.9129013564521798
Valid loss: 1.3803
0.8475699558173784
a1: 0.3246342047634253
a2: 0.4096974115841455
a3: 0.003963196739856433
a4: 0.2617051869125727
65200
15282
Val cmap: 0.91290771757346
Valid loss: 1.3804
0.8473430598313479
a1: 0.3921912809408445
a2: 0.3553740825400078
a3: 0.004203080488446503
a4: 0.24823155603070116
65200
15282
Val cmap: 0.912805742457998
Valid loss: 1.3809
0.8471910864255362
a1: 0.3317027407182678
a2: 0.3999727267826256
a3: 0.00225157732596139
a4: 0.2660729551731453
65200
15282
Val cmap: 0.912898219148966
Valid loss: 1.3805
0.8474099852764021
a1: 0.3496918133056664
a2: 0.28889922180241134
a3: 0.002402725874942237
a4: 0.3590062390169801
65200
15282
Val cmap: 0.9127803330706558
Valid loss: 1.3820
0.8477707859151158
a1: 0.4542713911047264
a2: 0.3763974845255377
a3: 0.004057217412062931
a4: 0.1652739069576729
65200
15282
Val cmap: 0.9128078785118756
Valid loss: 1.3805
0.8475234270414993
a1: 0.3673042708294791
a2: 0.3989674847685366
a3: 0.0018334766241770255
a4: 0.23189476777780724
65200
15282
Val cmap: 0.9128574687581167
Valid loss: 1.3805
0.8474383428705284
a1: 0.3150295557435701
a2: 0.2990956201118662
a3: 0.0011008754283811251
a4: 0.38477394871618265
65200
15282
Val cmap: 0.9127592351444929
Valid loss: 1.3820
0.8476289280813895
a1: 0.4480476569057817
a2: 0.25620130224083393
a3: 0.0021476476818692003
a4: 0.29360339317151524
65200
15282
Val cmap: 0.912768116590211
Valid loss: 1.3824
0.8478173540439208
a1: 0.2206889376405038
a2: 0.5412667374456515
a3: 0.0034251182672247176
a4: 0.23461920664662003
65200
15282
Val cmap: 0.9127940053032672
Valid loss: 1.3793
0.84763467139844
a1: 0.2888857886684706
a2: 0.40706338174484613
a3: 0.0065984468389900085
a4: 0.29745238274769326
65200
15282
Val cmap: 0.9128836902886471
Valid loss: 1.3804
0.8474644351464437
a1: 0.18810835831181053
a2: 0.4828764599035225
a3: 0.0038700748553931537
a4: 0.32514510692927384
65200
15282
Val cmap: 0.912808354230356
Valid loss: 1.3798
0.847681232211619
a1: 0.2806731400042006
a2: 0.40867743427427883
a3: 0.005827594731046317
a4: 0.3048218309904742
65200
15282
Val cmap: 0.9128934929294555
Valid loss: 1.3804
0.8474077049235199
a1: 0.3614841673773703
a2: 0.35325794753345535
a3: 0.002501822161185795
a4: 0.28275606292798855
65200
15282
Val cmap: 0.9127944309297283
Valid loss: 1.3810
0.847296573875803
a1: 0.2923273548583405
a2: 0.46076985500008233
a3: 0.005132014087092517
a4: 0.24177077605448466
65200
15282
Val cmap: 0.9128667025832465
Valid loss: 1.3799
0.8477038425492033
a1: 0.22691836476381105
a2: 0.42210246014162744
a3: 0.001511527448204759
a4: 0.3494676476463567
65200
15282
Val cmap: 0.9128415598499691
Valid loss: 1.3804
0.847673250753264
a1: 0.3487272231370517
a2: 0.36733422910115004
a3: 0.0030615915994370805
a4: 0.28087695616236114
65200
15282
Val cmap: 0.9128009660870244
Valid loss: 1.3809
0.8472477831688138
a1: 0.18608338261913032
a2: 0.5405625266114151
a3: 0.005173654446163151
a4: 0.26818043632329136
65200
15282
Val cmap: 0.9128290129783015
Valid loss: 1.3794
0.8475597509540068
a1: 0.09434318135665742
a2: 0.5794662780225365
a3: 0.006399832244738768
a4: 0.3197907083760673
65200
15282
Val cmap: 0.9127693484822311
Valid loss: 1.3792
0.8472635983263598
a1: 0.25249777129240236
a2: 0.45059320859667384
a3: 0.0018079436009302296
a4: 0.29510107650999357
65200
15282
Val cmap: 0.9128703717431853
Valid loss: 1.3801
0.847675469424641
a1: 0.29207099128782593
a2: 0.40191181327065195
a3: 0.0038874529182708548
a4: 0.3021297425232513
65200
15282
Val cmap: 0.9128535209327376
Valid loss: 1.3805
0.8474462815449495
a1: 0.29229003969097095
a2: 0.41672615225656756
a3: 0.00656367158594405
a4: 0.2844201364665175
65200
15282
Val cmap: 0.9128803534394785
Valid loss: 1.3803
0.8474179189397236
a1: 0.3733433091533092
a2: 0.3814158399552703
a3: 0.009869063963398051
a4: 0.23537178692802252
65200
15282
Val cmap: 0.9128518293087269
Valid loss: 1.3806
0.8472194338486247
a1: 0.4224558108350922
a2: 0.4117510927430943
a3: 0.006909900215978858
a4: 0.15888319620583463
65200
15282
Val cmap: 0.9128641890271092
Valid loss: 1.3801
0.8476209596466574
a1: 0.25828376320604074
a2: 0.4678330130988194
a3: 0.0045864621362544464
a4: 0.2692967615588854
65200
15282
Val cmap: 0.912834773947491
Valid loss: 1.3799
0.8478071643789756
a1: 0.3377130340436079
a2: 0.434771887354769
a3: 0.011018266222975056
a4: 0.21649681237864807
65200
15282
Val cmap: 0.9128720639543244
Valid loss: 1.3800
0.8476856655175876
a1: 0.1451007194113617
a2: 0.5056461636980654
a3: 0.029321599996194242
a4: 0.3199315168943787
65200
15282
Val cmap: 0.9128003957299657
Valid loss: 1.3794
0.8477278054988111
a1: 0.2211966913013099
a2: 0.321148134652578
a3: 0.014387998447303976
a4: 0.44326717559880807
65200
15282
Val cmap: 0.9128187640715218
Valid loss: 1.3816
0.8477220232316808
a1: 0.32298598138031376
a2: 0.3841398848063334
a3: 0.0056831457375844585
a4: 0.2871909880757684
65200
15282
Val cmap: 0.91286911075832
Valid loss: 1.3807
0.8472477831688138
a1: 0.17714701483189546
a2: 0.47507971529466664
a3: 0.017262459807077805
a4: 0.33051081006636013
65200
15282
Val cmap: 0.9127994097163225
Valid loss: 1.3797
0.8477198151744458
a1: 0.2825727403492944
a2: 0.43977107438165197
a3: 0.008497487783498972
a4: 0.2691586974855547
65200
15282
Val cmap: 0.9128686248159367
Valid loss: 1.3801
0.8477605944968869
a1: 0.2750705907318715
a2: 0.41878475043888025
a3: 0.007757859159228509
a4: 0.2983867996700197
65200
15282
Val cmap: 0.9128998882777124
Valid loss: 1.3803
0.8476266988016335
a1: 0.38640919014122826
a2: 0.40170535676581504
a3: 0.010839449735418638
a4: 0.201046003357538
65200
15282
Val cmap: 0.912870653053877
Valid loss: 1.3803
0.8475336322869954
a1: 0.24869258469289018
a2: 0.3431281729737314
a3: 0.007414574054801809
a4: 0.4007646682785766
65200
15282
Val cmap: 0.9128222843120137
Valid loss: 1.3813
0.8474644351464437
a1: 0.31115992700862627
a2: 0.3618673032860503
a3: 0.0057664776468022445
a4: 0.32120629205852114
65200
15282
Val cmap: 0.9128600132951504
Valid loss: 1.3810
0.8473611994243834
a1: 0.27071883886918496
a2: 0.44965089377719175
a3: 0.004695593803301014
a4: 0.2749346735503222
65200
15282
Val cmap: 0.9128659284333259
Valid loss: 1.3800
0.8477605944968869
a1: 0.21697183624113003
a2: 0.42279522084501825
a3: 0.012023498079889094
a4: 0.3482094448339626
65200
15282
Val cmap: 0.9128272140111144
Valid loss: 1.3803
0.8476630507566626
a1: 0.35179476884829985
a2: 0.3812507043556511
a3: 0.007503801077514922
a4: 0.2594507257185341
65200
15282
Val cmap: 0.912853832253918
Valid loss: 1.3806
0.847258005152742
a1: 0.4178442823299589
a2: 0.4091257643606282
a3: 0.008998926294247579
a4: 0.16403102701516536
65200
15282
Val cmap: 0.9128815940508141
Valid loss: 1.3802
0.8476493224025431
a1: 0.2023234634761763
a2: 0.31588257988251023
a3: 0.003003403882603818
a4: 0.4787905527587096
65200
15282
Val cmap: 0.912792401136641
Valid loss: 1.3819
0.8479207125159044
a1: 0.3058111169095131
a2: 0.4360436383698772
a3: 0.008761632579169794
a4: 0.2493836121414399
65200
15282
Val cmap: 0.9128703353335157
Valid loss: 1.3801
0.8476856655175876
a1: 0.28084923163382647
a2: 0.3551521122484512
a3: 0.003613165412897575
a4: 0.36038549070482473
65200
15282
Val cmap: 0.9128444618885114
Valid loss: 1.3812
0.8475030124514661
a1: 0.24691696356844925
a2: 0.48110803605018143
a3: 0.005901575844070587
a4: 0.2660734245372987
65200
15282
Val cmap: 0.9128061779133472
Valid loss: 1.3797
0.8478457366676709
a1: 0.3346067825518838
a2: 0.3906680680857688
a3: 0.013159631514847331
a4: 0.26156551784750004
65200
15282
Val cmap: 0.9128714872225024
Valid loss: 1.3805
0.847322623828648
a1: 0.3790637471672684
a2: 0.4183682194611334
a3: 0.006902055487192869
a4: 0.19566597788440532
65200
15282
Val cmap: 0.9128654543309768
Valid loss: 1.3801
0.8476493224025431
a1: 0.2745343809776109
a2: 0.4584645860104559
a3: 0.004340622562676099
a4: 0.26266041044925714
65200
15282
Val cmap: 0.9128613944342007
Valid loss: 1.3799
0.8477605944968869
a1: 0.3228097547107991
a2: 0.4444806546972943
a3: 0.010094935983881455
a4: 0.22261465460802515
65200
15282
Val cmap: 0.9128512359804603
Valid loss: 1.3799
0.8477140370841423
a1: 0.15728322448883952
a2: 0.5175822564032868
a3: 0.005375328666657171
a4: 0.3197591904412164
65200
15282
Val cmap: 0.9127861236560897
Valid loss: 1.3796
0.8476608285054084
a1: 0.23508719375556666
a2: 0.3436925724067861
a3: 0.002211756098886702
a4: 0.4190084777387606
65200
15282
Val cmap: 0.9128332571030078
Valid loss: 1.3814
0.847531380753138
a1: 0.3584518335075197
a2: 0.3754858179385191
a3: 0.007800231271241956
a4: 0.2582621172827192
65200
15282
Val cmap: 0.9128620250879641
Valid loss: 1.3807
0.8471627408993576
a1: 0.41892758733063384
a2: 0.413574838723657
a3: 0.006203538288317438
a4: 0.1612940356573917
65200
15282
Val cmap: 0.9128601040362394
Valid loss: 1.3801
0.8476493224025431
a1: 0.3040881051391687
a2: 0.3988723282655161
a3: 0.008716335324961029
a4: 0.28832323127035425
65200
15282
Val cmap: 0.9128825828515014
Valid loss: 1.3805
0.8473714151858917
a1: 0.26797058408581376
a2: 0.3663205299450654
a3: 0.004599398174645143
a4: 0.36110948779447566
65200
15282
Val cmap: 0.9128440700301258
Valid loss: 1.3810
0.8474462815449495
a1: 0.2947512475497674
a2: 0.39089021094533444
a3: 0.008466953516991216
a4: 0.305891587987907
65200
15282
Val cmap: 0.912842424256271
Valid loss: 1.3806
0.8475336322869954
a1: 0.333815454820832
a2: 0.4328150296615862
a3: 0.011795365161802249
a4: 0.2215741503557795
65200
15282
Val cmap: 0.9128814933078336
Valid loss: 1.3800
0.8476856655175876
a1: 0.31104497167508854
a2: 0.4060884257801439
a3: 0.00962023795552083
a4: 0.2732463645892468
65200
15282
Val cmap: 0.9129031024929641
Valid loss: 1.3804
0.8473997724382571
a1: 0.20152936684847778
a2: 0.4845970087867111
a3: 0.009817816051418305
a4: 0.30405580831339285
65200
15282
Val cmap: 0.912788334612046
Valid loss: 1.3797
0.847758395553621
a1: 0.38591448820979285
a2: 0.4235836142083635
a3: 0.0068376927871745515
a4: 0.18366420479466905
65200
15282
Val cmap: 0.9128508577396065
Valid loss: 1.3801
0.8477548015793349
a1: 0.2544963532522057
a2: 0.4474858576288898
a3: 0.01468613744745769
a4: 0.28333165167144675
65200
15282
Val cmap: 0.9128786598673684
Valid loss: 1.3799
0.8478173540439208
a1: 0.23394548418878053
a2: 0.4641823333626675
a3: 0.003644747357027835
a4: 0.29822743509152416
65200
15282
Val cmap: 0.912852446210764
Valid loss: 1.3799
0.8477787820963477
a1: 0.3065705103980932
a2: 0.40122485320019413
a3: 0.005329082246125634
a4: 0.2868755541555871
65200
15282
Val cmap: 0.9128776570181512
Valid loss: 1.3805
0.8473044875012549
a1: 0.3398016559459626
a2: 0.4029985905497319
a3: 0.008320639209591068
a4: 0.24887911429471435
65200
15282
Val cmap: 0.9129148462168417
Valid loss: 1.3804
0.8475438361665105
a1: 0.35723112126494394
a2: 0.42709596571931197
a3: 0.007938740389672006
a4: 0.20773417262607208
65200
15282
Val cmap: 0.9128870275202705
Valid loss: 1.3801
0.8475619959171379
a1: 0.346689690311853
a2: 0.3751493142358706
a3: 0.011104482057835482
a4: 0.26705651339444086
65200
15282
Val cmap: 0.9128454446372358
Valid loss: 1.3807
0.8471910864255362
a1: 0.3660972892142861
a2: 0.410757531263016
a3: 0.006495184784312361
a4: 0.21664999473838556
65200
15282
Val cmap: 0.9128847244799161
Valid loss: 1.3803
0.8476391259244386
a1: 0.3605775110600443
a2: 0.42479821306309284
a3: 0.007130727905778991
a4: 0.20749354797108385
65200
15282
Val cmap: 0.912885610827396
Valid loss: 1.3801
0.8476572958500669
a1: 0.33025259482949143
a2: 0.42881315042994766
a3: 0.007616595470645756
a4: 0.23331765926991516
65200
15282
Val cmap: 0.912896830651584
Valid loss: 1.3801
0.8477526021620535
a1: 0.31795601249599825
a2: 0.3892060261575689
a3: 0.004908019507848766
a4: 0.2879299418385841
65200
15282
Val cmap: 0.912865715593743
Valid loss: 1.3806
0.8473714151858917
a1: 0.39890351010595265
a2: 0.43134955918196394
a3: 0.008958293872507255
a4: 0.1607886368395762
65200
15282
Val cmap: 0.9128379712435554
Valid loss: 1.3800
0.8477649892933619
a1: 0.33944177715234347
a2: 0.45396274375899376
a3: 0.007829555402370365
a4: 0.1987659236862924
65200
15282
Val cmap: 0.9128311297083592
Valid loss: 1.3798
0.847687880612996
a1: 0.3860367165281407
a2: 0.4230245082819535
a3: 0.0076998908022905856
a4: 0.1832388843876153
65200
15282
Val cmap: 0.9128523089635389
Valid loss: 1.3801
0.8477264362431827
a1: 0.35953390513416367
a2: 0.43961593407404426
a3: 0.009481199104770443
a4: 0.19136896168702158
65200
15282
Val cmap: 0.9128360478361887
Valid loss: 1.3799
0.8477446125016732
a1: 0.32915517975579867
a2: 0.3933987237268322
a3: 0.005543187371882256
a4: 0.27190290914548687
65200
15282
Val cmap: 0.9128799490085863
Valid loss: 1.3805
0.8474383428705284
a1: 0.4458615045940045
a2: 0.40962406945457225
a3: 0.0071518734514078785
a4: 0.13736255250001544
65200
15282
Val cmap: 0.9128737620975362
Valid loss: 1.3801
0.8475642398286938
a1: 0.2763312801284002
a2: 0.3604748984979462
a3: 0.005969584162327015
a4: 0.3572242372113267
65200
15282
Val cmap: 0.9128385046206734
Valid loss: 1.3811
0.8474644351464437
a1: 0.3694644493037868
a2: 0.4687742539650348
a3: 0.010513263831232215
a4: 0.15124803289994612
65200
15282
Val cmap: 0.912820015582619
Valid loss: 1.3796
0.8475744396119104
a1: 0.29892723939101956
a2: 0.36576804969427845
a3: 0.011936172469714776
a4: 0.32336853844498714
65200
15282
Val cmap: 0.9128483310707509
Valid loss: 1.3809
0.8473895582329317
a1: 0.3186862785446407
a2: 0.42210828960520463
a3: 0.004085875833614042
a4: 0.2551195560165406
65200
15282
Val cmap: 0.9128935703075152
Valid loss: 1.3802
0.8475415871740803
a1: 0.2628007915977828
a2: 0.4469891016553559
a3: 0.004245770990019718
a4: 0.2859643357568416
65200
15282
Val cmap: 0.9128670631924232
Valid loss: 1.3801
0.8477889733203897
a1: 0.3139536324181584
a2: 0.375666974009652
a3: 0.003242503531906687
a4: 0.3071368900402829
65200
15282
Val cmap: 0.9128471447657751
Valid loss: 1.3808
0.8473044875012549
a1: 0.34361793140183794
a2: 0.41174951340443744
a3: 0.005014802616882487
a4: 0.23961775257684215
65200
15282
Val cmap: 0.9129163356112059
Valid loss: 1.3803
0.8474769107214564
a1: 0.3350858836027008
a2: 0.39832683893665605
a3: 0.002762393618819325
a4: 0.2638248838418238
65200
15282
Val cmap: 0.9128943016146
Valid loss: 1.3805
0.8474383428705284
a1: 0.4031135594122318
a2: 0.40193230104498506
a3: 0.00396031001981575
a4: 0.19099382952296737
65200
15282
Val cmap: 0.9128451999198858
Valid loss: 1.3803
0.8475721982398019
a1: 0.33404551610143746
a2: 0.38517347528690565
a3: 0.0050398818956867404
a4: 0.2757411267159701
65200
15282
Val cmap: 0.9128790143847672
Valid loss: 1.3806
0.8472863548149636
a1: 0.270352954225036
a2: 0.34741562229353545
a3: 0.0027538508932985805
a4: 0.3794775725881299
65200
15282
Val cmap: 0.9128376236379288
Valid loss: 1.3813
0.8474360690855537
a1: 0.29361649570716003
a2: 0.41475397881087944
a3: 0.0027238692026637008
a4: 0.28890565627929676
65200
15282
Val cmap: 0.9128836765217753
Valid loss: 1.3804
0.8473611994243834
a1: 0.2433886286399743
a2: 0.338463998643021
a3: 0.0034722104327712658
a4: 0.4146751622842335
65200
15282
Val cmap: 0.9128434940645181
Valid loss: 1.3815
0.847531380753138
a1: 0.3216438330954077
a2: 0.39380520624177595
a3: 0.004416968576507355
a4: 0.280133992086309
65200
15282
Val cmap: 0.9128694114325918
Valid loss: 1.3806
0.847420196747641
a1: 0.2839784873625829
a2: 0.45766502652267144
a3: 0.004049931864678804
a4: 0.2543065542500669
65200
15282
Val cmap: 0.9128532133459946
Valid loss: 1.3799
0.8477605944968869
a1: 0.21213137116585393
a2: 0.49249869288630777
a3: 0.003326951889450043
a4: 0.2920429840583883
65200
15282
Val cmap: 0.9127772459420989
Valid loss: 1.3797
0.8477969733494041
a1: 0.3430261533669729
a2: 0.42896024918778225
a3: 0.008209821262836219
a4: 0.21980377618240857
65200
15282
Val cmap: 0.9128921395287226
Valid loss: 1.3801
0.8476572958500669
a1: 0.34533098967179565
a2: 0.44442991270511895
a3: 0.005968344008443005
a4: 0.2042707536146424
65200
15282
Val cmap: 0.9128546729284395
Valid loss: 1.3799
0.8477911646586346
a1: 0.30920883542971256
a2: 0.41478500906559135
a3: 0.0020813591694957665
a4: 0.27392479633520034
65200
15282
Val cmap: 0.9128973567059788
Valid loss: 1.3804
0.8474564926372156
a1: 0.3071637501030098
a2: 0.40977771166872
a3: 0.002069790735752691
a4: 0.2809887474925175
65200
15282
Val cmap: 0.9128925737342354
Valid loss: 1.3804
0.8474848555841895
a1: 0.37848558851671293
a2: 0.3994112201959978
a3: 0.002362106602001167
a4: 0.21974108468528816
65200
15282
Val cmap: 0.9128524992595046
Valid loss: 1.3804
0.8474564926372156
a1: 0.25845576820403754
a2: 0.37195955047302925
a3: 0.002971866934833784
a4: 0.36661281438809934
65200
15282
Val cmap: 0.9128406182626306
Valid loss: 1.3810
0.8475903614457831
a1: 0.28697944732833713
a2: 0.37962974811683997
a3: 0.002557110779930922
a4: 0.33083369377489197
65200
15282
Val cmap: 0.9128316223581053
Valid loss: 1.3808
0.8473611994243834
a1: 0.3210038692040137
a2: 0.4180995760462096
a3: 0.001545784029959104
a4: 0.2593507707198176
65200
15282
Val cmap: 0.9128991505120074
Valid loss: 1.3803
0.8474848555841895
a1: 0.32263478198091516
a2: 0.4390470817359224
a3: 0.0015399102439554433
a4: 0.23677822603920695
65200
15282
Val cmap: 0.9128726839428257
Valid loss: 1.3801
0.8477242302543507
a1: 0.306724042286845
a2: 0.46126238847393897
a3: 0.001991941892449818
a4: 0.2300216273467662
65200
15282
Val cmap: 0.9128498142531437
Valid loss: 1.3799
0.847695860245641
a1: 0.2341224995649633
a2: 0.4154798301926027
a3: 0.0013561331027830957
a4: 0.34904153713965086
65200
15282
Val cmap: 0.9128546521663837
Valid loss: 1.3805
0.8476630507566626
a1: 0.33371076798411936
a2: 0.38787936103734333
a3: 0.0018563579848815885
a4: 0.2765535129936557
65200
15282
Val cmap: 0.9128908905406629
Valid loss: 1.3807
0.8473147063744353
a1: 0.3774536775876383
a2: 0.41553090785684926
a3: 0.002417526342548151
a4: 0.20459788821296432
65200
15282
Val cmap: 0.912846773523519
Valid loss: 1.3802
0.8476391259244386
a1: 0.2845539761495004
a2: 0.3570203947718395
a3: 0.003667559543624348
a4: 0.35475806953503575
65200
15282
Val cmap: 0.9128441014627328
Valid loss: 1.3811
0.8474360690855537
a1: 0.2645978519384351
a2: 0.43501669877130855
a3: 0.004835126290570767
a4: 0.2955503229996856
65200
15282
Val cmap: 0.9128695448733336
Valid loss: 1.3802
0.8475881230542631
a1: 0.3524639944501124
a2: 0.4030679806402817
a3: 0.0017128992797424592
a4: 0.24275512562986337
65200
15282
Val cmap: 0.912871058845221
Valid loss: 1.3804
0.8475052705551651
a1: 0.4037758779616716
a2: 0.4237281288310766
a3: 0.0066017352792941755
a4: 0.16589425792795767
65200
15282
Val cmap: 0.9128559994468565
Valid loss: 1.3801
0.8476697112650139
a1: 0.3166464079240908
a2: 0.3909645820309783
a3: 0.0023105739228773663
a4: 0.29007843612205353
65200
15282
Val cmap: 0.9128632323829257
Valid loss: 1.3806
0.8474485527856783
a1: 0.29805507095376615
a2: 0.4768558228877515
a3: 0.005365831367033138
a4: 0.21972327479144918
65200
15282
Val cmap: 0.9128599227479798
Valid loss: 1.3797
0.8478093516752017
a1: 0.24822304999538933
a2: 0.36365572907047705
a3: 0.002865774198428582
a4: 0.385255446735705
65200
15282
Val cmap: 0.9128343407834459
Valid loss: 1.3811
0.8474462815449495
a1: 0.3077032024822429
a2: 0.41131300510072316
a3: 0.0018784219213036281
a4: 0.2791053704957303
65200
15282
Val cmap: 0.9128919104222447
Valid loss: 1.3804
0.8474848555841895
a1: 0.3289420186327774
a2: 0.3999317995730522
a3: 0.0021929905303797446
a4: 0.26893319126379067
65200
15282
Val cmap: 0.9128950020586887
Valid loss: 1.3805
0.8473816295800569
a1: 0.33661705158850735
a2: 0.429044965589009
a3: 0.002112069241952027
a4: 0.23222591358053155
65200
15282
Val cmap: 0.9128966470255825
Valid loss: 1.3802
0.8477140370841423
a1: 0.368101291670041
a2: 0.43375192176559263
a3: 0.0020906975245643523
a4: 0.196056089039802
65200
15282
Val cmap: 0.9128424306655617
Valid loss: 1.3801
0.8478115379467273
a1: 0.3401553866011302
a2: 0.4462079129492474
a3: 0.002694872094059022
a4: 0.21094182835556338
65200
15282
Val cmap: 0.9128530345683455
Valid loss: 1.3800
0.8477627924098925
a1: 0.38250417165215245
a2: 0.41938602803397906
a3: 0.0021731688104200345
a4: 0.19593663150344845
65200
15282
Val cmap: 0.9128452656700692
Valid loss: 1.3802
0.8477548015793349
a1: 0.3271604641950731
a2: 0.3825111218790154
a3: 0.0015574464187095767
a4: 0.2887709675072018
65200
15282
Val cmap: 0.9128765821072784
Valid loss: 1.3807
0.8472296573875804
a1: 0.4264022996139664
a2: 0.4047190768677742
a3: 0.00323929836868501
a4: 0.16563932514957433
65200
15282
Val cmap: 0.9128887519456096
Valid loss: 1.3803
0.8475154759913001
a1: 0.35492809524651286
a2: 0.39539371561550285
a3: 0.0013773592156877867
a4: 0.24830082992229655
65200
15282
Val cmap: 0.9128780686424526
Valid loss: 1.3805
0.8473714151858917
a1: 0.40222483271701565
a2: 0.4301651990318303
a3: 0.0016662856847718375
a4: 0.16594368256638214
65200
15282
Val cmap: 0.9128191862769615
Valid loss: 1.3801
0.8477649892933619
a1: 0.27742399896787534
a2: 0.45682822777921867
a3: 0.0023997793065872494
a4: 0.2633479939463188
65200
15282
Val cmap: 0.9128565558245083
Valid loss: 1.3800
0.8477605944968869
a1: 0.32435334874470856
a2: 0.4034073528468001
a3: 0.001993413107667042
a4: 0.2702458853008243
65200
15282
Val cmap: 0.9128865713567177
Valid loss: 1.3805
0.8473044875012549
a1: 0.2902085763322166
a2: 0.37246223506668014
a3: 0.04850532932673066
a4: 0.28882385927437254
65200
15282
Val cmap: 0.9128830427346903
Valid loss: 1.3803
0.8474179189397236
a1: 0.3411075349545462
a2: 0.4213017072959875
a3: 0.007145542121709118
a4: 0.23044521562775713
65200
15282
Val cmap: 0.9129205242182219
Valid loss: 1.3802
0.8475619959171379
a1: 0.34794322776410486
a2: 0.4224756987785047
a3: 0.009666572804840986
a4: 0.2199145006525495
65200
15282
Val cmap: 0.9129049319683473
Valid loss: 1.3801
0.847695860245641
a1: 0.36606012806776456
a2: 0.44011028792620666
a3: 0.00953209416901889
a4: 0.1842974898370099
65200
15282
Val cmap: 0.912826758901414
Valid loss: 1.3799
0.847687880612996
a1: 0.3467888938922533
a2: 0.4216244669012631
a3: 0.010641065190718509
a4: 0.2209455740157651
65200
15282
Val cmap: 0.9129114023550836
Valid loss: 1.3801
0.847695860245641
a1: 0.3504568638176573
a2: 0.44893661784480543
a3: 0.010944389779601386
a4: 0.1896621285579359
65200
15282
Val cmap: 0.912824399555548
Valid loss: 1.3798
0.8477729812937121
a1: 0.3673345346650775
a2: 0.42289984457932817
a3: 0.009590494777697285
a4: 0.20017512597789708
65200
15282
Val cmap: 0.9128681060234655
Valid loss: 1.3801
0.8478013519844723
a1: 0.3953001873729309
a2: 0.41683725906536684
a3: 0.008876310520293487
a4: 0.17898624304140875
65200
15282
Val cmap: 0.9128630578121735
Valid loss: 1.3801
0.8477264362431827
a1: 0.33662414047663286
a2: 0.38944880764385953
a3: 0.013533636041735395
a4: 0.26039341583777226
65200
15282
Val cmap: 0.9128789027497608
Valid loss: 1.3805
0.847332842513888
a1: 0.3034096919911141
a2: 0.40211461741041643
a3: 0.007221647267027844
a4: 0.2872540433314416
65200
15282
Val cmap: 0.912895335086995
Valid loss: 1.3805
0.847332842513888
a1: 0.2990719448663681
a2: 0.430715467296646
a3: 0.007062493577884111
a4: 0.26315009425910174
65200
15282
Val cmap: 0.9128776126452375
Valid loss: 1.3801
0.8476368991832909
a1: 0.31151595981427255
a2: 0.3807233580300511
a3: 0.008230253298224525
a4: 0.2995304288574519
65200
15282
Val cmap: 0.9128425035828764
Valid loss: 1.3807
0.847332842513888
a1: 0.35091800772217824
a2: 0.4099622203380539
a3: 0.007432649970642358
a4: 0.23168712196912544
65200
15282
Val cmap: 0.912894271466884
Valid loss: 1.3803
0.8475234270414993
a1: 0.2744763542724534
a2: 0.4653630661957156
a3: 0.010332291567179764
a4: 0.2498282879646512
65200
15282
Val cmap: 0.9128631307441253
Valid loss: 1.3798
0.8477605944968869
a1: 0.3812579116063523
a2: 0.44032757439396436
a3: 0.006656916807566517
a4: 0.17175759719211675
65200
15282
Val cmap: 0.9128141586775709
Valid loss: 1.3799
0.8477548015793349
a1: 0.30121905182187814
a2: 0.39792155722837014
a3: 0.01582035368821814
a4: 0.28503903726153357
65200
15282
Val cmap: 0.9129077510016764
Valid loss: 1.3804
0.8473997724382571
a1: 0.300266849881321
a2: 0.42195457204935527
a3: 0.012360875339872525
a4: 0.2654177027294512
65200
15282
Val cmap: 0.9128856270628692
Valid loss: 1.3802
0.8475132204297477
a1: 0.2640868235670387
a2: 0.47153225838898805
a3: 0.017859587253267733
a4: 0.2465213307907055
65200
15282
Val cmap: 0.9128332642428485
Valid loss: 1.3796
0.8477787820963477
a1: 0.3246749103696214
a2: 0.3977627394881519
a3: 0.02156327934473204
a4: 0.25599907079749473
65200
15282
Val cmap: 0.9129234190847493
Valid loss: 1.3803
0.8474667023626263
a1: 0.3128390922516409
a2: 0.3887694303561549
a3: 0.023169677240381683
a4: 0.27522180015182257
65200
15282
Val cmap: 0.9128798624038379
Valid loss: 1.3804
0.8472863548149636
a1: 0.34798861104191325
a2: 0.4113737480316925
a3: 0.016038227367176028
a4: 0.2245994135592182
65200
15282
Val cmap: 0.9128935520648757
Valid loss: 1.3802
0.8475517922286557
a1: 0.2949136157843666
a2: 0.3699173458328781
a3: 0.020433647468437413
a4: 0.3147353909143179
65200
15282
Val cmap: 0.9128538294773333
Valid loss: 1.3807
0.8473895582329317
a1: 0.3248512461436503
a2: 0.4349930989112061
a3: 0.030092247349885227
a4: 0.21006340759525835
65200
15282
Val cmap: 0.912866032145327
Valid loss: 1.3798
0.847677687056619
a1: 0.2801789695668043
a2: 0.4509578134521821
a3: 0.01342997591606499
a4: 0.2554332410649486
65200
15282
Val cmap: 0.9128519056733556
Valid loss: 1.3799
0.8478173540439208
a1: 0.36176557882738464
a2: 0.40182356960089916
a3: 0.008577594188720323
a4: 0.22783325738299595
65200
15282
Val cmap: 0.9128755692240251
Valid loss: 1.3803
0.8474667023626263
a1: 0.2561556022393261
a2: 0.35498508119247957
a3: 0.011428427671143996
a4: 0.37743088889705034
65200
15282
Val cmap: 0.9128321987674016
Valid loss: 1.3811
0.8474746460488001
a1: 0.34006006180198983
a2: 0.42283384668153756
a3: 0.014959337937018726
a4: 0.22214675357945393
65200
15282
Val cmap: 0.9129117604417213
Valid loss: 1.3801
0.8477060536090754
a1: 0.3367326625523764
a2: 0.4247901106656555
a3: 0.019230278270721518
a4: 0.21924694851124668
65200
15282
Val cmap: 0.912914519237284
Valid loss: 1.3800
0.8476493224025431
a1: 0.3380727552888746
a2: 0.4263199336935233
a3: 0.01494655949807986
a4: 0.22066075151952227
65200
15282
Val cmap: 0.9129135941074739
Valid loss: 1.3800
0.8476107616115648
a1: 0.38007904821905375
a2: 0.4156640986389432
a3: 0.015219639067692792
a4: 0.1890372140743103
65200
15282
Val cmap: 0.912867607641994
Valid loss: 1.3801
0.847677687056619
a1: 0.3227235894414316
a2: 0.4243951410968575
a3: 0.019722072810513854
a4: 0.2331591966511971
65200
15282
Val cmap: 0.912908055408411
Valid loss: 1.3800
0.847695860245641
a1: 0.34423615973256105
a2: 0.4218605960255007
a3: 0.01856597757797832
a4: 0.21533726666395994
65200
15282
Val cmap: 0.9129103173928907
Valid loss: 1.3800
0.8476391259244386
a1: 0.3500660997324571
a2: 0.44354209759775837
a3: 0.018083840094473058
a4: 0.1883079625753114
65200
15282
Val cmap: 0.912830693951055
Valid loss: 1.3798
0.8478013519844723
a1: 0.3668710495820457
a2: 0.4247753079898246
a3: 0.01912390550518265
a4: 0.189229736922947
65200
15282
Val cmap: 0.9128663600622539
Valid loss: 1.3799
0.8478399089783489
a1: 0.3925533953233645
a2: 0.3950615502676644
a3: 0.01628679541079203
a4: 0.19609825899817918
65200
15282
Val cmap: 0.9128653147106056
Valid loss: 1.3803
0.847428131588635
a1: 0.4287483155255873
a2: 0.41101252460808363
a3: 0.021481488179465245
a4: 0.1387576716868638
65200
15282
Val cmap: 0.9128790705279206
Valid loss: 1.3800
0.8475642398286938
a1: 0.3364212650725836
a2: 0.38239808446050105
a3: 0.014367437211102509
a4: 0.2668132132558129
65200
15282
Val cmap: 0.9128720387192598
Valid loss: 1.3805
0.8472194338486247
a1: 0.31858973834813786
a2: 0.4543455738434072
a3: 0.018217372087199795
a4: 0.20884731572125517
65200
15282
Val cmap: 0.9128127514925958
Valid loss: 1.3797
0.8477242302543507
a1: 0.3169136182165689
a2: 0.4163623043498058
a3: 0.02551261690911629
a4: 0.24121146052450906
65200
15282
Val cmap: 0.9129128803498003
Valid loss: 1.3800
0.8476289280813895
a1: 0.34859085477944673
a2: 0.43202707551794295
a3: 0.026393524761262485
a4: 0.19298854494134782
65200
15282
Val cmap: 0.9128529710248806
Valid loss: 1.3798
0.847687880612996
a1: 0.31988756926769846
a2: 0.41884608094208736
a3: 0.01684687757891052
a4: 0.24441947221130367
65200
15282
Val cmap: 0.9128970549315786
Valid loss: 1.3801
0.8474950637528864
a1: 0.2920521592582707
a2: 0.39821959423687064
a3: 0.021732093338041283
a4: 0.2879961531668173
65200
15282
Val cmap: 0.9129009275360389
Valid loss: 1.3803
0.8473714151858917
a1: 0.2856379457409228
a2: 0.39271911599186404
a3: 0.021568443118077294
a4: 0.3000744951491358
65200
15282
Val cmap: 0.9128880556562075
Valid loss: 1.3804
0.8475517922286557
a1: 0.23084507728628145
a2: 0.37525475198509006
a3: 0.019347890135464788
a4: 0.3745522805931637
65200
15282
Val cmap: 0.912828368610819
Valid loss: 1.3808
0.8475983263598327
a1: 0.2965747784644529
a2: 0.4439698054171164
a3: 0.023642130035437553
a4: 0.23581328608299315
65200
15282
Val cmap: 0.9128352410046213
Valid loss: 1.3798
0.8478093516752017
a1: 0.33587673501804094
a2: 0.407426558383246
a3: 0.02021460648209166
a4: 0.2364821001166214
65200
15282
Val cmap: 0.9129238980382302
Valid loss: 1.3802
0.8475052705551651
a1: 0.5046310006807075
a2: 0.4062797872159773
a3: 0.01693159893283687
a4: 0.0721576131704783
65200
15282
Val cmap: 0.9128384509524701
Valid loss: 1.3799
0.8474020542674563
a1: 0.33590675586249596
a2: 0.4350841193972523
a3: 0.02101836815238198
a4: 0.20799075658786978
65200
15282
Val cmap: 0.9128673190123483
Valid loss: 1.3799
0.8476674921357339
a1: 0.31660823261727195
a2: 0.42318096854695797
a3: 0.026420167533947145
a4: 0.23379063130182298
65200
15282
Val cmap: 0.9129055288444413
Valid loss: 1.3799
0.8477344220601032
a1: 0.31020598775600633
a2: 0.41985237570440104
a3: 0.022723753445410007
a4: 0.24721788309418258
65200
15282
Val cmap: 0.9128974956769009
Valid loss: 1.3800
0.8476572958500669
a1: 0.2705326842573448
a2: 0.3903517747622351
a3: 0.026353463463168737
a4: 0.3127620775172514
65200
15282
Val cmap: 0.912892410219743
Valid loss: 1.3804
0.8475415871740803
a1: 0.3679475250592944
a2: 0.4094202948866162
a3: 0.02053056684268143
a4: 0.202101613211408
65200
15282
Val cmap: 0.9129014031561905
Valid loss: 1.3801
0.8476391259244386
a1: 0.3654285089170317
a2: 0.40719640141477664
a3: 0.026087924172216993
a4: 0.20128716549597464
65200
15282
Val cmap: 0.9128999418183055
Valid loss: 1.3800
0.8475721982398019
a1: 0.36933177597969014
a2: 0.405695092416501
a3: 0.02498230416303227
a4: 0.19999082744077662
65200
15282
Val cmap: 0.9128988633285156
Valid loss: 1.3801
0.8476005622113647
a1: 0.35745839843034605
a2: 0.4315405430514793
a3: 0.019635911432014472
a4: 0.1913651470861601
65200
15282
Val cmap: 0.9128583232678482
Valid loss: 1.3799
0.8477162456081646
a1: 0.3898600853752046
a2: 0.40806636305313654
a3: 0.024868785381020803
a4: 0.1772047661906381
65200
15282
Val cmap: 0.9128504789209987
Valid loss: 1.3800
0.8475823991969217
a1: 0.3307559964346006
a2: 0.3949087877843602
a3: 0.015215357545347459
a4: 0.2591198582356918
65200
15282
Val cmap: 0.9128850870506671
Valid loss: 1.3804
0.8474383428705284
a1: 0.3503901097989857
a2: 0.42265537156746413
a3: 0.02103942682551696
a4: 0.20591509180803325
65200
15282
Val cmap: 0.9128942714059983
Valid loss: 1.3800
0.847695860245641
a1: 0.29789526052984805
a2: 0.4518027701315569
a3: 0.028602836449850632
a4: 0.22169913288874443
65200
15282
Val cmap: 0.9128296689397057
Valid loss: 1.3796
0.8477707859151158
a1: 0.34138765320748304
a2: 0.4103031929891838
a3: 0.018992128793531474
a4: 0.22931702500980167
65200
15282
Val cmap: 0.9129081980074593
Valid loss: 1.3801
0.8475234270414993
a1: 0.3671255868428438
a2: 0.4057097410903494
a3: 0.01853866023925936
a4: 0.20862601182754742
65200
15282
Val cmap: 0.9129067415793762
Valid loss: 1.3802
0.8475234270414993
a1: 0.3441645658445972
a2: 0.4270201455695367
a3: 0.018553439525242226
a4: 0.21026184906062387
65200
15282
Val cmap: 0.9129129249275152
Valid loss: 1.3800
0.8476209596466574
a1: 0.34482143343939065
a2: 0.43630911434403846
a3: 0.01702033884191061
a4: 0.20184911337466027
65200
15282
Val cmap: 0.9128539321495391
Valid loss: 1.3799
0.847695860245641
a1: 0.37687951343599635
a2: 0.42136646055934396
a3: 0.017841663300941373
a4: 0.18391236270371833
65200
15282
Val cmap: 0.9128623789113286
Valid loss: 1.3800
0.8477831688137862
a1: 0.40206698228090443
a2: 0.4295974599424797
a3: 0.01953865864887876
a4: 0.14879689912773708
65200
15282
Val cmap: 0.9128269203900486
Valid loss: 1.3798
0.8476311563169165
a1: 0.3348542126088334
a2: 0.4109401574184007
a3: 0.014544846490848737
a4: 0.23966078348191716
65200
15282
Val cmap: 0.91292043155427
Valid loss: 1.3802
0.8474769107214564
a1: 0.3385836627301406
a2: 0.384669829752384
a3: 0.01457275485061222
a4: 0.26217375266686316
65200
15282
Val cmap: 0.9128620241289673
Valid loss: 1.3805
0.8472863548149636
a1: 0.3618074307257476
a2: 0.4126790864013698
a3: 0.015792940190222173
a4: 0.2097205426826604
65200
15282
Val cmap: 0.9128851224939024
Valid loss: 1.3801
0.8476572958500669
a1: 0.32043180988586945
a2: 0.4409732284739646
a3: 0.012885369711342909
a4: 0.22570959192882312
65200
15282
Val cmap: 0.912857272042448
Valid loss: 1.3799
0.8476856655175876
a1: 0.3311717432518125
a2: 0.42566570383959135
a3: 0.01834386227920405
a4: 0.2248186906293922
65200
15282
Val cmap: 0.9129091219482846
Valid loss: 1.3800
0.8476674921357339
a1: 0.3400238678601159
a2: 0.42499669207873814
a3: 0.018135441979824
a4: 0.2168439980813219
65200
15282
Val cmap: 0.9129151128691095
Valid loss: 1.3800
0.8476493224025431
a1: 0.3359691511175
a2: 0.42888202995832436
a3: 0.018653991534075293
a4: 0.21649482739010031
65200
15282
Val cmap: 0.9129152429212299
Valid loss: 1.3800
0.8477060536090754
a1: 0.33736527053629833
a2: 0.4572257430171987
a3: 0.018163872322757308
a4: 0.1872451141237456
65200
15282
Val cmap: 0.9128232268612474
Valid loss: 1.3797
0.8478115379467273
a1: 0.3453371552803412
a2: 0.4304356309720504
a3: 0.016175310755583528
a4: 0.2080519029920248
65200
15282
Val cmap: 0.9128825557613344
Valid loss: 1.3800
0.8476107616115648
a1: 0.3301485094011593
a2: 0.44557843553876775
a3: 0.014091772359013034
a4: 0.21018128270105985
65200
15282
Val cmap: 0.9128354025946227
Valid loss: 1.3798
0.847695860245641
a1: 0.3136292988173674
a2: 0.12732526358244672
a3: 0.02330662500994934
a4: 0.5357388125902366
65200
15282
Val cmap: 0.9126672791676067
Valid loss: 1.3850
0.8481237237639341
a1: 0.35317355070059453
a2: 0.42525227768956164
a3: 0.018766923533462463
a4: 0.20280724807638137
65200
15282
Val cmap: 0.9128901009312929
Valid loss: 1.3800
0.8477060536090754
a1: 0.38341351236800547
a2: 0.41753984031549757
a3: 0.016362090541198922
a4: 0.18268455677529805
65200
15282
Val cmap: 0.9128616654636648
Valid loss: 1.3800
0.8476980728051392
a1: 0.32234017884728333
a2: 0.40325827161459254
a3: 0.019198669231163784
a4: 0.25520288030696037
65200
15282
Val cmap: 0.9129170259322883
Valid loss: 1.3803
0.8474485527856783
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.912930015884743
Valid loss: 1.3803
0.8474769107214564
a1: 0.31871089060529695
a2: 0.3969279268261256
a3: 0.019689092300374127
a4: 0.2646720902682034
65200
15282
Val cmap: 0.9129237297309042
Valid loss: 1.3803
0.8474383428705284
a1: 0.3279705860763008
a2: 0.39484385670218247
a3: 0.019240975106059544
a4: 0.2579445821154572
65200
15282
Val cmap: 0.9129165277450785
Valid loss: 1.3803
0.8474383428705284
a1: 0.3261278636549631
a2: 0.3855070374139664
a3: 0.020627948626837214
a4: 0.26773715030423323
65200
15282
Val cmap: 0.9128759515716721
Valid loss: 1.3804
0.8472761343862938
a1: 0.3286373072217748
a2: 0.3928045962448286
a3: 0.015170774515549334
a4: 0.2633873220178473
65200
15282
Val cmap: 0.9128885029548202
Valid loss: 1.3804
0.8473611994243834
a1: 0.30777556451264176
a2: 0.37445218200048613
a3: 0.01758888429992029
a4: 0.3001833691869518
65200
15282
Val cmap: 0.9128423077060634
Valid loss: 1.3807
0.8474179189397236
a1: 0.34121689621090784
a2: 0.39786555676741125
a3: 0.02264419863761347
a4: 0.23827334838406738
65200
15282
Val cmap: 0.9128935132793604
Valid loss: 1.3802
0.8474564926372156
Date :05/13/2023, 23:12:16
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.912930
Valid loss: 1.380298
0.8474769107214564
{'a1': 0.6937323135173985, 'a2': 0.257843135443901, 'a3': 0.013153408823788099}
Date :05/13/2023, 23:25:01
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
Date :05/13/2023, 23:25:20
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.911080
Valid loss: 1.349437
0.8463233820877579
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Date :05/13/2023, 23:30:11
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.911118
Valid loss: 1.346453
0.8464179751308464
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.911118
Valid loss: 1.346453
0.8464179751308464
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Date :05/13/2023, 23:37:45
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
65200
15282
Date :05/13/2023, 23:38:02
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.911118
Valid loss: 1.346453
0.8464179751308464
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.911118
Valid loss: 1.346453
0.8464179751308464
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Date :05/13/2023, 23:48:42
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.911169
Valid loss: 1.348775
0.8466700050075113
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Val cmap: 0.911155
Valid loss: 1.348692
0.846690476985213
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65200
15282
Val cmap: 0.911178
Valid loss: 1.350527
0.846320707492074
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
65200
15282
Date :05/14/2023, 11:01:43
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.6937323135173985
a2: 0.257843135443901
a3: 0.013153408823788099
a4: 0.035271142214912427
65200
15282
Val cmap: 0.911162
Valid loss: 1.348775
0.8466700050075113
a1: 0.720851618618346
a2: 0.2646901786546922
a3: 0.0009314628127102604
a4: 0.013526739914251538
65200
15282
Val cmap: 0.911142
Valid loss: 1.348692
0.846690476985213
a1: 0.4100382340998717
a2: 0.029604937720546853
a3: 0.0017115421256902786
a4: 0.5586452860538912
65200
15282
Val cmap: 0.911178
Valid loss: 1.350526
0.846320707492074
a1: 0.5034775764035694
a2: 0.09994692322484082
a3: 0.08337430214449879
a4: 0.313201198227091
65200
15282
Val cmap: 0.911151
Valid loss: 1.350611
0.8465467169609775
a1: 0.19177019100713733
a2: 0.5660120151476459
a3: 0.004637129988249596
a4: 0.23758066385696722
65200
15282
Val cmap: 0.911177
Valid loss: 1.344826
0.8459872738781357
a1: 0.7669601802716342
a2: 0.002080856070885987
a3: 0.0016824296321262741
a4: 0.22927653402535358
65200
15282
Val cmap: 0.911079
Valid loss: 1.351757
0.8468757305547207
a1: 0.11073318159558475
a2: 0.2206725681169661
a3: 0.0010493901027721795
a4: 0.667544860184677
65200
15282
Val cmap: 0.911030
Valid loss: 1.348320
0.8454921312349961
a1: 0.7203206215385822
a2: 0.09535469483132053
a3: 0.002572012283329829
a4: 0.18175267134676742
65200
15282
Val cmap: 0.911125
Valid loss: 1.350461
0.8468420349846442
a1: 0.9001786173183521
a2: 0.09670108951510281
a3: 0.0014207798527804268
a4: 0.001699513313764625
65200
15282
Val cmap: 0.911074
Valid loss: 1.351374
0.8470478226021907
a1: 0.2572813990258973
a2: 0.43339924750918973
a3: 0.006022677214322562
a4: 0.3032966762505904
65200
15282
Val cmap: 0.911126
Valid loss: 1.345970
0.8461923012831195
a1: 0.37938796293965765
a2: 0.43620702950173984
a3: 0.020459289537260658
a4: 0.16394571802134178
65200
15282
Val cmap: 0.911122
Valid loss: 1.346215
0.8461974460707498
a1: 0.058006390075137276
a2: 0.7468513066615183
a3: 0.004132647388203495
a4: 0.19100965587514088
65200
15282
Val cmap: 0.911078
Valid loss: 1.343609
0.8452523638300705
a1: 0.26640344576561475
a2: 0.5443798161640354
a3: 0.004627310424917457
a4: 0.18458942764543232
65200
15282
Val cmap: 0.911165
Valid loss: 1.345034
0.8460436448442447
a1: 0.5068595169016182
a2: 0.019652589452044095
a3: 0.008820257197774697
a4: 0.464667636448563
65200
15282
Val cmap: 0.911128
Valid loss: 1.350829
0.8463001902473214
a1: 0.16874733892483398
a2: 0.6342859214531106
a3: 0.0031662130745127646
a4: 0.1938005265475427
65200
15282
Val cmap: 0.911106
Valid loss: 1.344307
0.8457028647568288
a1: 0.3606929884582907
a2: 0.35882711843300075
a3: 0.0020821181763827907
a4: 0.2783977749323258
65200
15282
Val cmap: 0.911109
Valid loss: 1.346715
0.846407734622437
a1: 0.017283932700296822
a2: 0.9103675498802135
a3: 0.0028912589560481415
a4: 0.06945725846344153
65200
15282
Val cmap: 0.911023
Valid loss: 1.342783
0.84564696485623
a1: 0.2056185150327045
a2: 0.36042067820351803
a3: 0.023302590093172423
a4: 0.410658216670605
65200
15282
Val cmap: 0.911117
Valid loss: 1.346810
0.8459127883717829
a1: 0.392214888019437
a2: 0.1842274546697888
a3: 0.006782170355343243
a4: 0.41677548695543104
65200
15282
Val cmap: 0.911083
Valid loss: 1.348633
0.846289811572453
a1: 0.12802986933034033
a2: 0.5510625138448619
a3: 0.0018538348451345667
a4: 0.31905378197966316
65200
15282
Val cmap: 0.911135
Valid loss: 1.344937
0.8457592111399826
a1: 0.5701568959108129
a2: 0.14671495911655127
a3: 0.2747440846683931
a4: 0.008384060304242713
65200
15282
Val cmap: 0.911026
Valid loss: 1.352755
0.8469227426202653
a1: 0.2703385094676942
a2: 0.4957411897962763
a3: 0.0049395503096668104
a4: 0.22898075042636268
65200
15282
Val cmap: 0.911123
Valid loss: 1.345430
0.8461743535057318
a1: 0.27414752934396597
a2: 0.3777683877403536
a3: 0.004184392975446987
a4: 0.3438996899402335
65200
15282
Val cmap: 0.911079
Valid loss: 1.346482
0.8461692338467693
a1: 0.3351086809649867
a2: 0.32404179885893236
a3: 0.009459188670437303
a4: 0.3313903315056436
65200
15282
Val cmap: 0.911079
Valid loss: 1.347095
0.846397492748308
a1: 0.1923502736723114
a2: 0.5621702450175946
a3: 0.0027310383211076026
a4: 0.2427484429889864
65200
15282
Val cmap: 0.911184
Valid loss: 1.344841
0.8459872738781357
a1: 0.0910386579861504
a2: 0.6305105464455163
a3: 0.0013901381413338725
a4: 0.2770606574269994
65200
15282
Val cmap: 0.911141
Valid loss: 1.344344
0.8454466724402105
a1: 0.01298677580870139
a2: 0.6508210557228313
a3: 0.0026552810930903694
a4: 0.33353688737537684
65200
15282
Val cmap: 0.911112
Valid loss: 1.344292
0.8454006527676015
a1: 0.1511100077463441
a2: 0.47274302535505286
a3: 0.001051994407520777
a4: 0.37509497249108226
65200
15282
Val cmap: 0.911121
Valid loss: 1.345588
0.8458052908642633
a1: 0.2145492978596183
a2: 0.33653035981523716
a3: 0.002366148184979794
a4: 0.44655419414016473
65200
15282
Val cmap: 0.911119
Valid loss: 1.346882
0.8460640816190445
a1: 0.40964138680380063
a2: 0.28068201684093136
a3: 0.010471522302468226
a4: 0.2992050740527997
65200
15282
Val cmap: 0.911128
Valid loss: 1.347636
0.8465001500650281
a1: 0.4426871698191742
a2: 0.2241774590268526
a3: 0.0017013806640457582
a4: 0.33143399048992744
65200
15282
Val cmap: 0.911129
Valid loss: 1.348203
0.8463565115891278
a1: 0.30663075291425934
a2: 0.5240243951952964
a3: 0.003670338889725471
a4: 0.16567451300071875
65200
15282
Val cmap: 0.911135
Valid loss: 1.345228
0.8463358549671742
a1: 0.2138270992118323
a2: 0.45253518860894265
a3: 0.005912769716168336
a4: 0.3277249424630567
65200
15282
Val cmap: 0.911097
Valid loss: 1.345788
0.8461256457257124
a1: 0.1781702378449985
a2: 0.5510057976421299
a3: 0.0033813658058527317
a4: 0.26744259870701886
65200
15282
Val cmap: 0.911173
Valid loss: 1.344933
0.8458334721620631
a1: 0.16609848161770602
a2: 0.4120810934651364
a3: 0.016243019061885407
a4: 0.4055774058552722
65200
15282
Val cmap: 0.911119
Valid loss: 1.346260
0.8458948631621055
a1: 0.08923754477376454
a2: 0.5833355409776386
a3: 0.0032690832974377137
a4: 0.32415783095115913
65200
15282
Val cmap: 0.911131
Valid loss: 1.344718
0.8454645391252208
a1: 0.3447369534920235
a2: 0.29182342798800887
a3: 0.0011308873105314056
a4: 0.36230873120943624
65200
15282
Val cmap: 0.911070
Valid loss: 1.347358
0.8463667589288693
a1: 0.2027895391620559
a2: 0.39373385228174407
a3: 0.0019248351590132294
a4: 0.40155177339718684
65200
15282
Val cmap: 0.911120
Valid loss: 1.346308
0.8458948631621055
a1: 0.3052467224848777
a2: 0.4776993648472212
a3: 0.0013630962701346979
a4: 0.21569081639776638
65200
15282
Val cmap: 0.911077
Valid loss: 1.345581
0.8460974471772311
a1: 0.11791577311244256
a2: 0.5188197075323507
a3: 0.0022032011037202933
a4: 0.36106131825148646
65200
15282
Val cmap: 0.911163
Valid loss: 1.345216
0.8456080743479565
a1: 0.0641693367244093
a2: 0.5861016029483052
a3: 0.00090066503979662
a4: 0.34882839528748893
65200
15282
Val cmap: 0.911133
Valid loss: 1.344706
0.8454748342826689
a1: 0.2584883627410707
a2: 0.4279944883711341
a3: 0.00476917156223888
a4: 0.30874797732555637
65200
15282
Val cmap: 0.911132
Valid loss: 1.346009
0.8461923012831195
a1: 0.23493664531747427
a2: 0.04735787398432477
a3: 0.007716850279586534
a4: 0.7099886304186144
65200
15282
Val cmap: 0.911071
Valid loss: 1.350417
0.8457920544381067
a1: 0.178681225173703
a2: 0.5123407305043844
a3: 0.0036279601477835276
a4: 0.305350084174129
65200
15282
Val cmap: 0.911155
Valid loss: 1.345252
0.8459180273242253
a1: 0.3070655232112046
a2: 0.2480602531867726
a3: 0.005380654104682057
a4: 0.4394935694973407
65200
15282
Val cmap: 0.911097
Valid loss: 1.347847
0.8464334544969487
a1: 0.14584269835432973
a2: 0.5475749694960123
a3: 0.002993225940975771
a4: 0.30358910620868224
65200
15282
Val cmap: 0.911131
Valid loss: 1.344965
0.8457873871472832
a1: 0.2429379390135581
a2: 0.46555714467105236
a3: 0.0023921954898017124
a4: 0.28911272082558787
65200
15282
Val cmap: 0.911113
Valid loss: 1.345649
0.8463076512929885
a1: 0.18349574534056737
a2: 0.0647794094047344
a3: 0.012374573012665818
a4: 0.7393502722420324
65200
15282
Val cmap: 0.911075
Valid loss: 1.350297
0.8457459226895242
a1: 0.4336948085855542
a2: 0.13859916207168899
a3: 0.0070716903654327095
a4: 0.4206343389773241
65200
15282
Val cmap: 0.911115
Valid loss: 1.349218
0.8462025949768186
a1: 0.12897853477423743
a2: 0.005371567071917029
a3: 0.0015416289511205818
a4: 0.8641082692027251
65200
15282
Val cmap: 0.910928
Valid loss: 1.351204
0.8457074244546727
a1: 0.3508016355661708
a2: 0.44539603094297936
a3: 0.004128834465560545
a4: 0.19967349902528939
65200
15282
Val cmap: 0.911094
Valid loss: 1.345936
0.8462769148723419
a1: 0.12254333046279356
a2: 0.5356685643365433
a3: 0.00219754096993691
a4: 0.33959056423072626
65200
15282
Val cmap: 0.911140
Valid loss: 1.345070
0.8457413144132442
a1: 0.06753530137785588
a2: 0.571516170519984
a3: 0.00272810499332134
a4: 0.3582204231088387
65200
15282
Val cmap: 0.911132
Valid loss: 1.344832
0.8455517436631916
a1: 0.11132181724029563
a2: 0.514751160996342
a3: 0.0020917170977845984
a4: 0.37183530466557774
65200
15282
Val cmap: 0.911167
Valid loss: 1.345256
0.8456362425049967
a1: 0.03407844500804619
a2: 0.6811507085760372
a3: 0.0018505105063153283
a4: 0.2829203359096012
65200
15282
Val cmap: 0.911117
Valid loss: 1.344041
0.8452214452214452
a1: 0.2734784480057083
a2: 0.49806183742520727
a3: 0.0043926560990808754
a4: 0.22406705847000355
65200
15282
Val cmap: 0.911130
Valid loss: 1.345408
0.8461743535057318
a1: 0.18888925419748848
a2: 0.4923924556372191
a3: 0.001273108295238124
a4: 0.31744518187005427
65200
15282
Val cmap: 0.911118
Valid loss: 1.345402
0.8459641405052323
a1: 0.23656919289143336
a2: 0.5597605322851301
a3: 0.003429464905426027
a4: 0.20024080991801055
65200
15282
Val cmap: 0.911141
Valid loss: 1.344883
0.8459872738781357
a1: 0.14553534439699806
a2: 0.6066465063338595
a3: 0.0016157722839320492
a4: 0.2462023769852104
65200
15282
Val cmap: 0.911112
Valid loss: 1.344496
0.8457310370098936
a1: 0.10006043445778844
a2: 0.5990948122927455
a3: 0.005544657940494902
a4: 0.2953000953089711
65200
15282
Val cmap: 0.911126
Valid loss: 1.344602
0.8455593310680258
a1: 0.03188217803705451
a2: 0.7302967632993732
a3: 0.0028560794953822553
a4: 0.23496497916819004
65200
15282
Val cmap: 0.911095
Valid loss: 1.343725
0.8453367961908568
a1: 0.10153846540335652
a2: 0.5221604550215977
a3: 0.0022338945163256577
a4: 0.3740671850587201
65200
15282
Val cmap: 0.911170
Valid loss: 1.345203
0.8455235811350919
a1: 0.1637227053504531
a2: 0.5422197344359843
a3: 0.0021012358304951643
a4: 0.2919563243830675
65200
15282
Val cmap: 0.911146
Valid loss: 1.344996
0.8457873871472832
a1: 0.21767826325012388
a2: 0.5593106739358507
a3: 0.002412110203331362
a4: 0.22059895261069412
65200
15282
Val cmap: 0.911153
Valid loss: 1.344868
0.8460436448442447
a1: 0.10407111910960591
a2: 0.513762392691107
a3: 0.0015971411795561484
a4: 0.38056934701973094
65200
15282
Val cmap: 0.911165
Valid loss: 1.345268
0.8455132902538138
a1: 0.0866446737041182
a2: 0.4209222661153172
a3: 0.0010604754757836334
a4: 0.49137258470478096
65200
15282
Val cmap: 0.911112
Valid loss: 1.346149
0.8455745134630765
a1: 0.0676346557262741
a2: 0.4628233039845778
a3: 0.0015675584364434197
a4: 0.4679744818527046
65200
15282
Val cmap: 0.911127
Valid loss: 1.345778
0.8456232714671287
a1: 0.1067600393893519
a2: 0.5038999248261673
a3: 0.0011717888112875525
a4: 0.3881682469731933
65200
15282
Val cmap: 0.911164
Valid loss: 1.345349
0.8456080743479565
a1: 0.03814495017036933
a2: 0.6257868618071716
a3: 0.001513741209259628
a4: 0.33455444681319946
65200
15282
Val cmap: 0.911118
Valid loss: 1.344435
0.8453415942173812
a1: 0.1472816928838479
a2: 0.4797979049887612
a3: 0.0028042045026270656
a4: 0.3701161976247639
65200
15282
Val cmap: 0.911110
Valid loss: 1.345540
0.8458052908642633
a1: 0.0027118633505484185
a2: 0.40608850001122987
a3: 0.001888536877095402
a4: 0.5893110997611263
65200
15282
Val cmap: 0.910983
Valid loss: 1.346484
0.8455950952952153
a1: 0.1802125136394157
a2: 0.529940706806034
a3: 0.0037490512492677256
a4: 0.2860977283052826
65200
15282
Val cmap: 0.911161
Valid loss: 1.345107
0.8459077579312184
a1: 0.2139194439446553
a2: 0.574555594249916
a3: 0.0033121502849496405
a4: 0.20821281152047905
65200
15282
Val cmap: 0.911156
Valid loss: 1.344757
0.8459770114942529
a1: 0.10664242656153283
a2: 0.5178249895191148
a3: 0.0012968090911122442
a4: 0.37423577482824005
65200
15282
Val cmap: 0.911164
Valid loss: 1.345229
0.8455799080674172
a1: 0.28933009636501505
a2: 0.5339689813875792
a3: 0.002517671913627304
a4: 0.17418325033377843
65200
15282
Val cmap: 0.911152
Valid loss: 1.345120
0.8461948553911769
a1: 0.24897505681799964
a2: 0.4454059669182606
a3: 0.004970587799355633
a4: 0.3006483884643842
65200
15282
Val cmap: 0.911123
Valid loss: 1.345851
0.8461641005132307
a1: 0.14001713083678696
a2: 0.6039710042869678
a3: 0.002104387082070527
a4: 0.25390747779417466
65200
15282
Val cmap: 0.911121
Valid loss: 1.344521
0.8457592111399826
a1: 0.1947488559589718
a2: 0.49461319958595223
a3: 0.004183037417751859
a4: 0.3064549070373241
65200
15282
Val cmap: 0.911124
Valid loss: 1.345406
0.8460128628078243
a1: 0.32330378979902796
a2: 0.5604072988508368
a3: 0.0017639969310825191
a4: 0.11452491441905267
65200
15282
Val cmap: 0.911126
Valid loss: 1.344959
0.846364060521229
a1: 0.15369326125047175
a2: 0.5872724959519958
a3: 0.003035746680925948
a4: 0.25599849611660647
65200
15282
Val cmap: 0.911132
Valid loss: 1.344650
0.8457694870086608
a1: 0.27249177872004804
a2: 0.5468802465825041
a3: 0.0019488912086481878
a4: 0.17867908348879966
65200
15282
Val cmap: 0.911151
Valid loss: 1.344998
0.8460333855329358
a1: 0.1100201516660839
a2: 0.5181871985459721
a3: 0.0014233446843170295
a4: 0.370369305103627
65200
15282
Val cmap: 0.911163
Valid loss: 1.345223
0.8456080743479565
a1: 0.08126791755179835
a2: 0.47533811905641987
a3: 0.001226410039276078
a4: 0.44216755335250574
65200
15282
Val cmap: 0.911148
Valid loss: 1.345638
0.8456617353058776
a1: 0.12568682498508676
a2: 0.509577097653797
a3: 0.0009771883167935158
a4: 0.36375888904432274
65200
15282
Val cmap: 0.911160
Valid loss: 1.345281
0.8457310370098936
a1: 0.04950227959172424
a2: 0.390618386337736
a3: 0.00090236439995146
a4: 0.5589769696705882
65200
15282
Val cmap: 0.911024
Valid loss: 1.346526
0.8454975671532361
a1: 0.17121978659595896
a2: 0.5215253860486215
a3: 0.0013491532548705447
a4: 0.305905674100549
65200
15282
Val cmap: 0.911140
Valid loss: 1.345159
0.845938562004398
a1: 0.09372535565895766
a2: 0.43674832712387923
a3: 0.0025285621635419333
a4: 0.4669977550536212
65200
15282
Val cmap: 0.911129
Valid loss: 1.345993
0.8455848050649785
a1: 0.22554167126189759
a2: 0.5637593519580604
a3: 0.001659071523133276
a4: 0.20903990525690874
65200
15282
Val cmap: 0.911148
Valid loss: 1.344832
0.846015458422175
a1: 0.20413617840745563
a2: 0.5374058036787542
a3: 0.0021803890423612183
a4: 0.25627762887142896
65200
15282
Val cmap: 0.911169
Valid loss: 1.345034
0.8460795094804892
a1: 0.1966258921203499
a2: 0.5439460458397386
a3: 0.0023660673521240494
a4: 0.2570619946877875
65200
15282
Val cmap: 0.911170
Valid loss: 1.344982
0.8459667477426448
a1: 0.19033929417614787
a2: 0.4838544006520894
a3: 0.0022922355705261824
a4: 0.3235140696012365
65200
15282
Val cmap: 0.911112
Valid loss: 1.345484
0.845869297163995
a1: 0.2401988482413831
a2: 0.5528191663500637
a3: 0.0031864654102844087
a4: 0.20379551999826886
65200
15282
Val cmap: 0.911136
Valid loss: 1.344937
0.846015458422175
a1: 0.1649229034646897
a2: 0.5807880158570518
a3: 0.0026092624656422047
a4: 0.2516798182126163
65200
15282
Val cmap: 0.911156
Valid loss: 1.344695
0.8457797615082273
a1: 0.20499431484939903
a2: 0.535932842038171
a3: 0.002070315661743754
a4: 0.2570025274506862
65200
15282
Val cmap: 0.911169
Valid loss: 1.345046
0.846051316227924
a1: 0.19991628095185263
a2: 0.5417467308753602
a3: 0.0019922734308966024
a4: 0.2563447147418906
65200
15282
Val cmap: 0.911171
Valid loss: 1.344998
0.8459667477426448
a1: 0.2071763939781211
a2: 0.5716043818381941
a3: 0.0019595949835917513
a4: 0.21925962920009315
65200
15282
Val cmap: 0.911149
Valid loss: 1.344766
0.846015458422175
a1: 0.2634083033007321
a2: 0.5310233064909522
a3: 0.002206309128890022
a4: 0.2033620810794256
65200
15282
Val cmap: 0.911127
Valid loss: 1.345115
0.8461000233232266
a1: 0.22656362694206952
a2: 0.5440962825463806
a3: 0.0028791507736264242
a4: 0.22646093973792336
65200
15282
Val cmap: 0.911141
Valid loss: 1.344994
0.8460718331445325
a1: 0.19980469169169104
a2: 0.4573174214016729
a3: 0.0037435055590049047
a4: 0.3391343813476312
65200
15282
Val cmap: 0.911112
Valid loss: 1.345729
0.8460974471772311
a1: 0.13309198414059345
a2: 0.6181933657976885
a3: 0.0017902991456629803
a4: 0.24692435091605514
65200
15282
Val cmap: 0.911110
Valid loss: 1.344415
0.8456541293267148
a1: 0.29154683714272567
a2: 0.500510636219357
a3: 0.0023906716104969226
a4: 0.20555185502742043
65200
15282
Val cmap: 0.911114
Valid loss: 1.345387
0.846156409316584
a1: 0.16212275296486203
a2: 0.5052544960125692
a3: 0.0016324753031447352
a4: 0.330990275719424
65200
15282
Val cmap: 0.911121
Valid loss: 1.345302
0.8458334721620631
a1: 0.18381645320187395
a2: 0.5924710065564931
a3: 0.002190140027438924
a4: 0.22152240021419398
65200
15282
Val cmap: 0.911166
Valid loss: 1.344604
0.8458463793218307
a1: 0.1822705648501427
a2: 0.5907392314582934
a3: 0.00205730401372727
a4: 0.22493289967783658
65200
15282
Val cmap: 0.911173
Valid loss: 1.344616
0.845713143694624
a1: 0.23060819199629645
a2: 0.5680808771366237
a3: 0.002665700892541534
a4: 0.19864522997453832
65200
15282
Val cmap: 0.911165
Valid loss: 1.344810
0.8459488272921107
a1: 0.2578709134800156
a2: 0.5397421790547142
a3: 0.002020615924115205
a4: 0.2003662915411549
65200
15282
Val cmap: 0.911135
Valid loss: 1.345041
0.8460718331445325
a1: 0.19780510504504967
a2: 0.6143271754928249
a3: 0.0031146438372078597
a4: 0.18475307562491758
65200
15282
Val cmap: 0.911143
Valid loss: 1.344456
0.8458924645212872
a1: 0.13547339591371224
a2: 0.6438941147666528
a3: 0.0017952786300529735
a4: 0.218837210689582
65200
15282
Val cmap: 0.911117
Valid loss: 1.344231
0.8455620316402997
a1: 0.16616299009425242
a2: 0.5930044603657894
a3: 0.0014850009228963878
a4: 0.23934754861706187
65200
15282
Val cmap: 0.911162
Valid loss: 1.344594
0.845797661481062
a1: 0.21345734883255352
a2: 0.5541034881582309
a3: 0.003358144930532481
a4: 0.22908101807868314
65200
15282
Val cmap: 0.911165
Valid loss: 1.344914
0.8460718331445325
a1: 0.25109255762436683
a2: 0.5766617845716179
a3: 0.00251303093326898
a4: 0.16973262687074636
65200
15282
Val cmap: 0.911162
Valid loss: 1.344759
0.8461102781942361
a1: 0.18747574316043275
a2: 0.5956614273713038
a3: 0.002100696251520748
a4: 0.21476213321674265
65200
15282
Val cmap: 0.911162
Valid loss: 1.344581
0.8459027315123252
a1: 0.18099205277634928
a2: 0.6069390953821328
a3: 0.00232021350058202
a4: 0.2097486383409359
65200
15282
Val cmap: 0.911163
Valid loss: 1.344498
0.8458182060420345
a1: 0.14706731128999645
a2: 0.636181618318096
a3: 0.0028539486557453767
a4: 0.21389712173616207
65200
15282
Val cmap: 0.911108
Valid loss: 1.344291
0.8456080743479565
a1: 0.11539891490736173
a2: 0.6626959129419828
a3: 0.002081754391231725
a4: 0.21982341775942368
65200
15282
Val cmap: 0.911104
Valid loss: 1.344107
0.8454672617065212
a1: 0.22011030079093757
a2: 0.5282279441101645
a3: 0.0017760439182488157
a4: 0.24988571118064917
65200
15282
Val cmap: 0.911153
Valid loss: 1.345110
0.8461282153805145
a1: 0.37368448966373974
a2: 0.5524623058149439
a3: 0.0022570988884679983
a4: 0.07159610563284839
65200
15282
Val cmap: 0.911097
Valid loss: 1.345114
0.8462025527376945
a1: 0.15678669131804834
a2: 0.4885336573481804
a3: 0.0037651441959150236
a4: 0.35091450713785627
65200
15282
Val cmap: 0.911097
Valid loss: 1.345465
0.8457565559294925
a1: 0.08013352400908152
a2: 0.46353402749269773
a3: 0.0011290326846000686
a4: 0.4552034158136207
65200
15282
Val cmap: 0.911125
Valid loss: 1.345748
0.8456617353058776
a1: 0.17809707657281698
a2: 0.5789513778202436
a3: 0.0014507381222691941
a4: 0.24150080748467023
65200
15282
Val cmap: 0.911154
Valid loss: 1.344700
0.8458182060420345
a1: 0.12588805279293042
a2: 0.6218169613419948
a3: 0.0027763344066412086
a4: 0.2495186514584335
65200
15282
Val cmap: 0.911118
Valid loss: 1.344398
0.8455696202531646
a1: 0.05958878694919466
a2: 0.506558986508221
a3: 0.001624295821676347
a4: 0.43222793072090804
65200
15282
Val cmap: 0.911135
Valid loss: 1.345389
0.845531163596389
a1: 0.19505978713820193
a2: 0.5251014720351997
a3: 0.0019356471076758758
a4: 0.27790309371892247
65200
15282
Val cmap: 0.911162
Valid loss: 1.345132
0.846041055718475
a1: 0.2426303802049497
a2: 0.540875822891523
a3: 0.0023877101595832133
a4: 0.2141060867439441
65200
15282
Val cmap: 0.911134
Valid loss: 1.345025
0.846015458422175
a1: 0.11065104863165716
a2: 0.4850993237147413
a3: 0.0013021243865117694
a4: 0.4029475032670897
65200
15282
Val cmap: 0.911158
Valid loss: 1.345513
0.8456541293267148
a1: 0.14214084667043775
a2: 0.5949066935058029
a3: 0.0017195379700252677
a4: 0.2612329218537341
65200
15282
Val cmap: 0.911121
Valid loss: 1.344585
0.8456644125387254
a1: 0.09149435173570539
a2: 0.5147419695143802
a3: 0.0031427389841527983
a4: 0.39062093976576157
65200
15282
Val cmap: 0.911154
Valid loss: 1.345285
0.8455132902538138
a1: 0.20940445436692415
a2: 0.5608161757466997
a3: 0.001995770194760011
a4: 0.22778359969161613
65200
15282
Val cmap: 0.911162
Valid loss: 1.344850
0.8460718331445325
a1: 0.28764024655755965
a2: 0.5322656323554048
a3: 0.002513937164081044
a4: 0.17758018392295455
65200
15282
Val cmap: 0.911139
Valid loss: 1.345131
0.8461948553911769
a1: 0.32933719835835107
a2: 0.5685430400974034
a3: 0.0021139290353195664
a4: 0.10000583250892595
65200
15282
Val cmap: 0.911115
Valid loss: 1.344913
0.8463256123979338
a1: 0.16202837783375038
a2: 0.587547860555128
a3: 0.0014736823371219701
a4: 0.2489500792739997
65200
15282
Date :05/14/2023, 16:22:49
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.8589150909821097
a2: 0.0887346660808082
a3: 0.006072282390609099
a4: 0.046277960546472985
65200
15282
Val cmap: 0.911109
Valid loss: 1.351275
0.8469708102331173
a1: 0.2630903641693799
a2: 0.13612066492977823
a3: 0.0741636674410898
a4: 0.526625303459752
65200
15282
Val cmap: 0.911086
Valid loss: 1.349792
0.8461050875729775
a1: 0.987285105068721
a2: 0.0019895663923901246
a3: 0.0035106791015881355
a4: 0.007214649437300714
65200
15282
Val cmap: 0.911030
Valid loss: 1.353024
0.8470737573490112
a1: 0.9270405747091894
a2: 0.004424537525010259
a3: 0.06659803973509244
a4: 0.0019368480307078578
65200
15282
Val cmap: 0.911070
Valid loss: 1.353482
0.8470022057349107
a1: 0.7673977432706894
a2: 0.159425358872902
a3: 0.015148492661758479
a4: 0.05802840519465009
65200
15282
Val cmap: 0.911160
Valid loss: 1.350138
0.8469346867904368
a1: 0.43189296396362054
a2: 0.08950493383969035
a3: 0.001477684762710721
a4: 0.4771244174339784
65200
15282
Val cmap: 0.911114
Valid loss: 1.349763
0.846189777125317
a1: 0.6165986073083497
a2: 0.3270069138260658
a3: 0.0035683949335098162
a4: 0.052826083932074705
65200
15282
Val cmap: 0.911200
Valid loss: 1.347693
0.8467338359911923
a1: 0.0035202104272471497
a2: 0.371655484259046
a3: 0.004344114458419881
a4: 0.6204801908552869
65200
15282
Val cmap: 0.910958
Valid loss: 1.346864
0.8453951752632282
a1: 0.14813290534244877
a2: 0.5912029629106038
a3: 0.0014562559289121354
a4: 0.25920787581803534
65200
15282
Val cmap: 0.911123
Valid loss: 1.344610
0.8456362425049967
a1: 0.06832296142417968
a2: 0.01125317835580128
a3: 0.10888497183744841
a4: 0.8115388883825706
65200
15282
Val cmap: 0.910980
Valid loss: 1.352110
0.8457405986185724
a1: 0.6443295194321799
a2: 0.25315161951065784
a3: 0.014064975389211731
a4: 0.08845388566795057
65200
15282
Val cmap: 0.911169
Valid loss: 1.348617
0.8467572348876798
a1: 0.6487364099822176
a2: 0.2561189312843328
a3: 0.012866324025985448
a4: 0.08227833470746418
65200
15282
Val cmap: 0.911164
Valid loss: 1.348592
0.8467572348876798
a1: 0.534034651073446
a2: 0.3394664306498813
a3: 0.02585333529633974
a4: 0.10064558298033291
65200
15282
Val cmap: 0.911134
Valid loss: 1.347526
0.8467158154585182
a1: 0.6882938968076427
a2: 0.26061539991833743
a3: 0.0028902749888405728
a4: 0.04820042828517925
65200
15282
Val cmap: 0.911161
Valid loss: 1.348602
0.8465954606141521
a1: 0.5458308493461967
a2: 0.31183298784857316
a3: 0.02813257002759054
a4: 0.11420359277763956
65200
15282
Val cmap: 0.911144
Valid loss: 1.347847
0.8466568797544375
a1: 0.3869075549630716
a2: 0.4309863666917998
a3: 0.007538037385703812
a4: 0.1745680409594248
65200
15282
Val cmap: 0.911149
Valid loss: 1.346151
0.8463230882058803
a1: 0.6425999094416679
a2: 0.21058356866473343
a3: 0.008976222576198652
a4: 0.13784029931740002
65200
15282
Val cmap: 0.911186
Valid loss: 1.348976
0.8468624833110815
a1: 0.7874958167208053
a2: 0.049076497943609104
a3: 0.002896049911465776
a4: 0.16053163542411986
65200
15282
Val cmap: 0.911113
Valid loss: 1.351304
0.8471429048525531
a1: 0.5609737042606693
a2: 0.1994819819270426
a3: 0.0009777583275126789
a4: 0.23856655548477543
65200
15282
Val cmap: 0.911200
Valid loss: 1.348728
0.8466544301685298
a1: 0.39313555931385863
a2: 0.19338957440667828
a3: 0.0010201186999947104
a4: 0.4124547475794685
65200
15282
Val cmap: 0.911089
Valid loss: 1.348475
0.8463565115891278
a1: 0.5002530889099237
a2: 0.21219199589683418
a3: 0.002003692570998619
a4: 0.2855512226222435
65200
15282
Val cmap: 0.911170
Valid loss: 1.348447
0.8464309539693129
a1: 0.6265410860990935
a2: 0.1550847212961078
a3: 0.0009379397954528295
a4: 0.2174362528093458
65200
15282
Val cmap: 0.911175
Valid loss: 1.349415
0.8467187395687296
a1: 0.5726715585993136
a2: 0.19561299659085982
a3: 0.0020678194409685553
a4: 0.229647625368858
65200
15282
Val cmap: 0.911176
Valid loss: 1.348815
0.8466339574780547
a1: 0.6845056688621716
a2: 0.12269928913102404
a3: 0.005485722977740908
a4: 0.18730931902906348
65200
15282
Val cmap: 0.911169
Valid loss: 1.350040
0.8468805287578862
a1: 0.766143856650159
a2: 0.09529498089448123
a3: 0.008204404076207096
a4: 0.13035675837915262
65200
15282
Val cmap: 0.911110
Valid loss: 1.350738
0.8469936233432376
a1: 0.46140154504416186
a2: 0.21950913453078333
a3: 0.0041159313592781825
a4: 0.3149733890657766
65200
15282
Val cmap: 0.911139
Valid loss: 1.348309
0.8464334544969487
a1: 0.5822951558052296
a2: 0.232379496933393
a3: 0.002586929406343658
a4: 0.18273841785503372
65200
15282
Val cmap: 0.911172
Valid loss: 1.348467
0.8465106965257151
a1: 0.7200650936964337
a2: 0.16672697592480346
a3: 0.004607267740962647
a4: 0.10860066263780022
65200
15282
Val cmap: 0.911173
Valid loss: 1.349706
0.8470219017094017
a1: 0.48142943126961507
a2: 0.286156631838916
a3: 0.0009049724216745226
a4: 0.23150896446979446
65200
15282
Val cmap: 0.911124
Valid loss: 1.347625
0.846556611639153
a1: 0.8180819410378335
a2: 0.076313697196929
a3: 0.0068658031597387354
a4: 0.09873855860549877
65200
15282
Val cmap: 0.911113
Valid loss: 1.351197
0.8471044018435642
a1: 0.8522667196163187
a2: 0.051120824841596524
a3: 0.0067386416627664815
a4: 0.08987381387931827
65200
15282
Val cmap: 0.911081
Valid loss: 1.351666
0.8469503640857773
a1: 0.5945934846839077
a2: 0.19004689104912217
a3: 0.0019094032766540702
a4: 0.21345022099031605
65200
15282
Val cmap: 0.911177
Valid loss: 1.348941
0.8465569611802797
a1: 0.6036486632495446
a2: 0.1837927517960043
a3: 0.0015196995958137857
a4: 0.21103888535863735
65200
15282
Val cmap: 0.911171
Valid loss: 1.349033
0.846490203277813
a1: 0.5433798227373944
a2: 0.14570431172999465
a3: 0.0018742808829534832
a4: 0.3090415846496575
65200
15282
Val cmap: 0.911162
Valid loss: 1.349285
0.8464644442219774
a1: 0.7062862670310126
a2: 0.17750581845211352
a3: 0.001398190001259742
a4: 0.11480972451561414
65200
15282
Val cmap: 0.911195
Valid loss: 1.349493
0.8470140534766498
a1: 0.7184887090404533
a2: 0.1317026275021605
a3: 0.0030964031270309263
a4: 0.1467122603303553
65200
15282
Val cmap: 0.911173
Valid loss: 1.350055
0.8470886752136751
a1: 0.8875615581043532
a2: 0.04145154063482301
a3: 0.001216944105517563
a4: 0.0697699571553062
65200
15282
Val cmap: 0.911081
Valid loss: 1.351905
0.8469503640857773
a1: 0.6645657132477691
a2: 0.17821659485747565
a3: 0.0035735891790884505
a4: 0.15364410271566675
65200
15282
Val cmap: 0.911193
Valid loss: 1.349337
0.846872705426874
a1: 0.7364702556357354
a2: 0.16675575412515464
a3: 0.0012894870470279065
a4: 0.09548450319208203
65200
15282
Val cmap: 0.911160
Valid loss: 1.349741
0.8469551282051281
a1: 0.8031805362909393
a2: 0.12052216933905656
a3: 0.0035129989566438044
a4: 0.0727842954133603
65200
15282
Val cmap: 0.911136
Valid loss: 1.350589
0.8471067481385021
a1: 0.9837473282322683
a2: 0.005639155328311286
a3: 0.0011130453347576298
a4: 0.009500471104662792
65200
15282
Val cmap: 0.911035
Valid loss: 1.352924
0.847083973545327
a1: 0.6515588317972153
a2: 0.17848726787996955
a3: 0.002508468752632675
a4: 0.1674454315701825
65200
15282
Val cmap: 0.911190
Valid loss: 1.349271
0.8468342178164946
a1: 0.6601668559240476
a2: 0.14785580621159394
a3: 0.0023397978882316465
a4: 0.18963753997612684
65200
15282
Val cmap: 0.911183
Valid loss: 1.349632
0.8468522598304292
a1: 0.7101460221264426
a2: 0.1686828896417637
a3: 0.0015838437190091753
a4: 0.1195872445127845
65200
15282
Val cmap: 0.911182
Valid loss: 1.349605
0.8470706059088633
a1: 0.6186285260093798
a2: 0.18228732150755436
a3: 0.003577983443249771
a4: 0.19550616903981607
65200
15282
Val cmap: 0.911185
Valid loss: 1.349123
0.8467289719626168
a1: 0.7624666496728508
a2: 0.14323460131920165
a3: 0.0013181457525585406
a4: 0.09298060325538898
65200
15282
Val cmap: 0.911150
Valid loss: 1.350113
0.8469755641607691
a1: 0.6819714949701315
a2: 0.18181669734794656
a3: 0.002358932050629555
a4: 0.13385287563129233
65200
15282
Val cmap: 0.911192
Valid loss: 1.349356
0.8470525402229789
a1: 0.6812478174379841
a2: 0.16006271739485878
a3: 0.001486200031431944
a4: 0.15720326513572516
65200
15282
Val cmap: 0.911185
Valid loss: 1.349573
0.8469190199612792
a1: 0.7532566014605409
a2: 0.17696812297771553
a3: 0.001090187021117371
a4: 0.06868508854062626
65200
15282
Val cmap: 0.911137
Valid loss: 1.349713
0.8468113522537564
a1: 0.530793793645994
a2: 0.23865872149820166
a3: 0.005287431180360229
a4: 0.2252600536754441
65200
15282
Val cmap: 0.911164
Valid loss: 1.348276
0.8466081617671593
a1: 0.6966478824114329
a2: 0.13499344433301264
a3: 0.001627694993929973
a4: 0.16673097826162445
65200
15282
Val cmap: 0.911184
Valid loss: 1.349909
0.8469755641607691
a1: 0.6425761087286994
a2: 0.20143171129653215
a3: 0.002554803685069182
a4: 0.15343737628969925
65200
15282
Val cmap: 0.911201
Valid loss: 1.348997
0.8468907506926132
a1: 0.6011975640765007
a2: 0.2098281768460037
a3: 0.0022734123198400844
a4: 0.18670084675765553
65200
15282
Val cmap: 0.911166
Valid loss: 1.348758
0.8466724517722448
a1: 0.6645983539549898
a2: 0.19820335528007288
a3: 0.0031382847962218596
a4: 0.13406000596871548
65200
15282
Val cmap: 0.911193
Valid loss: 1.349124
0.8467392029904545
a1: 0.6323392097389515
a2: 0.20243396546632528
a3: 0.0029962207066335862
a4: 0.16223060408808962
65200
15282
Val cmap: 0.911216
Valid loss: 1.348954
0.8469292389853137
a1: 0.5711237246007121
a2: 0.2266767095181863
a3: 0.004343236416385031
a4: 0.1978563294647165
65200
15282
Val cmap: 0.911168
Valid loss: 1.348508
0.8465774455161365
a1: 0.6274130428344227
a2: 0.20126070124904707
a3: 0.0027741481855654286
a4: 0.16855210773096482
65200
15282
Val cmap: 0.911205
Valid loss: 1.348945
0.8468059542086643
a1: 0.6173587944589943
a2: 0.23666268207882193
a3: 0.0017454838779338935
a4: 0.14423303958424985
65200
15282
Val cmap: 0.911205
Valid loss: 1.348536
0.8466929186411266
a1: 0.5053013177926396
a2: 0.25871001043172076
a3: 0.0019171568942499908
a4: 0.2340715148813896
65200
15282
Val cmap: 0.911177
Valid loss: 1.347969
0.8464207085195812
a1: 0.6252923828787987
a2: 0.24093210563368067
a3: 0.00273947332080815
a4: 0.13103603816671244
65200
15282
Val cmap: 0.911216
Valid loss: 1.348534
0.8466929186411266
a1: 0.6216861361893108
a2: 0.2413232300393196
a3: 0.00281768855548038
a4: 0.13417294521588924
65200
15282
Val cmap: 0.911218
Valid loss: 1.348517
0.8466646644642439
a1: 0.6321552907315159
a2: 0.24360963058761612
a3: 0.0026365506961549758
a4: 0.12159852798471302
65200
15282
Val cmap: 0.911211
Valid loss: 1.348532
0.8467879192391122
a1: 0.6255329402781695
a2: 0.2393910568944089
a3: 0.0027778790301443636
a4: 0.1322981237972772
65200
15282
Val cmap: 0.911217
Valid loss: 1.348550
0.8466929186411266
a1: 0.597322088340939
a2: 0.236703363907041
a3: 0.002822377929616815
a4: 0.16315216982240316
65200
15282
Val cmap: 0.911195
Valid loss: 1.348476
0.8466724517722448
a1: 0.6354683589980088
a2: 0.24300482437522067
a3: 0.003075780256779266
a4: 0.11845103636999127
65200
15282
Val cmap: 0.911209
Valid loss: 1.348556
0.8468161794152985
a1: 0.5481364770734195
a2: 0.2674877930568405
a3: 0.004995457028430137
a4: 0.17938027284130986
65200
15282
Val cmap: 0.911196
Valid loss: 1.348031
0.8465901508074204
a1: 0.6172456009133295
a2: 0.24312016725601063
a3: 0.004131401958663579
a4: 0.13550282987199633
65200
15282
Val cmap: 0.911215
Valid loss: 1.348497
0.8466929186411266
a1: 0.5145062787506897
a2: 0.275856638222745
a3: 0.005981303928148533
a4: 0.20365577909841684
65200
15282
Val cmap: 0.911154
Valid loss: 1.347862
0.8467055879899916
a1: 0.5728185609562613
a2: 0.248710243967199
a3: 0.004086678627844492
a4: 0.17438451644869524
65200
15282
Val cmap: 0.911201
Valid loss: 1.348287
0.8465491923641704
a1: 0.566782962656996
a2: 0.22257845765923515
a3: 0.002120245941591984
a4: 0.20851833374217685
65200
15282
Val cmap: 0.911171
Valid loss: 1.348513
0.8466159391269524
a1: 0.7334278317442228
a2: 0.22732569328484234
a3: 0.0031025124845487405
a4: 0.03614396248638615
65200
15282
Val cmap: 0.911122
Valid loss: 1.349136
0.8468498547627792
a1: 0.6160210350982246
a2: 0.24440288630070456
a3: 0.0038167000358608474
a4: 0.13575937856521
65200
15282
Val cmap: 0.911215
Valid loss: 1.348477
0.8466929186411266
a1: 0.6367083944618929
a2: 0.24724920995685648
a3: 0.0039471986464978594
a4: 0.1120951969347528
65200
15282
Val cmap: 0.911190
Valid loss: 1.348528
0.8468161794152985
a1: 0.6113409118913258
a2: 0.21524237426161782
a3: 0.004553298881731589
a4: 0.1688634149653248
65200
15282
Val cmap: 0.911184
Valid loss: 1.348763
0.8467776924874011
a1: 0.5851803507446465
a2: 0.26557722922673604
a3: 0.0030835189437847313
a4: 0.14615890108483276
65200
15282
Val cmap: 0.911212
Valid loss: 1.348150
0.8465774455161365
a1: 0.5308006166348611
a2: 0.2868962683785238
a3: 0.0037099884029252847
a4: 0.17859312658368984
65200
15282
Val cmap: 0.911177
Valid loss: 1.347775
0.8466953591565742
a1: 0.5739609258011207
a2: 0.264920682363605
a3: 0.004820646107905951
a4: 0.15629774572736838
65200
15282
Val cmap: 0.911205
Valid loss: 1.348137
0.8465954606141521
a1: 0.590056710253744
a2: 0.2506196373238004
a3: 0.002176206022757235
a4: 0.15714744639969844
65200
15282
Val cmap: 0.911201
Valid loss: 1.348304
0.8465672040319081
a1: 0.4770449234786742
a2: 0.2927737809750495
a3: 0.005771788128429919
a4: 0.22440950741784632
65200
15282
Val cmap: 0.911107
Valid loss: 1.347598
0.846556611639153
a1: 0.6752817845957962
a2: 0.2309723672593284
a3: 0.003353052369598532
a4: 0.09039279577527683
65200
15282
Val cmap: 0.911168
Valid loss: 1.348839
0.8467187395687296
a1: 0.5564879420491383
a2: 0.2562946367502794
a3: 0.0028338686491248895
a4: 0.18438355255145739
65200
15282
Val cmap: 0.911195
Valid loss: 1.348145
0.8465209410979476
a1: 0.635396965014655
a2: 0.24297233415036382
a3: 0.0032450886180497222
a4: 0.11838561221693143
65200
15282
Val cmap: 0.911210
Valid loss: 1.348558
0.8468161794152985
a1: 0.6416422252414627
a2: 0.24143555242530607
a3: 0.0026108539715549816
a4: 0.1143113683616762
65200
15282
Val cmap: 0.911183
Valid loss: 1.348590
0.8468444414778227
a1: 0.6093169963806669
a2: 0.22202557487418664
a3: 0.003922297468022696
a4: 0.16473513127712372
65200
15282
Val cmap: 0.911198
Valid loss: 1.348679
0.8466929186411266
a1: 0.6933708256406494
a2: 0.24358148184695452
a3: 0.0034151198123182694
a4: 0.05963257270007776
65200
15282
Val cmap: 0.911158
Valid loss: 1.348795
0.846680241679741
a1: 0.6677377804862686
a2: 0.2540464562738127
a3: 0.00249773071698617
a4: 0.07571803252293247
65200
15282
Val cmap: 0.911162
Valid loss: 1.348572
0.8467289719626168
a1: 0.5878268107737622
a2: 0.2130219119666156
a3: 0.002033987885944664
a4: 0.19711728937367753
65200
15282
Val cmap: 0.911177
Valid loss: 1.348678
0.8466057005540351
a1: 0.7048335980184232
a2: 0.23643900711342994
a3: 0.0033591103759658594
a4: 0.05536828449218104
65200
15282
Val cmap: 0.911153
Valid loss: 1.348916
0.8467085058085192
a1: 0.5273255940745881
a2: 0.26932937691338876
a3: 0.004310395696468247
a4: 0.19903463331555488
65200
15282
Val cmap: 0.911184
Valid loss: 1.347945
0.8466773418734989
a1: 0.6579529561591373
a2: 0.22527027739189007
a3: 0.0027928027083460407
a4: 0.1139839637406266
65200
15282
Val cmap: 0.911186
Valid loss: 1.348818
0.8467776924874011
a1: 0.5540230062278094
a2: 0.27601522061616357
a3: 0.0018432353016776429
a4: 0.16811853785434935
65200
15282
Val cmap: 0.911193
Valid loss: 1.347932
0.8465799132465798
a1: 0.6292302925238097
a2: 0.2451531741192925
a3: 0.003130055373093342
a4: 0.12248647798380448
65200
15282
Val cmap: 0.911208
Valid loss: 1.348511
0.8467596609490756
a1: 0.6379939373044472
a2: 0.25757882297976203
a3: 0.0023453531797415655
a4: 0.1020818865360492
65200
15282
Val cmap: 0.911189
Valid loss: 1.348414
0.8468444414778227
a1: 0.6209246404680363
a2: 0.23113397519444384
a3: 0.0030433002632336828
a4: 0.14489808407428617
65200
15282
Val cmap: 0.911209
Valid loss: 1.348619
0.8467776924874011
a1: 0.6088038535711016
a2: 0.23135544032521335
a3: 0.0038303881490588648
a4: 0.15601031795462622
65200
15282
Val cmap: 0.911204
Valid loss: 1.348582
0.8467109434969796
a1: 0.6823409805735814
a2: 0.2505594979391942
a3: 0.002671983467976214
a4: 0.0644275380192482
65200
15282
Val cmap: 0.911161
Valid loss: 1.348670
0.8467572348876798
a1: 0.5886124139286221
a2: 0.21009585617765608
a3: 0.0051791863792111535
a4: 0.19611254351451068
65200
15282
Val cmap: 0.911174
Valid loss: 1.348746
0.8466057005540351
a1: 0.6529435933391701
a2: 0.2196060636833617
a3: 0.0021940825884682095
a4: 0.12525626038900003
65200
15282
Val cmap: 0.911200
Valid loss: 1.348848
0.8468444414778227
a1: 0.6210900949566227
a2: 0.22975850794760097
a3: 0.0044622486878519805
a4: 0.14468914840792435
65200
15282
Val cmap: 0.911207
Valid loss: 1.348649
0.8467776924874011
a1: 0.7099775979508837
a2: 0.2385207839175187
a3: 0.002986789895286783
a4: 0.04851482823631086
65200
15282
Val cmap: 0.911144
Valid loss: 1.348915
0.8467650397275823
a1: 0.5598582777946187
a2: 0.20553657147814217
a3: 0.001669186399865033
a4: 0.23293596432737407
65200
15282
Val cmap: 0.911199
Valid loss: 1.348667
0.8465876856332387
a1: 0.6501210473066458
a2: 0.2449170434674027
a3: 0.003302577816667506
a4: 0.10165933140928402
65200
15282
Val cmap: 0.911194
Valid loss: 1.348597
0.8468161794152985
a1: 0.6211451691487196
a2: 0.21912347375717628
a3: 0.0037272486568220636
a4: 0.15600410843728202
65200
15282
Val cmap: 0.911193
Valid loss: 1.348749
0.8468444414778227
a1: 0.5891956405329231
a2: 0.2627083918689025
a3: 0.0025055315524018253
a4: 0.14559043604577263
65200
15282
Val cmap: 0.911207
Valid loss: 1.348185
0.8466159391269524
a1: 0.6719247217714708
a2: 0.23395173915855189
a3: 0.0030701645127600694
a4: 0.09105337455721726
65200
15282
Val cmap: 0.911168
Valid loss: 1.348792
0.8467572348876798
a1: 0.6308136157332959
a2: 0.24971583125907204
a3: 0.002883881524903445
a4: 0.11658667148272865
65200
15282
Val cmap: 0.911195
Valid loss: 1.348469
0.8468161794152985
a1: 0.6016006963444751
a2: 0.1912963997669511
a3: 0.002077995998441542
a4: 0.20502490789013225
65200
15282
Val cmap: 0.911182
Valid loss: 1.348952
0.84651845917618
a1: 0.7347515431915331
a2: 0.24061245936685144
a3: 0.0035709931486393068
a4: 0.021065004292976124
65200
15282
Val cmap: 0.911123
Valid loss: 1.349019
0.846698270681712
a1: 0.5727551232995093
a2: 0.27274650786344523
a3: 0.004756100853806203
a4: 0.14974226798323928
65200
15282
Val cmap: 0.911198
Valid loss: 1.348056
0.8465774455161365
a1: 0.6941859898182031
a2: 0.25514019687792877
a3: 0.0032313706430463973
a4: 0.04744244266082171
65200
15282
Val cmap: 0.911171
Valid loss: 1.348685
0.8466622162883845
a1: 0.6583733516191491
a2: 0.22905174126226935
a3: 0.0041428780069955595
a4: 0.10843202911158598
65200
15282
Val cmap: 0.911177
Valid loss: 1.348797
0.8468444414778227
a1: 0.6377055119701883
a2: 0.2434514840447917
a3: 0.0023479820969332914
a4: 0.11649502188808669
65200
15282
Val cmap: 0.911192
Valid loss: 1.348551
0.8468161794152985
a1: 0.6160815705576582
a2: 0.2613384538744566
a3: 0.00306853749907135
a4: 0.11951143806881384
65200
15282
Val cmap: 0.911195
Valid loss: 1.348302
0.8467314045449995
a1: 0.6304545862610164
a2: 0.21699468355395318
a3: 0.0027118189491732495
a4: 0.14983891123585721
65200
15282
Val cmap: 0.911213
Valid loss: 1.348794
0.846872705426874
a1: 0.5481408927570603
a2: 0.21157556035391453
a3: 0.001740278880479095
a4: 0.23854326800854603
65200
15282
Val cmap: 0.911185
Valid loss: 1.348571
0.8465696743192739
a1: 0.5881191581514329
a2: 0.2015106187297051
a3: 0.002643943781835101
a4: 0.2077262793370269
65200
15282
Val cmap: 0.911176
Valid loss: 1.348807
0.8465004505857615
a1: 0.6783840025533444
a2: 0.23591902765546446
a3: 0.0036764996084652267
a4: 0.0820204701827259
65200
15282
Val cmap: 0.911156
Valid loss: 1.348807
0.846690476985213
a1: 0.6042538883881562
a2: 0.22189378978376617
a3: 0.0019303745111237947
a4: 0.17192194731695384
65200
15282
Val cmap: 0.911187
Valid loss: 1.348641
0.8467109434969796
a1: 0.649027692997424
a2: 0.2505684219389089
a3: 0.002899882977324399
a4: 0.0975040020863427
65200
15282
Val cmap: 0.911181
Valid loss: 1.348533
0.8468444414778227
a1: 0.5196459461780872
a2: 0.27636055750721034
a3: 0.0024665797876403947
a4: 0.20152691652706203
65200
15282
Val cmap: 0.911190
Valid loss: 1.347834
0.8466773418734989
a1: 0.579734650548423
a2: 0.20763435837132418
a3: 0.0064853776763077325
a4: 0.2061456134039451
65200
15282
Val cmap: 0.911168
Valid loss: 1.348757
0.8465672040319081
a1: 0.6329817261531012
a2: 0.2434053386859423
a3: 0.0032589239522012032
a4: 0.12035401120875527
65200
15282
Val cmap: 0.911212
Valid loss: 1.348544
0.8467879192391122
a1: 0.6263924306100931
a2: 0.2635674328615916
a3: 0.0033028271481001415
a4: 0.10673730938021515
65200
15282
Val cmap: 0.911191
Valid loss: 1.348322
0.8468161794152985
a1: 0.6477618478606966
a2: 0.22703814370329597
a3: 0.0027282900888423336
a4: 0.12247171834716512
65200
15282
Val cmap: 0.911197
Valid loss: 1.348759
0.846872705426874
a1: 0.6699975198626257
a2: 0.24338743718680309
a3: 0.0022637432972745894
a4: 0.08435129965329664
65200
15282
Val cmap: 0.911181
Valid loss: 1.348682
0.8467854996995793
a1: 0.6061013513477941
a2: 0.23497174439839325
a3: 0.0037927568240351804
a4: 0.1551341474297775
65200
15282
Val cmap: 0.911204
Valid loss: 1.348535
0.8466724517722448
a1: 0.6906930651993933
a2: 0.25485686749830877
a3: 0.003432401210698489
a4: 0.05101766609159941
65200
15282
Val cmap: 0.911171
Valid loss: 1.348675
0.846690476985213
a1: 0.5429181218494069
a2: 0.21716205115746098
a3: 0.004950727957227306
a4: 0.2349690990359048
65200
15282
Val cmap: 0.911177
Valid loss: 1.348531
0.8466364121729845
a1: 0.718909466280057
a2: 0.2479170218891455
a3: 0.0029731606653759578
a4: 0.030200351165421517
65200
15282
Val cmap: 0.911135
Valid loss: 1.348866
0.8466032381906192
a1: 0.6309537775231985
a2: 0.2245417792087225
a3: 0.004152192149179263
a4: 0.14035225111889976
65200
15282
Val cmap: 0.911225
Valid loss: 1.348735
0.8468059542086643
a1: 0.5687470648572451
a2: 0.1890558921039217
a3: 0.004003427799273375
a4: 0.23819361523955979
65200
15282
Val cmap: 0.911172
Valid loss: 1.348895
0.8465954606141521
a1: 0.6200464950476288
a2: 0.22416833518227858
a3: 0.004318024729896708
a4: 0.15146714504019596
65200
15282
Val cmap: 0.911213
Valid loss: 1.348700
0.8467776924874011
a1: 0.6200558147629226
a2: 0.21574250138538276
a3: 0.005450444515396795
a4: 0.15875123933629784
65200
15282
Val cmap: 0.911196
Valid loss: 1.348799
0.8468624833110815
a1: 0.6623864304698658
a2: 0.22558234355861004
a3: 0.004389760323098024
a4: 0.10764146564842615
65200
15282
Val cmap: 0.911182
Valid loss: 1.348851
0.8467957276368492
a1: 0.6000590821851562
a2: 0.20298115870172267
a3: 0.004177730398008204
a4: 0.19278202871511288
65200
15282
Val cmap: 0.911172
Valid loss: 1.348847
0.846690476985213
a1: 0.6414354816997946
a2: 0.23375967405367237
a3: 0.0026778368430416047
a4: 0.12212700740349144
65200
15282
Val cmap: 0.911207
Valid loss: 1.348666
0.846872705426874
a1: 0.5827104893129296
a2: 0.21967342152877528
a3: 0.00472426940572115
a4: 0.192891819752574
65200
15282
Val cmap: 0.911165
Valid loss: 1.348622
0.8465672040319081
a1: 0.6173852483291496
a2: 0.2309421063506338
a3: 0.003573453652248143
a4: 0.1480991916679684
65200
15282
Val cmap: 0.911204
Valid loss: 1.348614
0.8467109434969796
a1: 0.6664374868197951
a2: 0.23776566931162793
a3: 0.0032610157387404355
a4: 0.09253582812983654
65200
15282
Val cmap: 0.911172
Valid loss: 1.348734
0.846767464370348
a1: 0.5572945618460209
a2: 0.1972683216763609
a3: 0.0057192884479320555
a4: 0.23971782802968616
65200
15282
Val cmap: 0.911176
Valid loss: 1.348792
0.8466261763331776
a1: 0.6917600296765716
a2: 0.2252648800422997
a3: 0.0024215753022609897
a4: 0.08055351497886774
65200
15282
Val cmap: 0.911147
Valid loss: 1.348956
0.846690476985213
a1: 0.6382589524230201
a2: 0.24377090765833923
a3: 0.0028567305601541605
a4: 0.1151134093584865
65200
15282
Val cmap: 0.911189
Valid loss: 1.348556
0.8468161794152985
a1: 0.6282239986859444
a2: 0.2532163616624607
a3: 0.0038908874858021554
a4: 0.11466875216579278
65200
15282
Val cmap: 0.911197
Valid loss: 1.348436
0.8468161794152985
a1: 0.5964264531246828
a2: 0.21256790553221325
a3: 0.0031264342579414347
a4: 0.18787920708516254
65200
15282
Val cmap: 0.911170
Valid loss: 1.348723
0.8465389493358254
a1: 0.6428143557321887
a2: 0.23871885425238362
a3: 0.003457013546323126
a4: 0.11500977646910455
65200
15282
Val cmap: 0.911187
Valid loss: 1.348631
0.8468444414778227
a1: 0.6113580490056738
a2: 0.26083223582575565
a3: 0.0021816174957610505
a4: 0.1256280976728095
65200
15282
Val cmap: 0.911205
Valid loss: 1.348279
0.8467314045449995
a1: 0.6613070685202955
a2: 0.24691996831171845
a3: 0.0027217565716278914
a4: 0.08905120659635814
65200
15282
Val cmap: 0.911182
Valid loss: 1.348617
0.8468907506926132
a1: 0.5748425712856979
a2: 0.2598281180313686
a3: 0.004325773749760177
a4: 0.16100353693317326
65200
15282
Val cmap: 0.911197
Valid loss: 1.348185
0.8465672040319081
a1: 0.6303561166216968
a2: 0.22776858051850205
a3: 0.0025103721241699767
a4: 0.13936493073563122
65200
15282
Val cmap: 0.911212
Valid loss: 1.348682
0.8467494326525163
a1: 0.6783957187738129
a2: 0.23028857522070775
a3: 0.002525160004526928
a4: 0.08879054600095243
65200
15282
Val cmap: 0.911169
Valid loss: 1.348850
0.8467187395687296
a1: 0.5941239711701507
a2: 0.21869398133103987
a3: 0.001984987916861884
a4: 0.18519705958194754
65200
15282
Val cmap: 0.911167
Valid loss: 1.348639
0.8465389493358254
a1: 0.626939693512018
a2: 0.23899154040094145
a3: 0.0029949301324093194
a4: 0.1310738359546313
65200
15282
Val cmap: 0.911215
Valid loss: 1.348562
0.8466929186411266
a1: 0.6232084867295148
a2: 0.22443897039139074
a3: 0.0022038076131250623
a4: 0.15014873526596942
65200
15282
Val cmap: 0.911219
Valid loss: 1.348685
0.8467776924874011
a1: 0.6514616360435355
a2: 0.24039817718996687
a3: 0.0022709204823290648
a4: 0.10586926628416861
65200
15282
Val cmap: 0.911187
Valid loss: 1.348636
0.8468444414778227
a1: 0.6285560206365736
a2: 0.22604417717555922
a3: 0.002114244656583947
a4: 0.14328555753128328
65200
15282
Val cmap: 0.911212
Valid loss: 1.348688
0.8467776924874011
a1: 0.6077951217271731
a2: 0.22215113195114744
a3: 0.0018851980749996736
a4: 0.1681685482466798
65200
15282
Val cmap: 0.911194
Valid loss: 1.348650
0.8466929186411266
a1: 0.6273002729232059
a2: 0.2098717218494419
a3: 0.002437515930555929
a4: 0.16039048929679628
65200
15282
Val cmap: 0.911200
Valid loss: 1.348852
0.8468624833110815
a1: 0.5801975431211668
a2: 0.19457450167484797
a3: 0.00205026337857337
a4: 0.2231776918254119
65200
15282
Val cmap: 0.911182
Valid loss: 1.348849
0.8465672040319081
a1: 0.7087950988295433
a2: 0.22470659438728002
a3: 0.002650263228794538
a4: 0.06384804355438216
65200
15282
Val cmap: 0.911145
Valid loss: 1.349040
0.8467085058085192
a1: 0.5325230124904251
a2: 0.2722449288534172
a3: 0.0015883577123789263
a4: 0.19364370094377875
65200
15282
Val cmap: 0.911188
Valid loss: 1.347902
0.8467055879899916
a1: 0.560945786347292
a2: 0.2075041341208785
a3: 0.001811200745908513
a4: 0.229738878785921
65200
15282
Val cmap: 0.911192
Valid loss: 1.348651
0.8465876856332387
a1: 0.6503283776435987
a2: 0.23691997652337698
a3: 0.002934934150653507
a4: 0.10981671168237077
65200
15282
Val cmap: 0.911187
Valid loss: 1.348673
0.8468444414778227
a1: 0.6275476831181379
a2: 0.2504907176239826
a3: 0.0022573650215205166
a4: 0.11970423423635895
65200
15282
Date :05/14/2023, 22:51:28
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b0
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
a1: 0.43146820306383094
a2: 0.04558263842440432
a3: 0.13995310589562254
a4: 0.38299605261614217
65200
15282
Val cmap: 0.911081
Valid loss: 1.351776
0.8462951213811066
a1: 0.42380484999218854
a2: 0.5346892213656875
a3: 0.0019509612795772663
a4: 0.039554967362546725
65200
15282
Val cmap: 0.911125
Valid loss: 1.345356
0.8459333333333333
a1: 0.5645914144151729
a2: 0.36341914986068136
a3: 0.011716170751471166
a4: 0.060273264972674566
65200
15282
Val cmap: 0.911164
Valid loss: 1.347264
0.8468029752176378
a1: 0.8927352382583126
a2: 0.06936180628608918
a3: 0.015489060129267783
a4: 0.02241389532633046
65200
15282
Val cmap: 0.911069
Valid loss: 1.351814
0.8469503640857773
a1: 0.39445057744679285
a2: 0.32262849406911215
a3: 0.0042403351927914916
a4: 0.27868059329130357
65200
15282
Val cmap: 0.911100
Valid loss: 1.347131
0.8466155385128377
a1: 0.5307649493546166
a2: 0.4272470080811601
a3: 0.04031413042272916
a4: 0.0016739121414941216
65200
15282
Val cmap: 0.911137
Valid loss: 1.346917
0.8464849354375896
a1: 0.8549606237583012
a2: 0.04457251881678182
a3: 0.009961840645530849
a4: 0.09050501677938616
65200
15282
Val cmap: 0.911093
Valid loss: 1.351798
0.8469503640857773
a1: 0.11197819070509708
a2: 0.24022266836111603
a3: 0.006550791105348214
a4: 0.6412483498284387
65200
15282
Val cmap: 0.911048
Valid loss: 1.348120
0.845530623812223
a1: 0.9105338088456787
a2: 0.05648954039802192
a3: 0.0076252445376669324
a4: 0.025351406218632456
65200
15282
Val cmap: 0.911060
Valid loss: 1.351961
0.8470273881095525
a1: 0.4596942149842487
a2: 0.21406897188856744
a3: 0.006635308152234598
a4: 0.31960150497494927
65200
15282
Val cmap: 0.911141
Valid loss: 1.348390
0.8463180362860193
a1: 0.6970196526072107
a2: 0.11943865744615616
a3: 0.0009369743196473291
a4: 0.18260471562698585
65200
15282
Val cmap: 0.911178
Valid loss: 1.350074
0.8469472911172681
a1: 0.6925895258475098
a2: 0.11868155811302375
a3: 0.0012266388495030818
a4: 0.1875022771899634
65200
15282
Val cmap: 0.911172
Valid loss: 1.350067
0.8469087995727067
a1: 0.7135070269683548
a2: 0.10614323367344049
a3: 0.0009235078100617641
a4: 0.179426231548143
65200
15282
Val cmap: 0.911149
Valid loss: 1.350291
0.8468703054581872
a1: 0.7151275933168731
a2: 0.0011823520596054987
a3: 0.0012980528887731138
a4: 0.28239200173474827
65200
15282
Val cmap: 0.911099
Valid loss: 1.351549
0.846885957588913
a1: 0.7369509891075213
a2: 0.11263209612461199
a3: 0.0021261368031099386
a4: 0.14829077796475673
65200
15282
Val cmap: 0.911143
Valid loss: 1.350335
0.8471271658932327
a1: 0.6415713605542428
a2: 0.15042299736800677
a3: 0.0009015794097464638
a4: 0.20710406266800396
65200
15282
Val cmap: 0.911167
Valid loss: 1.349518
0.8468137663985046
a1: 0.8211616947733744
a2: 0.08350294869019459
a3: 0.0025594410068839374
a4: 0.09277591552954706
65200
15282
Val cmap: 0.911112
Valid loss: 1.351078
0.8471711976487877
a1: 0.9521234430168074
a2: 0.0011965715038409347
a3: 0.0014266911856090918
a4: 0.04525329429374257
65200
15282
Val cmap: 0.911032
Valid loss: 1.352770
0.8470658962626499
a1: 0.9794970020162206
a2: 0.0048018495092947144
a3: 0.001254932418764751
a4: 0.014446216055719949
65200
15282
Val cmap: 0.911046
Valid loss: 1.352907
0.8470273881095525
a1: 0.6231260482180789
a2: 0.14980254829526896
a3: 0.0027509432072198004
a4: 0.2243204602794323
65200
15282
Val cmap: 0.911166
Valid loss: 1.349481
0.8467470040391227
a1: 0.7913723989396455
a2: 0.08834411866680572
a3: 0.003389355776002576
a4: 0.1168941266175462
65200
15282
Val cmap: 0.911116
Valid loss: 1.350880
0.8470116861435726
a1: 0.6534936874373501
a2: 0.14100997741107418
a3: 0.0009565054694000493
a4: 0.20453982968217563
65200
15282
Val cmap: 0.911173
Valid loss: 1.349666
0.8468137663985046
a1: 0.6369136787270949
a2: 0.13792237493697765
a3: 0.0009131264807658984
a4: 0.22425081985516154
65200
15282
Val cmap: 0.911169
Valid loss: 1.349640
0.8467854996995793
a1: 0.7539332194977665
a2: 0.12882215463249677
a3: 0.001907187909654955
a4: 0.11533743796008179
65200
15282
Val cmap: 0.911138
Valid loss: 1.350233
0.8470988849569341
a1: 0.5688426281213007
a2: 0.18203561492158904
a3: 0.004056704637862293
a4: 0.24506505231924797
65200
15282
Val cmap: 0.911171
Valid loss: 1.348972
0.846680241679741
a1: 0.8287186064369626
a2: 0.09467303176086393
a3: 0.0013529764894057049
a4: 0.07525538531276776
65200
15282
Val cmap: 0.911104
Valid loss: 1.350980
0.8470171688155522
a1: 0.6654176170466645
a2: 0.11791236021015356
a3: 0.0017704092218600984
a4: 0.2148996135213219
65200
15282
Val cmap: 0.911147
Valid loss: 1.349977
0.8468522598304292
a1: 0.7795508350431523
a2: 0.10277863421086064
a3: 0.0014361586798128623
a4: 0.11623437206617424
65200
15282
Val cmap: 0.911124
Valid loss: 1.350637
0.8470784641068447
a1: 0.5233420229197292
a2: 0.17848530813140662
a3: 0.0029032314778329503
a4: 0.29526943747103124
65200
15282
Val cmap: 0.911168
Valid loss: 1.348878
0.8464104617026955
a1: 0.6843406663645681
a2: 0.131526270285715
a3: 0.0009375825269328839
a4: 0.18319548082278397
65200
15282
Val cmap: 0.911189
Valid loss: 1.349889
0.8468907506926132
a1: 0.619275813467108
a2: 0.16403216791558695
a3: 0.002017136981941066
a4: 0.21467488163536397
65200
15282
Val cmap: 0.911175
Valid loss: 1.349304
0.8466519794378798
a1: 0.6900056356966016
a2: 0.13807401480027354
a3: 0.0009073640223360749
a4: 0.17101298548078883
65200
15282
Val cmap: 0.911186
Valid loss: 1.349839
0.8469190199612792
a1: 0.7636495550911907
a2: 0.12757809645022122
a3: 0.0017558004823439112
a4: 0.10701654797624416
65200
15282
Val cmap: 0.911150
Valid loss: 1.350292
0.8470321159110635
a1: 0.6114214096013295
a2: 0.16429905845858045
a3: 0.002180231876895345
a4: 0.2220993000631947
65200
15282
Val cmap: 0.911179
Valid loss: 1.349277
0.8465749766323942
a1: 0.5616835234607834
a2: 0.19716136031387488
a3: 0.0023057842809413327
a4: 0.23884933194440036
65200
15282
Val cmap: 0.911196
Valid loss: 1.348769
0.8466159391269524
a1: 0.5692289510099793
a2: 0.1950398046609934
a3: 0.002667598499784494
a4: 0.23306364582924283
65200
15282
Val cmap: 0.911186
Valid loss: 1.348817
0.8466339574780547
a1: 0.3848392888462793
a2: 0.24359438827494198
a3: 0.004957550336668345
a4: 0.36660877254211044
65200
15282
Val cmap: 0.911102
Valid loss: 1.347944
0.8463000633607897
a1: 0.49916927678652023
a2: 0.2027617714490365
a3: 0.0034615304743759972
a4: 0.2946074212900673
65200
15282
Val cmap: 0.911153
Valid loss: 1.348562
0.8464591880983355
a1: 0.5686649868927186
a2: 0.19109350478788784
a3: 0.002450790278161542
a4: 0.23779071804123203
65200
15282
Val cmap: 0.911174
Valid loss: 1.348856
0.8466339574780547
a1: 0.4526905775277554
a2: 0.27424582606894277
a3: 0.004587606679054644
a4: 0.26847598972424713
65200
15282
Val cmap: 0.911132
Valid loss: 1.347720
0.8466233116558278
a1: 0.5717345876790647
a2: 0.23009282104201748
a3: 0.019851704517967535
a4: 0.1783208867609503
65200
15282
Val cmap: 0.911151
Valid loss: 1.348645
0.8466339574780547
a1: 0.6012035160181307
a2: 0.16625818058115155
a3: 0.002327413313354925
a4: 0.2302108900873628
65200
15282
Val cmap: 0.911186
Valid loss: 1.349223
0.8465749766323942
a1: 0.509395427341418
a2: 0.207607161422454
a3: 0.003041433582351092
a4: 0.27995597765377694
65200
15282
Val cmap: 0.911169
Valid loss: 1.348528
0.846382226373553
a1: 0.580751382698541
a2: 0.1668811423412933
a3: 0.0016501840674043341
a4: 0.25071729089276135
65200
15282
Val cmap: 0.911191
Valid loss: 1.349146
0.8465287049399199
a1: 0.6792375366646424
a2: 0.167733991031268
a3: 0.0015578158836102867
a4: 0.15147065642047935
65200
15282
Val cmap: 0.911198
Valid loss: 1.349483
0.8470242664975467
a1: 0.6856787125473682
a2: 0.1768105967807515
a3: 0.0015872837370140113
a4: 0.13592340693486626
65200
15282
Val cmap: 0.911194
Valid loss: 1.349415
0.8470242664975467
a1: 0.8666145971178478
a2: 0.0690107460991095
a3: 0.00166778075145713
a4: 0.06270687603158555
65200
15282
Val cmap: 0.911106
Valid loss: 1.351479
0.8469323001903745
a1: 0.7234525173946096
a2: 0.17290316894336358
a3: 0.0011564037109303375
a4: 0.1024879099510965
65200
15282
Val cmap: 0.911154
Valid loss: 1.349615
0.8469936233432376
a1: 0.6801582929689752
a2: 0.1512240142250295
a3: 0.0016010148298485271
a4: 0.16701667797614672
65200
15282
Val cmap: 0.911180
Valid loss: 1.349665
0.8468907506926132
a1: 0.7370883310744598
a2: 0.1825889073587516
a3: 0.001133111489499721
a4: 0.07918965007728886
65200
15282
Val cmap: 0.911163
Valid loss: 1.349578
0.8468420349846442
a1: 0.5340761894126346
a2: 0.21775560226429666
a3: 0.0015621985908309554
a4: 0.2466060097322378
65200
15282
Val cmap: 0.911181
Valid loss: 1.348465
0.8466466466466467
a1: 0.6795172836854618
a2: 0.16075906690620417
a3: 0.0012828901940734067
a4: 0.1584407592142606
65200
15282
Val cmap: 0.911183
Valid loss: 1.349556
0.8468907506926132
a1: 0.6494445986091963
a2: 0.13806355401464665
a3: 0.0010523771184292974
a4: 0.21143947025772772
65200
15282
Val cmap: 0.911174
Valid loss: 1.349685
0.8468239927901466
a1: 0.7038531326519334
a2: 0.15193657793032955
a3: 0.0011118497511562629
a4: 0.14309843966658078
65200
15282
Val cmap: 0.911177
Valid loss: 1.349749
0.8470038390919712
a1: 0.7949430189962039
a2: 0.1444050416951546
a3: 0.0015117887421714966
a4: 0.05914015056646999
65200
15282
Val cmap: 0.911158
Valid loss: 1.350267
0.8469731877525126
a1: 0.686793114752672
a2: 0.16966619530358817
a3: 0.0020012661042493746
a4: 0.14153942383949042
65200
15282
Val cmap: 0.911206
Valid loss: 1.349499
0.8470242664975467
a1: 0.7510960085452449
a2: 0.15676589205902286
a3: 0.002022925050279945
a4: 0.09011517434545226
65200
15282
Val cmap: 0.911158
Valid loss: 1.349923
0.8469936233432376
a1: 0.6468751053805445
a2: 0.1852220775499492
a3: 0.002227126063050752
a4: 0.16567569100645554
65200
15282
Val cmap: 0.911194
Valid loss: 1.349179
0.8469009712626414
a1: 0.6238381509942633
a2: 0.18772562117954064
a3: 0.002411317312619056
a4: 0.18602491051357697
65200
15282
Val cmap: 0.911190
Valid loss: 1.349070
0.8467392029904545
a1: 0.6000043500328123
a2: 0.19213035210083138
a3: 0.0034474739754719462
a4: 0.2044178238908844
65200
15282
Val cmap: 0.911184
Valid loss: 1.348953
0.8465569611802797
a1: 0.4829037609214839
a2: 0.22332458746823552
a3: 0.005426016724227143
a4: 0.2883456348860534
65200
15282
Val cmap: 0.911144
Valid loss: 1.348324
0.8464694306394049
a1: 0.6332668374287492
a2: 0.17445735533355847
a3: 0.002414801804239227
a4: 0.18986100543345308
65200
15282
Val cmap: 0.911155
Valid loss: 1.349245
0.8468239927901466
a1: 0.6536336410960932
a2: 0.1877857659300708
a3: 0.0018415155328350755
a4: 0.1567390774410009
65200
15282
Val cmap: 0.911179
Valid loss: 1.349174
0.8468624833110815
a1: 0.7256637668212629
a2: 0.17360192370737676
a3: 0.002291498102116007
a4: 0.09844281136924435
65200
15282
Val cmap: 0.911152
Valid loss: 1.349632
0.8469936233432376
a1: 0.5969991054313356
a2: 0.2027402890885714
a3: 0.0035680921202554216
a4: 0.1966925133598376
65200
15282
Val cmap: 0.911167
Valid loss: 1.348833
0.8466622162883845
a1: 0.5333421709668446
a2: 0.2447159945639384
a3: 0.0027571781353321364
a4: 0.21918465633388493
65200
15282
Val cmap: 0.911167
Valid loss: 1.348194
0.8466466466466467
a1: 0.6548707214975957
a2: 0.17939191330857412
a3: 0.0014249702525405787
a4: 0.16431239494128957
65200
15282
Val cmap: 0.911196
Valid loss: 1.349262
0.846872705426874
a1: 0.7099592823171438
a2: 0.16898267131237885
a3: 0.0014059971129037258
a4: 0.11965204925757365
65200
15282
Val cmap: 0.911184
Valid loss: 1.349598
0.8470706059088633
a1: 0.6648123141144815
a2: 0.1772749760847387
a3: 0.0019063714820243048
a4: 0.15600633831875552
65200
15282
Val cmap: 0.911194
Valid loss: 1.349329
0.846872705426874
a1: 0.6635307858073959
a2: 0.1780185117260881
a3: 0.00198821063548072
a4: 0.1564624918310353
65200
15282
Val cmap: 0.911193
Valid loss: 1.349317
0.846872705426874
a1: 0.7611728547715305
a2: 0.1596968715640318
a3: 0.0013087030988127946
a4: 0.07782157056562487
65200
15282
Val cmap: 0.911156
Valid loss: 1.349933
0.8468318087734528
a1: 0.6837117156834633
a2: 0.17929478506638202
a3: 0.0019691202871676625
a4: 0.13502437896298697
65200
15282
Val cmap: 0.911192
Valid loss: 1.349385
0.8470525402229789
a1: 0.6556859624418785
a2: 0.20183113178644474
a3: 0.0019027608709148835
a4: 0.1405801449007619
65200
15282
Val cmap: 0.911203
Valid loss: 1.349037
0.8468624833110815
a1: 0.6376589053145321
a2: 0.1962220354357402
a3: 0.0017367946504225668
a4: 0.16438226459930516
65200
15282
Val cmap: 0.911208
Valid loss: 1.349024
0.8469009712626414
a1: 0.6382401135595314
a2: 0.19815837336476608
a3: 0.0018304723404815866
a4: 0.16177104073522097
65200
15282
Val cmap: 0.911210
Valid loss: 1.349007
0.8469292389853137
a1: 0.6308948642816216
a2: 0.20325109970331642
a3: 0.0031158456632731685
a4: 0.16273819035178885
65200
15282
Val cmap: 0.911213
Valid loss: 1.348941
0.8468624833110815
a1: 0.5491466183554679
a2: 0.20937801756688937
a3: 0.004230807705120633
a4: 0.23724455637252215
65200
15282
Val cmap: 0.911189
Valid loss: 1.348623
0.8465979243834886
a1: 0.6063399614381996
a2: 0.20084132450460113
a3: 0.00288981965766159
a4: 0.18992889439953772
65200
15282
Val cmap: 0.911183
Valid loss: 1.348877
0.8467007109242014
a1: 0.6282581063936805
a2: 0.19736905677987326
a3: 0.0013838852941767718
a4: 0.17298895153226945
65200
15282
Val cmap: 0.911208
Valid loss: 1.348973
0.8468059542086643
a1: 0.7027178462789664
a2: 0.19872956052149526
a3: 0.0014531634709318625
a4: 0.0970994297286065
65200
15282
Val cmap: 0.911153
Valid loss: 1.349259
0.8467392029904545
a1: 0.6317955197410486
a2: 0.21346732551773978
a3: 0.001053038107735822
a4: 0.15368411663347575
65200
15282
Val cmap: 0.911207
Valid loss: 1.348816
0.8468342178164946
a1: 0.622982977800121
a2: 0.21342380407250844
a3: 0.0010465414064327154
a4: 0.16254667672093784
65200
15282
Val cmap: 0.911197
Valid loss: 1.348784
0.8468624833110815
a1: 0.6271942901452107
a2: 0.2144075093856945
a3: 0.0010222270682843121
a4: 0.15737597340081053
65200
15282
Val cmap: 0.911207
Valid loss: 1.348789
0.8469009712626414
a1: 0.7327580772678505
a2: 0.19397823847105328
a3: 0.0012276646638687313
a4: 0.07203601959722752
65200
15282
Val cmap: 0.911145
Valid loss: 1.349442
0.8468035386412953
a1: 0.6321683063438502
a2: 0.22594007784804768
a3: 0.0010273957369485403
a4: 0.14086422007115354
65200
15282
Val cmap: 0.911217
Valid loss: 1.348690
0.8468059542086643
a1: 0.5898036229690131
a2: 0.232288453370899
a3: 0.0010860131386853714
a4: 0.1768219105214025
65200
15282
Val cmap: 0.911184
Valid loss: 1.348476
0.8465106965257151
a1: 0.640831760783157
a2: 0.21677466441041998
a3: 0.0012514920667093554
a4: 0.1411420827397137
65200
15282
Val cmap: 0.911203
Valid loss: 1.348818
0.8468059542086643
a1: 0.6236566296752711
a2: 0.2173019929857409
a3: 0.0009988162087619541
a4: 0.158042561130226
65200
15282
Val cmap: 0.911205
Valid loss: 1.348746
0.8468444414778227
a1: 0.5861792583159652
a2: 0.2512115056178397
a3: 0.0010090640814656468
a4: 0.16160017198472945
65200
15282
Val cmap: 0.911205
Valid loss: 1.348272
0.8465287049399199
a1: 0.6130690302837016
a2: 0.22453527278657381
a3: 0.0009800758364172006
a4: 0.16141562109330734
65200
15282
Val cmap: 0.911196
Valid loss: 1.348634
0.8467494326525163
a1: 0.5469479411615773
a2: 0.23546489391779207
a3: 0.0009119929358676381
a4: 0.216675171984763
65200
15282
Val cmap: 0.911166
Valid loss: 1.348308
0.8465979243834886
a1: 0.5890816130422463
a2: 0.25230069099623387
a3: 0.0011490811685978908
a4: 0.15746861479292198
65200
15282
Val cmap: 0.911203
Valid loss: 1.348273
0.8465672040319081
a1: 0.6304106302973559
a2: 0.2098382643510441
a3: 0.0010504348130305047
a4: 0.1587006705385695
65200
15282
Val cmap: 0.911206
Valid loss: 1.348848
0.8468624833110815
a1: 0.6333833690383256
a2: 0.21239473546989535
a3: 0.0012809355437716048
a4: 0.15294095994800747
65200
15282
Val cmap: 0.911206
Valid loss: 1.348835
0.8468624833110815
a1: 0.557654694629601
a2: 0.21037173366216264
a3: 0.0013171462693419651
a4: 0.23065642543889436
65200
15282
Val cmap: 0.911195
Valid loss: 1.348606
0.8465979243834886
a1: 0.6321468131436802
a2: 0.22339677072091274
a3: 0.0017063871752548876
a4: 0.1427500289601522
65200
15282
Val cmap: 0.911217
Valid loss: 1.348724
0.8468444414778227
a1: 0.6995204629061369
a2: 0.2056556217866527
a3: 0.0017385382258710222
a4: 0.09308537708133938
65200
15282
Val cmap: 0.911156
Valid loss: 1.349179
0.8467392029904545
a1: 0.6732939227028231
a2: 0.22333842742827648
a3: 0.0011566177261781924
a4: 0.10221103214272227
65200
15282
Val cmap: 0.911185
Valid loss: 1.348881
0.846767464370348
a1: 0.5828384655756709
a2: 0.22956600497549384
a3: 0.0016664949024271832
a4: 0.1859290345464081
65200
15282
Val cmap: 0.911172
Valid loss: 1.348487
0.8465774455161365
a1: 0.6348278063633902
a2: 0.20049058586848761
a3: 0.0014707288276028041
a4: 0.1632108789405194
65200
15282
Val cmap: 0.911215
Valid loss: 1.348966
0.8469009712626414
a1: 0.6075469136215923
a2: 0.1984883350375906
a3: 0.0014713114004468945
a4: 0.1924934399403702
65200
15282
Val cmap: 0.911173
Valid loss: 1.348890
0.8466622162883845
a1: 0.6428585794055968
a2: 0.1934159002227606
a3: 0.0017854182164553016
a4: 0.16194010215518734
65200
15282
Val cmap: 0.911196
Valid loss: 1.349073
0.8469009712626414
a1: 0.7160124825692468
a2: 0.20842461165459433
a3: 0.0011961122221280517
a4: 0.07436679355403085
65200
15282
Val cmap: 0.911146
Valid loss: 1.349218
0.8467572348876798
a1: 0.6658596166366766
a2: 0.18827447004378428
a3: 0.0010689634452950153
a4: 0.14479694987424413
65200
15282
Val cmap: 0.911191
Valid loss: 1.349208
0.8469009712626414
a1: 0.6315006801404516
a2: 0.22313362753674826
a3: 0.0013860175360082187
a4: 0.14397967478679194
65200
15282
Val cmap: 0.911217
Valid loss: 1.348720
0.8468444414778227
a1: 0.5629180319648215
a2: 0.22414302268167935
a3: 0.0014619592277616026
a4: 0.21147698612573756
65200
15282
Val cmap: 0.911181
Valid loss: 1.348478
0.8466159391269524
a1: 0.6960834462244021
a2: 0.19704166736823733
a3: 0.0015877989599202846
a4: 0.10528708744744028
65200
15282
Val cmap: 0.911169
Valid loss: 1.349249
0.8468624833110815
a1: 0.6023004371576812
a2: 0.23519612690911035
a3: 0.0013514437813862885
a4: 0.16115199215182213
65200
15282
Val cmap: 0.911196
Valid loss: 1.348492
0.8467392029904545
a1: 0.6206632689374156
a2: 0.21701289521177566
a3: 0.0021157980419732186
a4: 0.16020803780883547
65200
15282
Val cmap: 0.911197
Valid loss: 1.348751
0.8468342178164946
a1: 0.6719348007505528
a2: 0.18479116980843135
a3: 0.001748795957252446
a4: 0.14152523348376342
65200
15282
Val cmap: 0.911194
Valid loss: 1.349276
0.8469111904682443
a1: 0.6465972373730215
a2: 0.20331094659159188
a3: 0.002164259402106845
a4: 0.14792755663327972
65200
15282
Val cmap: 0.911195
Valid loss: 1.348989
0.8469292389853137
a1: 0.6394611817939609
a2: 0.20759556876470736
a3: 0.0011887452562782445
a4: 0.15175450418505346
65200
15282
Val cmap: 0.911205
Valid loss: 1.348906
0.8468624833110815
a1: 0.6203380766180852
a2: 0.21913060080209135
a3: 0.0013592909035853788
a4: 0.1591720316762381
65200
15282
Val cmap: 0.911195
Valid loss: 1.348719
0.8468059542086643
a1: 0.5786271185347857
a2: 0.23754614188565637
a3: 0.000919068767820625
a4: 0.18290767081173734
65200
15282
Val cmap: 0.911183
Valid loss: 1.348384
0.8464824456013884
a1: 0.6869859153828725
a2: 0.19083976182668566
a3: 0.0015359925997342643
a4: 0.12063833019070762
65200
15282
Val cmap: 0.911193
Valid loss: 1.349274
0.8469292389853137
a1: 0.6584812124949936
a2: 0.21201620121393122
a3: 0.001161957484736302
a4: 0.1283406288063389
65200
15282
Val cmap: 0.911190
Valid loss: 1.348935
0.8468342178164946
a1: 0.7179980379637066
a2: 0.2072307075798525
a3: 0.0010397374058369602
a4: 0.07373151705060388
65200
15282
Val cmap: 0.911147
Valid loss: 1.349237
0.8467572348876798
a1: 0.6066841398362178
a2: 0.22801688471065362
a3: 0.0017590818814500087
a4: 0.16353989357167853
65200
15282
Val cmap: 0.911195
Valid loss: 1.348585
0.8467494326525163
a1: 0.5257113982825504
a2: 0.2492297384356085
a3: 0.0024384576074382132
a4: 0.22262040567440286
65200
15282
Val cmap: 0.911171
Valid loss: 1.348124
0.846628632435859
a1: 0.6304922863339102
a2: 0.2202585655323935
a3: 0.002626614960567406
a4: 0.1466225331731289
65200
15282
Val cmap: 0.911214
Valid loss: 1.348759
0.846872705426874
a1: 0.7370658165302157
a2: 0.19707314713395246
a3: 0.00201554351808436
a4: 0.06384549281774743
65200
15282
Val cmap: 0.911139
Valid loss: 1.349441
0.8467752703965816
a1: 0.6327821806656989
a2: 0.2211054247702996
a3: 0.0027038884078203693
a4: 0.14340850615618111
65200
15282
Val cmap: 0.911215
Valid loss: 1.348760
0.846872705426874
a1: 0.6711227700543964
a2: 0.22175033439022135
a3: 0.003160542249799358
a4: 0.10396635330558293
65200
15282
Val cmap: 0.911185
Valid loss: 1.348911
0.846767464370348
a1: 0.5717167967700059
a2: 0.24171346538565824
a3: 0.0026637147840660475
a4: 0.18390602306026985
65200
15282
Val cmap: 0.911185
Valid loss: 1.348338
0.8465209410979476
a1: 0.6390757928889645
a2: 0.22639968795278392
a3: 0.0026991880083066175
a4: 0.1318253311499449
65200
15282
Val cmap: 0.911205
Valid loss: 1.348731
0.8468342178164946
a1: 0.5938471424059613
a2: 0.23230451284236106
a3: 0.002185180747730066
a4: 0.17166316400394763
65200
15282
Val cmap: 0.911182
Valid loss: 1.348502
0.8465106965257151
a1: 0.6859168376277892
a2: 0.21841313530993467
a3: 0.0025071039244308935
a4: 0.09316292313784523
65200
15282
Val cmap: 0.911163
Valid loss: 1.349000
0.8467187395687296
a1: 0.5462149115705914
a2: 0.2559199157771139
a3: 0.0031134610043935503
a4: 0.1947517116479011
65200
15282
Val cmap: 0.911171
Valid loss: 1.348121
0.846541426140345
a1: 0.6160147528422331
a2: 0.186122876916699
a3: 0.0019384817228680028
a4: 0.19592388851819995
65200
15282
Val cmap: 0.911188
Valid loss: 1.349055
0.8467289719626168
a1: 0.6489032289166715
a2: 0.20267670195547446
a3: 0.0015752554649932657
a4: 0.14684481366286076
65200
15282
Val cmap: 0.911193
Valid loss: 1.348998
0.8469292389853137
a1: 0.6288864328714079
a2: 0.21376975910338689
a3: 0.0037211096461671764
a4: 0.15362269837903805
65200
15282
Val cmap: 0.911210
Valid loss: 1.348832
0.8469009712626414
a1: 0.6655167705077918
a2: 0.21523256731177098
a3: 0.002276794701296247
a4: 0.11697386747914099
65200
15282
Val cmap: 0.911189
Valid loss: 1.348944
0.8468342178164946
a1: 0.6224638360314833
a2: 0.2290608902351622
a3: 0.003772634684737923
a4: 0.1447026390486166
65200
15282
Val cmap: 0.911207
Valid loss: 1.348653
0.8467776924874011
a1: 0.6260134501106461
a2: 0.2308959179333103
a3: 0.0033435232963944365
a4: 0.13974710865964915
65200
15282
Val cmap: 0.911210
Valid loss: 1.348643
0.8467494326525163
a1: 0.5910225717441293
a2: 0.2369239831357458
a3: 0.0035391761816898166
a4: 0.16851426893843507
65200
15282
Val cmap: 0.911183
Valid loss: 1.348460
0.8465106965257151
a1: 0.6105733292158441
a2: 0.2290536747261351
a3: 0.004169096305366444
a4: 0.1562038997526544
65200
15282
Val cmap: 0.911198
Valid loss: 1.348615
0.8467109434969796
a1: 0.5752740013431558
a2: 0.2622978975039968
a3: 0.002968202998109039
a4: 0.1594598981547384
65200
15282
Val cmap: 0.911204
Valid loss: 1.348147
0.8465954606141521
a1: 0.6235533502695605
a2: 0.24479458642918256
a3: 0.004827192387165577
a4: 0.12682487091409136
65200
15282
Val cmap: 0.911210
Valid loss: 1.348512
0.846721174703821
a1: 0.6545599957261142
a2: 0.2422324421751877
a3: 0.0038258695316044596
a4: 0.09938169256709362
65200
15282
Val cmap: 0.911186
Valid loss: 1.348648
0.8468161794152985
a1: 0.5655500804860135
a2: 0.24455420564136837
a3: 0.004516519896478502
a4: 0.1853791939761396
65200
15282
Val cmap: 0.911186
Valid loss: 1.348310
0.8465491923641704
a1: 0.5998341910138758
a2: 0.23198104249790688
a3: 0.00381095423469339
a4: 0.16437381225352393
65200
15282
Val cmap: 0.911193
Valid loss: 1.348543
0.846644194506558
a1: 0.6304487515441726
a2: 0.22234499986890333
a3: 0.0032592383569776794
a4: 0.14394701022994644
65200
15282
Val cmap: 0.911215
Valid loss: 1.348745
0.846872705426874
a1: 0.6322415890331787
a2: 0.22247586405281553
a3: 0.003235341905177466
a4: 0.14204720500882828
65200
15282
Val cmap: 0.911216
Valid loss: 1.348751
0.8468444414778227
a1: 0.6426547269837009
a2: 0.22333032541977324
a3: 0.0029921118265434803
a4: 0.13102283576998242
65200
15282
Val cmap: 0.911202
Valid loss: 1.348779
0.846872705426874
a1: 0.6591492686168354
a2: 0.22138797927506285
a3: 0.003227235384083452
a4: 0.11623551672401827
65200
15282
Val cmap: 0.911189
Valid loss: 1.348867
0.8467392029904545
a1: 0.6977288565345071
a2: 0.20525218603048456
a3: 0.0033522848652898034
a4: 0.09366667256971851
65200
15282
Val cmap: 0.911164
Valid loss: 1.349194
0.8467392029904545
a1: 0.6330613365847678
a2: 0.237716941377897
a3: 0.002718063558080476
a4: 0.1265036584792547
65200
15282
Val cmap: 0.911209
Valid loss: 1.348595
0.8467314045449995
a1: 0.606353469877206
a2: 0.23943410820265307
a3: 0.002807416383714604
a4: 0.15140500553642638
65200
15282
Val cmap: 0.911203
Valid loss: 1.348480
0.8466724517722448
a1: 0.5912230317824138
a2: 0.25378295777566745
a3: 0.0056032031621864485
a4: 0.14939080727973233
65200
15282
Val cmap: 0.911199
Valid loss: 1.348315
0.8466724517722448
a1: 0.6695832179899799
a2: 0.23574364305431358
a3: 0.0025305000389124603
a4: 0.09214263891679407
65200
15282
Val cmap: 0.911172
Valid loss: 1.348758
0.8467289719626168
a1: 0.5463765710847649
a2: 0.27185785373793353
a3: 0.0035481961854365116
a4: 0.17821737899186507
65200
15282
Val cmap: 0.911192
Valid loss: 1.347967
0.8465901508074204
a1: 0.6325308864880672
a2: 0.22345755035203585
a3: 0.0032391578824191225
a4: 0.1407724052774778
65200
15282
Val cmap: 0.911216
Valid loss: 1.348742
0.8468444414778227
a1: 0.630594296612047
a2: 0.22331739712401963
a3: 0.0031340247601146427
a4: 0.1429542815038187
65200
15282
Val cmap: 0.911216
Valid loss: 1.348735
0.8468444414778227
a1: 0.6276466117697479
a2: 0.22301446927281088
a3: 0.003289419401964273
a4: 0.14604949955547694
65200
15282
Val cmap: 0.911220
Valid loss: 1.348729
0.8468444414778227
a1: 0.6174272658921518
a2: 0.22248314057859025
a3: 0.003177718511229452
a4: 0.1569118750180285
65200
15282
Val cmap: 0.911204
Valid loss: 1.348695
0.8467776924874011
a1: 0.5803924067268587
a2: 0.24395836749035626
a3: 0.0034082751170276928
a4: 0.1722409506657574
65200
15282
Val cmap: 0.911202
Valid loss: 1.348352
0.8464824456013884
a1: 0.6536970477005987
a2: 0.227671361837489
a3: 0.003910534931005224
a4: 0.1147210555309071
65200
15282
Val cmap: 0.911185
Valid loss: 1.348790
0.8468444414778227
a1: 0.6876137987771325
a2: 0.21864424275990593
a3: 0.0030413627340900302
a4: 0.09070059572887157
65200
15282
Val cmap: 0.911155
Valid loss: 1.349011
0.8467187395687296
a1: 0.6026319509035797
a2: 0.21044181506031878
a3: 0.004813780232001017
a4: 0.18211245380410052
65200
15282
Val cmap: 0.911171
Valid loss: 1.348785
0.8466057005540351
a1: 0.6352264517989391
a2: 0.2319861726540284
a3: 0.0038301420473386897
a4: 0.1289572334996938
65200
15282
Val cmap: 0.911209
Valid loss: 1.348673
0.846721174703821
a1: 0.7052984249372091
a2: 0.2144803584797632
a3: 0.002802365710798624
a4: 0.07741885087222909
65200
15282
Val cmap: 0.911155
Valid loss: 1.349128
0.8468239927901466
a1: 0.6279335163660035
a2: 0.2417231416236744
a3: 0.0026911572003657427
a4: 0.12765218480995638
65200
15282
Val cmap: 0.911211
Valid loss: 1.348535
0.8467596609490756
a1: 0.6718984775624707
a2: 0.21916808486063333
a3: 0.003377681065424958
a4: 0.10555575651147103
65200
15282
Val cmap: 0.911182
Valid loss: 1.348943
0.8468059542086643
a1: 0.6169856052947803
a2: 0.24619653538201242
a3: 0.004131137082713616
a4: 0.13268672224049366
65200
15282
Val cmap: 0.911217
Valid loss: 1.348466
0.8466929186411266
a1: 0.6477007752317694
a2: 0.24450912184185916
a3: 0.004011506723636964
a4: 0.10377859620273448
65200
15282
Val cmap: 0.911178
Valid loss: 1.348600
0.8468444414778227
a1: 0.6129454862307337
a2: 0.24953036565661185
a3: 0.00422529241699793
a4: 0.13329885569565647
65200
15282
Val cmap: 0.911211
Valid loss: 1.348419
0.8466929186411266
a1: 0.5923220583951955
a2: 0.2588577756490787
a3: 0.004321649248486009
a4: 0.14449851670723982
65200
15282
Val cmap: 0.911201
Valid loss: 1.348254
0.846644194506558
a1: 0.571280932338547
a2: 0.25016795880742065
a3: 0.0023992616908224073
a4: 0.1761518471632099
65200
15282
Val cmap: 0.911202
Valid loss: 1.348249
0.8465491923641704
a1: 0.608601244250876
a2: 0.2615121254506281
a3: 0.0026428178927086067
a4: 0.1272438124057873
65200
15282
Val cmap: 0.911205
Valid loss: 1.348268
0.8467314045449995
a1: 0.6580636712954717
a2: 0.22656306763165715
a3: 0.002997509900553475
a4: 0.11237575117231766
65200
15282
Val cmap: 0.911191
Valid loss: 1.348808
0.8468059542086643
a1: 0.676089103827848
a2: 0.22509637214112474
a3: 0.003571503331833953
a4: 0.09524302069919327
65200
15282
Val cmap: 0.911174
Valid loss: 1.348904
0.8467289719626168
a1: 0.6226672617708602
a2: 0.23924884149615339
a3: 0.004441566633118598
a4: 0.13364233009986784
65200
15282
Val cmap: 0.911214
Valid loss: 1.348560
0.8466929186411266
a1: 0.6402739084755484
a2: 0.23636972754823846
a3: 0.004072810224277925
a4: 0.11928355375193518
65200
15282
Val cmap: 0.911194
Valid loss: 1.348652
0.8468161794152985
a1: 0.6152394068700697
a2: 0.20403594462621613
a3: 0.004466432222426872
a4: 0.17625821628128727
65200
15282
Val cmap: 0.911192
Valid loss: 1.348892
0.8468161794152985
a1: 0.5910996599943134
a2: 0.21485031339001265
a3: 0.00579661475790652
a4: 0.18825341185776748
65200
15282
Val cmap: 0.911167
Valid loss: 1.348711
0.8465672040319081
a1: 0.6515299004334649
a2: 0.22019886013030626
a3: 0.0028807037377773428
a4: 0.12539053569845146
65200
15282
Val cmap: 0.911200
Valid loss: 1.348844
0.8469009712626414
a1: 0.6258696288259263
a2: 0.23727225459841453
a3: 0.003178742407943907
a4: 0.13367937416771522
65200
15282
Val cmap: 0.911213
Valid loss: 1.348577
0.846721174703821
a1: 0.6136830283813901
a2: 0.2481063722713986
a3: 0.0050627881477131355
a4: 0.13314781119949817
65200
15282
Val cmap: 0.911211
Valid loss: 1.348445
0.8466929186411266
a1: 0.6059564787804127
a2: 0.2664178756896526
a3: 0.004292184958703166
a4: 0.12333346057123155
65200
15282
Val cmap: 0.911201
Valid loss: 1.348229
0.8467031500266952
a1: 0.5714631501330709
a2: 0.25676957959939517
a3: 0.004936593534391555
a4: 0.16683067673314236
65200
15282
Val cmap: 0.911200
Valid loss: 1.348211
0.8465106965257151
a1: 0.5574447786674488
a2: 0.27566723427306994
a3: 0.006545518399124648
a4: 0.16034246866035662
65200
15282
Val cmap: 0.911205
Valid loss: 1.347996
0.8465696743192739
a1: 0.62587276514659
a2: 0.245980890113161
a3: 0.0035841826959626044
a4: 0.12456216204428645
65200
15282
Val cmap: 0.911210
Valid loss: 1.348495
0.8467596609490756
a1: 0.6276333024527686
a2: 0.24699528657674952
a3: 0.0032315337733650777
a4: 0.1221398771971168
65200
15282
Val cmap: 0.911206
Valid loss: 1.348488
0.8467596609490756
a1: 0.6092212085687388
a2: 0.2522251002907143
a3: 0.0036876075379165857
a4: 0.13486608360263025
65200
15282
Val cmap: 0.911214
Valid loss: 1.348373
0.8466929186411266
a1: 0.5962695829224468
a2: 0.2506014957895749
a3: 0.004198059709576843
a4: 0.14893086157840144
65200
15282
Val cmap: 0.911206
Valid loss: 1.348348
0.8466057005540351
a1: 0.660526080827943
a2: 0.2391176453277739
a3: 0.0030476248253698875
a4: 0.09730864901891326
65200
15282
Val cmap: 0.911180
Valid loss: 1.348694
0.8468161794152985
a1: 0.6115938924428227
a2: 0.23511991070098653
a3: 0.00252020993970948
a4: 0.1507659869164813
65200
15282
Val cmap: 0.911206
Valid loss: 1.348539
0.8466724517722448
a1: 0.5835603584833602
a2: 0.2580810072370608
a3: 0.004571387952294134
a4: 0.15378724632728488
65200
15282
Val cmap: 0.911210
Valid loss: 1.348234
0.8465954606141521
a1: 0.5164241937526741
a2: 0.27886445990875025
a3: 0.002373424297196747
a4: 0.20233792204137888
65200
15282
Val cmap: 0.911191
Valid loss: 1.347800
0.8466773418734989
a1: 0.6492541481268193
a2: 0.23229237193452842
a3: 0.005326875728219189
a4: 0.11312660421043313
65200
15282
Date :05/16/2023, 22:33:26
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
Date :05/16/2023, 22:33:48
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_88_0.91261.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.846535
Valid loss: 2.209377
0.7405354802471448
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_88_0.91261.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:37:42
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_88_0.91261.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:39:04
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_88_0.91261.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913653
Valid loss: 1.336114
0.8477596064353146
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_88_0.91261.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:42:34
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_98_0.91311.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913682
Valid loss: 1.337358
0.8475477971737323
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_98_0.91311.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:45:10
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_98_0.91311.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913686
Valid loss: 1.337257
0.847604163202873
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_98_0.91311.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:48:28
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913723
Valid loss: 1.335679
0.8476006912136117
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:51:13
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913728
Valid loss: 1.335585
0.8476570289132602
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:54:21
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913695
Valid loss: 1.335394
0.8473731432559065
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
Date :05/16/2023, 22:58:01
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 22:59:37
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_96_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913664
Valid loss: 1.337004
0.8475196169703417
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_96_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
Date :05/16/2023, 23:02:46
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_96_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913670
Valid loss: 1.336942
0.8475861151748904
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_96_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 23:06:30
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 23:07:18
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Val cmap: 0.913728
Valid loss: 1.335585
0.8476570289132602
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_94_0.91360.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_93_0.91336.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_89_0.91299.pth
none: trainv2b2/tf_efficientnetv2_b2_fold_0_model_epoch_90_0.91294.pth
a1: 0.7367410938748198
a2: 0.15888725220218328
a3: 0.04916402342152138
a4: 0.055207630501475556
65200
15282
Date :05/16/2023, 23:10:47
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
Date :05/16/2023, 23:10:58
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b2
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
Date :05/16/2023, 23:11:15
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.912766
Valid loss: 1.386141
0.848369164824861
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Date :05/16/2023, 23:14:10
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.912644
Valid loss: 1.384344
0.8477322175732219
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Date :05/16/2023, 23:19:49
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Date :05/16/2023, 23:21:11
Duration: 5
Sample rate: 32000
nfft: 768
fmin: 20
nmels: 128
fmax: 16000
trainbs: 32
validbs: 192
epochwarmup: 0
totalepoch: 40
learningrate: 0.001
weightdecay: 0.01
thrupsample: 50
model_name: tf_efficientnetv2_b1
mix_up: 0.2
hop_length: 256
train_with_mixup: True
num_channels: 1
use_spec_augmenter: False
use_drop_path: True
76407
Fold: 0
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
65200
15282
Val cmap: 0.912713
Valid loss: 1.380743
0.8483123493169032
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_90_0.91242.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_94_0.91264.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_93_0.91253.pth
none: trainv2b1/tf_efficientnetv2_b1_fold_0_model_epoch_95_0.91246.pth
a1: 0.323980347034444
a2: 0.398980879041631
a3: 0.019388610026137464
a4: 0.25765016389778755
